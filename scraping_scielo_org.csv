Título,Resumo,Texto Completo,Referências,Datas de Publicação,Autores,Detalhes,Link,Data de Coleta,Portal
Editorial – Inteligência artificial e coautoria de trabalhos científicos: discussões sobre utilização de ChatGPT em pesquisa e redação científicas,"O avanço das tecnologias ocasiona relevantes e imprevisíveis impactos na vida humana em geral e na pesquisa científica especificamente. Assim, a sua publicação em revistas é impactada diretamente por inovações na forma de se fazer ciência. Em termos recentes, a propagação do uso de ferramentas de inteligência artificial, como ChatGPT, tem gerado discussões pertinentes em relação à sua possível contribuição à pesquisa e à escrita científica e, consequentemente, aos critérios de autoria e coautoria em trabalhos científicos. Por exemplo, se houver a utilização de ChatGPT para produção de parte do texto do artigo, para análise de dados, etc., o mecanismo deve ser listado como coautor do artigo?","O avanço das tecnologias ocasiona relevantes e imprevisíveis impactos na vida humana em geral e na pesquisa científica especificamente. Assim, a sua publicação em revistas é impactada diretamente por inovações na forma de se fazer ciência. Em termos recentes, a propagação do uso de ferramentas de inteligência artificial, como ChatGPT, tem gerado discussões pertinentes em relação à sua possível contribuição à pesquisa e à escrita científica e, consequentemente, aos critérios de autoria e coautoria em trabalhos científicos. Por exemplo, se houver a utilização de ChatGPT para produção de parte do texto do artigo, para análise de dados, etc., o mecanismo deve ser listado como coautor do artigo?
Para instigar o debate, apresentamos esse questionamento ao próprio sistema (ChatGPT) e obtivemos uma resposta interessante, embora questionável, para a questão: “A decisão de incluir o ChatGPT como coautor em um artigo científico depende de vários fatores, incluindo o grau de contribuição do modelo para a pesquisa e redação do texto. O ChatGPT é uma ferramenta poderosa para auxiliar na geração de texto e na obtenção de informações, mas seu papel em um projeto de pesquisa pode variar. Aqui estão algumas considerações a serem feitas ao decidir se o ChatGPT deve ser incluído como coautor:
Contribuição Substancial: Se o ChatGPT desempenhou um papel substancial na criação do conteúdo do artigo, influenciou a análise dos dados, ajudou na formulação das ideias ou desempenhou um papel fundamental na pesquisa, pode haver argumentos para incluí-lo como coautor.
Autores Humanos Principais: Se a maior parte do trabalho, incluindo o design da pesquisa, a análise dos resultados e a interpretação dos dados, foi realizada por autores humanos, e o ChatGPT foi usado principalmente como uma ferramenta de suporte, a inclusão como coautor pode ser menos justificável.
Agradecimentos: Em muitos casos, agradecimentos no final do artigo podem ser apropriados para reconhecer a contribuição do ChatGPT. Isso permite destacar a utilização da ferramenta sem necessariamente conceder o status de coautor.
Políticas da Revista: É importante verificar as políticas da revista à qual você pretende submeter o artigo. Algumas revistas podem ter diretrizes específicas sobre a inclusão de ferramentas ou modelos como coautores.
Transparência e Ética: Independentemente de incluir o ChatGPT como coautor, é crucial ser transparente sobre a utilização da ferramenta. Isso inclui detalhar como o modelo foi utilizado, qual foi o seu papel e como ele contribuiu para a pesquisa.
Lembre-se de que a ética é uma consideração importante em qualquer decisão relacionada à autoria de um artigo científico. Se você está em dúvida, é uma boa prática discutir a questão com seus colaboradores, orientadores ou colegas de pesquisa para obter uma perspectiva mais abrangente e tomar uma decisão informada.”2
Contudo, a resposta retornada pelo ChatGPT não é compatível com a posição majoritária em termos de orientações internacionais de integridade científica.3
Diante disso, este editorial pretende problematizar e sugerir, considerando o cenário atual, critérios para definição da coautoria em trabalhos científicos e o uso de ferramentas de inteligência artificial.
A utilização de mecanismos de inteligência artificial tem se disseminado no público científico, especialmente a partir da expansão do ChatGPT. A partir de um modelo estatístico e probabilístico, o sistema gera uma resposta ao comando inserido pelo usuário, desenvolvendo uma réplica ao questionamento que, em geral, apresenta encadeamento lógico e plausibilidade. Assim, com base nos comandos e informações providos ao sistema, forma-se um banco de dados que constantemente é atualizado e ampliado para fornecimento de respostas mais precisas.
Sem dúvidas, abre-se uma enorme gama de possibilidades e avanços nas diversas áreas das ciências, nas mais distintas etapas do processo de pesquisa, editoração e divulgação científicas.4
O sistema pode revolucionar o modo de sistematização de dados, de consolidação de revisões bibliográficas, etc. Contudo, os riscos, especialmente no estágio atual do seu desenvolvimento, são relevantes e precisam sem ponderados, ainda mais ao se considerar a função da equipe editorial de periódicos científicos.5
Embora o sistema se aprimore diuturnamente e de um modo extremamente veloz, verifica-se que a resposta ao comando pode resultar comprometida por diversos motivos, como vieses e plágio, tendo em vista as informações que subsidiaram o seu treinamento.6
Além disso, o modo de determinação do comando e até mesmo a ordem de sua inserção podem ocasionar respostas distintas e não diretamente relacionadas ao objeto questionado. Diante disso, já há autores que recomendam alterações nos mecanismos para adotar maiores proteções contra plágio e violações de direitos autorais.7
Na utilização dos sistemas, é fundamental considerar que toda a informação inserida no comando, como artigos e materiais científicos, será considerada na aprendizagem do algoritmo e, assim, poderá ser utilizada por ele em futuras respostas. Isso potencializa o risco de plágio com o passar do tempo. Portanto, autore/as, revisore/as e editore/as precisam adotar postura cautelosa em seu emprego, vedando-se a inserção no sistema de partes do texto em avaliação.
A WAME (Associação Mundial dos Editores em Medicina) esboçou recomendações sobre chatbots e inteligência artificial em manuscritos científicos: “1) Somente humanos podem ser autore/as; 2) Autore/as devem declarar as fontes de seus materiais; 3) Autore/as devem se responsabilizar publicamente por seus trabalhos; 4) Editore/as e revisore/as devem indicar especificamente para autores, e reciprocamente, o uso de chatbots na avaliação de manuscritos e redação de pareceres e correspondências; e, 5) Editore/as precisam de ferramentas digitais apropriadas para lidar com os efeitos de chatbots na publicação”.8
De modo semelhante, o COPE (Comitê de Ética na Publicação) adotou posição no sentido de que ferramentas de IA não cumprem os requisitos mínimos de autoria porque não assumem responsabilidade pelo trabalho submetido e não são capazes de constatar a presença ou ausência de conflitos de interesse ou problemas de direitos autorais e licenças. Também ressaltou que autore/as devem declarar como ferramentas de IA foram utilizadas na pesquisa e são responsáveis pelo trabalho integralmente, inclusive trechos eventualmente por elas produzidos.9
No mesmo sentido, a revista Nature, juntamente aos periódicos da Springer, alterou suas políticas editorias em sentido semelhante, a partir de dois princípios. Primeiramente, sistemas como ChatGPT não podem ser indicados como autores, visto que não são responsabilizáveis pela pesquisa e/ou texto. Além disso, autore/as que utilizem tais mecanismos devem declarar isso na seção de metodologia ou agradecimentos do artigo.10
Com relação à autoria, em editorial anteriormente publicado nesta Revista, assentou-se que, para poder ser considerado autor/a do trabalho, a/o pesquisador/a “deve cumprir requisitos básicos de atuação no sentido de: 1) contribuir efetivamente com a pesquisa (a) em sua concepção ou desenvolvimento, e (b) em sua redação e revisão crítica; 2) aprovar a versão final do artigo e concordar com as ideias sustentadas; e, 3) responsabilizar-se por garantir a integridade da pesquisa e do artigo em sua integralidade”.11
Diante disso, no cenário atual da IA em chatbots, tais ferramentas não são capazes de aprovar a versão final do trabalho e concordar com as ideias sustentadas, tampouco de se responsabilizar pela integridade da pesquisa científica.
Para assegurar a transparência necessária à produção de conhecimento científico aberto, autore/as devem declarar a utilização de chatbots e mecanismos de inteligência artificial na redação de artigos e nas demais fases da pesquisa científica.12
Tal declaração deve constar no item de metodologia do trabalho e/ou nos agradecimentos ao final do artigo. Para garantir a repetibilidade do processo, deve-se indicar o comando exato utilizado, qual ferramenta e a data da pesquisa realizada.
Por fim, pensa-se que as políticas aqui recomendadas para atuação de autore/as também se aplicam, na medida de suas respectivas atribuições, a revisore/as e editore/as. Portanto, todo/as a/os autore/as do processo editorial devem ser transparentes em relação à utilização de chatbots e mecanismos de inteligência artificial, responsabilizando-se pelo conteúdo gerado e informando aos demais o seu emprego.
Diante do exposto, considerando o cenário atual, pensa-se que as revistas científicas devem inserir normas em suas políticas editoriais e de integridade científica para regular questões de coautoria relacionadas ao uso de inteligência artificial, recomendando-se que: 1. mecanismos de inteligência artificial (como ChatGPT) não cumprem os requisitos para coautoria; 2. autore/as devem declarar (na metodologia ou nos agradecimentos) a utilização de mecanismos de inteligência artificial na redação do artigo e/ou nas demais fases da pesquisa científica; 3. autore/as são responsáveis por erros, plágios e outras más-práticas que eventualmente ocorram em suas pesquisas em razão da utilização de mecanismos de inteligência artificial.
Contudo, por óbvio, ressalta-se que este editorial pode ser rapidamente superado em suas conclusões, considerando-se a veloz alteração das premissas relacionadas às possibilidades e às capacidades das ferramentas de inteligência artificial na sociedade e na pesquisa científica.","['2\nChatGPT (\nhttps://chat.openai.com/\n), acesso em 11 ago. 2023. Comando utilizado: “O ChatGPT deve ser indicado como coautor em artigo científico quando for utilizado na pesquisa ou redação do texto?”.', '3\nVale destacar que, em momento posterior, quando da revisão final deste texto, idêntico questionamento foi apresentado ao ChatGPT, em 2 out. 2023 (Comando utilizado: “O ChatGPT deve ser indicado como coautor em artigo científico quando for utilizado na pesquisa ou redação do texto?”) e a resposta foi outra, mais compatível com os parâmetros de integridade aqui propostos, o que demonstra a evolução do sistema: “O uso de ChatGPT, ou qualquer outra ferramenta de IA, na pesquisa ou redação de um artigo científico não requer que o modelo seja listado como coautor. A autoria em um artigo científico deve ser reservada para aqueles que fizeram contribuições intelectuais substanciais para o trabalho. No entanto, é apropriado e ético reconhecer o uso de ferramentas de IA em seus agradecimentos ou na seção de metodologia do artigo. Por exemplo, você pode mencionar que ‘uma parte da pesquisa foi realizada com a assistência do ChatGPT, um modelo de linguagem desenvolvido pela OpenAI’. Além disso, se a plataforma ou a equipe de desenvolvimento da ferramenta de IA (como a OpenAI, no caso do ChatGPT) tiverem fornecido orientações específicas sobre como citar ou referenciar a ferramenta em trabalhos acadêmicos, é importante seguir essas orientações. Em resumo, não é necessário incluir o ChatGPT como coautor, mas é importante reconhecer a contribuição da ferramenta na seção de agradecimentos ou metodologia do artigo. Certifique-se também de seguir quaisquer diretrizes específicas fornecidas pelos desenvolvedores da ferramenta.”', '4\nLIRA, R. P. C. et al. Challenges and advantages of being a scientific journal editor in the era of ChatGPT. Arquivos Brasileiros de Oftalmologia, v. 86, n. 3, p. 5–7, maio 2023. p. 6\n.', '5\nVASCONCELLOS, V. G. de. Editorial: A função do periódico científico e do editor para a produção do conhecimento no Direito e nas ciências criminais. Revista Brasileira de Direito Processual Penal v. 3, n. 1, p. 9–17, 2017\n.', '6\nLEVENE, Alysa. Artificial intelligence and authorship. COPE, Feb. 13, 2023\n. Disponível em: <\nhttps://publicationethics.org/news/artificial-intelligence-and-authorship\n>. Acesso em: 12 ago. 2023; THORP, Holden. ChatGPT is fun, but not an author. Science, vol. 379, n. 6630, 2023. p. 313\n; YOSHINARI JÚNIOR, Gerson H.; VITORINO, Luciano M. How may ChatGPT impact medical teaching? Revista da Associação Médica Brasileira, v. 69, n. 4, p. e20230282, 2023\n.', '7\nNAGPAL, Arth. Authorship in works created by AI\n. Disponível em: <\nhttps://legaltechcenter.net/files/sites/159/2020/05/Authorship-in-Works-Created-by-Artificial-Intelligence.pdf\n>. Acesso em: 12 ago. 2023. p. 9-10.', '8\nZIELINSKI, WINKER, AGGARWAL, FERRIS, HEINEMANN, LAPEÑA, PAI, ING, CITROME, ALAM, VOIGHT, HABIBZADEH. Chatbots, Generative AI, and Scholarly Manuscripts. WAME Recommendations on Chatbots and Generative Artificial Intelligence in Relation to Scholarly Publications. WAME, May 31, 2023\n. Disponível em: <\nhttps://wame.org/page3.php?id=106\n>. Acesso em: 12 ago. 2023 (tradução livre).', '9\nCOPE, Authorship and AI tools position statement. Feb. 13, 2023\n. Disponível em: <\nhttps://publicationethics.org/cope-position-statements/ai-author\n>. Acesso em: 12 ago. 2023.', '10\n“Large Language Models (LLMs), such as ChatGPT, do not currently satisfy our authorship criteria. Notably an attribution of authorship carries with it accountability for the work, which cannot be effectively applied to LLMs. Use of an LLM should be properly documented in the Methods section (and if a Methods section is not available, in a suitable alternative part) of the manuscript.” (Disponível em: <\nhttps://www.nature.com/nature/for-authors/initial-submission\n>. Acesso em: 12 ago. 2023).', '11\nVASCONCELLOS, Vinicius G. Editorial – Autoria e coautoria de trabalhos científicos: discussões sobre critérios para legitimação de coautoria e parâmetros de integridade científica. Revista Brasileira de Direito Processual Penal, vol. 6, n. 1, jan./abr. 2020. p. 19\n.', '12\nTOOLS such as ChatGPT threaten transparent science; here are our ground rules for their use. Nature, v. 613, 2023. p. 612\n.']","['Publicação nesta coleção\n13 Nov 2023', 'Data do Fascículo\nSep-Dec 2023']",[' Vinicius Gomes de Vasconcellos '],['\n          vinicius.vasconcellos@ueg.br\n        '],http://www.scielo.br/scielo.php?script=sci_arttext&pid=S2525-510X2023000301047&lang=pt,2024-11-21 09:59:29.326146,Scielo.org
Cidades cognitivas: Utopia tecnológica ou revolução urbana?,"Os avanços tecnológicos das últimas duas décadas, particularmente nos dispositivos eletrônicos e computação, abriram o caminho para uma extensa lista de potenciais aplicações, em diversas áreas, impactando decisivamente as ações humanas. A proliferação dos equipamentos eletrônicos, tanto de uso pessoal como de coletivo, e conectados de forma ininterrupta, favoreceu a criação e disponibilização de um extenso conjunto de informações, sobre demandas individuais e coletivas, podendo ser utilizadas para gerenciar uma estrutura urbana de forma mais eficiente e otimizada. Surge assim o conceito de estruturas urbanas com uma forma de inteligência subliminar, as cidades inteligentes. Um passo tecnológico complementar foi a proliferação dos gadgets e apps, permitindo um crescimento sem precedentes no volume de dados disponíveis, e que podem ser usados por algoritmos de inteligência artificial para tomar decisões autônomas em tempo real na gestão da infraestrutura urbana, as cidades cognitivas. Embora isso possa representar uma grande revolução urbana, com a melhoria na qualidade de vida nas cidades, o funcionamento de uma estrutura coletiva de forma totalmente autônoma traz consigo profundos questionamentos éticos e morais. Aqui, discutimos as tecnologias que levaram a essa revolução urbana, e os consequentes desafios da humanidade para estabelecer os parâmetros limitantes para o uso dessas tecnologias, e de como este novo cenário urbano resgata o debate sobre o papel da tecnologia na sociedade e no progresso da humanidade.","Estabelecer uma definição precisa para o conceito de cidades suscita intensos debates entre historiadores, antropólogos, sociólogos e urbanistas, mas seria consensual afirmar que elas se estabeleceram há mais de 10 mil anos como uma organização social eficiente. Três grandes temas sustentaram historicamente a formação e o desenvolvimento das cidades: o templo (aspectos religiosos), o forte (questões de defesa) e o mercado (troca de mercadorias) (Kothkin, 2005). Desde os primórdios, as cidades têm sistematicamente mantido a mesma estrutura singular, combinando diversas características comuns, como especialização profissional, governo e gestão centralizados, recolhimento de tributos, relações comerciais e circulação intensiva de mercadorias, estabelecimento de infraestrutura pública e coletiva, dentre outras (Childe, 1950). As vantagens da expansão de uma cidade, em termos socioeconômicos, geralmente sobrepõem as suas desvantagens, caso contrário a cidade passaria por uma condição de estagnação ou entraria em declínio, podendo levar até ao seu desaparecimento. Dessa forma, o processo de adensamento das cidades geralmente é analisado num contexto competitivo, em termos do conceito de sucesso corporativo em uma economia de escala (O’Flaherty, 2005). No último século, apesar de uma acelerada expansão das cidades, manteve-se a mesma lógica da antiguidade de expansão populacional como mecanismo de otimização, mesmo que as grandes cidades da atualidade envolvam milhões ou dezenas de milhões de habitantes, trazendo consigo uma nova dimensão para os desafios urbanos.
Um dos principais desafios das cidades modernas é promover o desenvolvimento urbano de tal forma que a equação de adensamento populacional continue com a combinação de elementos favoráveis se sobrepondo àqueles desfavoráveis. Por outro lado, os desafios contemporâneos requerem que sejam considerados elementos muito mais complexos que na antiguidade, transcendendo a eficiência econômica e incluindo variáveis adicionais mais abstratas, como sustentabilidade, cooperativismo e bem-estar social. Com o passar dos séculos, incorporar esses elementos nas cidades vem se tornando sistematicamente mais desafiador. As cidades do século XXI demandarão estruturas urbanas consideravelmente mais complexas, desde concepção e planejamento até governança, para poder viabilizar efetivamente melhorias na qualidade de vida, se mantendo competitivas e ainda mais atrativas sob diferentes perspectivas (Da Fonseca; Mota, 2019).
Este artigo está organizado da seguinte forma. A próxima seção trata da conceituação das cidades inteligentes e cognitivas, apresentando as tecnologias a elas subjacentes. O caráter orgânico das cidades é tratado na seção que segue, discutindo como as tecnologias de suporte podem se ajustar ao crescimento urbano. A seção posterior discorre sobre as tecnologias usadas para a construção de sistemas de suporte às cidades cognitivas, discutindo suas características. A evolução urbana é indissociável do ser humano, de modo que a seção na sequência trata da relação dessas tecnologias com as organizações sociais e políticas coordenadoras do ambiente urbano, quando são discutidos os desafios sociais e políticos inerentes. Finalmente, reflexões sobre possíveis formas de estabelecimento desses novos contextos urbanos são objeto das duas seções finais.
Desde a antiguidade, a tecnologia tem sido o principal vetor de desenvolvimento e otimização das estruturas urbanas. Particularmente nos últimos 30 anos, a combinação de sistemas eletrônicos e tecnologias digitais passou a permear essas estruturas. Sistemas de informação, compreendendo sensores, atuadores e computadores interligados por sistemas de comunicação de alta velocidade, estabeleceram uma infraestrutura que permite otimizar diversos processos urbanos, como racionalização de serviços públicos, trânsito, mobilidade, logística, consumo energético, segurança, governança, dentre outras (Halegoua, 2020). Essa é a estrutura fundamental que se conceitua como cidade inteligente (Smart City) (Albino et al., 2015).
O número crescente de dispositivos funcionando como sensores ou atuadores dentro de um supersistema urbano interconectado, chamado Internet das Coisas (IoT, Internet of Things), abre novas possibilidades para a infraestrutura urbana (Bibri, 2018). Adicionalmente, com a disseminação de gadgets, como o smartphone, os cidadãos passaram a integrar organicamente toda essa infraestrutura. Em particular, o smartphone permitiu ao cidadão receber diversas informações e utilizar vários serviços, por exemplo por meio de aplicativos (apps). Além disso, o smartphone pode servir como um sensor fornecendo automaticamente informações dos cidadãos para a infraestrutura urbana, de forma conectada, ubíqua e em tempo real. O cidadão pode ainda usar esse mesmo dispositivo para emitir opinião sobre serviços urbanos, e até mesmo em decisões governamentais, ou seja, manifestar sua cidadania (Ruhlandt, 2018). Assim, um conjunto substancial de informações sobre o organismo urbano fica disponível, podendo ser usado para aperfeiçoar a gestão da sua infraestrutura.
Com a disponibilização intensiva de dispositivos eletrônicos e, consequentemente, de substancial quantidade de informações proveniente desses dispositivos, ferramentas computacionais modernas de inteligência artificial e aprendizado de máquina podem ser usadas para identificar padrões de comportamento e de atividades e ações coletivas, de tal forma a ajustar e otimizar o uso do supersistema de infraestrutura urbana de modo autônomo e em tempo real, baseando-se naquelas informações. Assim, uma cidade pode funcionar num contexto ainda mais amplo, agora conceituada como cognitiva (Cognitive City) (Ahuja; Khosla, 2019; Portmann et al., 2018).
A disponibilidade de informações sobre os mais variados processos da cidade cria um organismo coletivo urbano muito mais complexo, com capacidade cognitiva, capaz de aprender com as experiências passadas usando as informações disponibilizadas, e de levar a uma otimização evolutiva sem precedentes das atividades e processos coletivos e urbanos.
As cidades cognitivas (D’Onofrio; Portmann, 2017) se distinguem fundamentalmente das cidades inteligentes. Enquanto as cidades inteligentes dispõem de aparatos de apoio decisório inteligente, as cognitivas vão além, sendo capazes de explorar e compreender as intrincadas inter-relações nesse organismo social e, a partir disso, propor, testar e avaliar novos procedimentos de controle e ajuste da estrutura urbana de forma evolutiva, tudo isso em tempo real. Na medida em que os sistemas inteligentes podem, além de aprender, também se comunicar por meio da ampla rede conectiva existente, a infraestrutura urbana passa a ter um papel mais ativo e dinâmico na organização social. Por isso, o surgimento das cidades com elementos cognitivos aponta para uma revolução urbana, comparável às grandes revoluções tecnológicas da humanidade.
Embora as cidades cognitivas ainda representem uma utopia conceitual para a melhoria da qualidade de vida nos centros urbanos, diversas iniciativas do uso de tecnologias interativas e autônomas já permitem a otimização de alguns processos urbanos. É uma revolução em curso, com seu alcance, impacto e consequências ainda não bem compreendidos. Certo é que o estabelecimento das cidades cognitivas representa um passo inescapável para a consolidação das cidades como estruturas eficientes, no desenrolar do século XXI.
As cidades cognitivas são organismos com maior autonomia, na medida em que observam, aprendem, se ajustam e podem tomar decisões ou sugerir ações em benefício de sua população. Mas como organismo, também interagem com seus cidadãos de múltiplas maneiras, propiciando um apoio sem precedentes, tanto na administração das urbes como em diversos aspectos de seu controle cotidiano.
O caráter orgânico é fundamental para a cidade cognitiva (Appio et al., 2019). É de fundamental importância uma boa aderência do aspecto concreto (corpo) da cidade ao seu aspecto cognitivo (mente). Como dois aspectos de um mesmo organismo, eles devem se completar, de modo que o lado cognitivo possa acompanhar naturalmente as transformações da cidade. E, dessa forma, possa continuar observando e controlando a cidade. Ou seja, deve haver uma simbiose entre o lado físico (corpo urbano) e o lado cognitivo (mente urbana), explorando um equilíbrio e uma coerência entre eles. Deve ainda haver um acoplamento e uma boa sinergia entre:
proposições de planejamento urbano: diretrizes, estratégias, planos diretores, dentre outros (caráter top-down);
acompanhamento do seu crescimento espontâneo, conduzido pelos seus habitantes: abertura de um novo comércio ou disponibilização de um serviço, ocupação habitacional, dentre outros (caráter bottom-up).
Não há como tratar do desenvolvimento urbano sem considerar esses dois aspectos, que se complementam no organismo urbano, de modo que o caráter mental deste organismo (a sua parte cognitiva) tem que ser perfeitamente ajustado a esse princípio.
Essa dualidade (planejamento e espontaneidade) é característica indissociável do conceito de cidades. Pela sua complexidade e pluralidade, elas demandam planejamento, coordenação e controle, ao menos sob alguns aspectos e normalmente com um caráter global (geral). Ao mesmo tempo, a cidade é um organismo vivo, se alterando constantemente e de forma muitas vezes espontânea e incontrolável, na medida em que tais variações decorrem de ações de seus habitantes. Isso pode ser observado na escolha de um local para habitar, pela decisão de que serviços utilizar, ou mesmo de que forma se locomover na malha urbana. E então a mente, que complementa o corpo da cidade, precisa ser capaz de reconhecê-lo (bottom-up) para então poder controlá-lo (top-down), e assim ser capaz de contribuir efetivamente para o oferecimento de um melhor espaço urbano a quem o habita. A cidade existe, e deve bem servir aos seus habitantes e visitantes, enfim a todas as pessoas que ocupem seu espaço em um determinado momento.
A concepção de uma cidade inteligente remete diretamente aos recentes desenvolvimentos tecnológicos, como as redes de comunicação de dados de alta velocidade, computação ubíqua e extensiva presença de sensores e atuadores, que permitiram estabelecer uma infraestrutura urbana funcionando de forma autônoma. Entretanto, é possível vislumbrar um conceito ainda mais complexo para a cidade, agregando a ela um caráter mais orgânico, auto adaptado e com capacidade cognitiva. Nesse contexto, uma cidade pode ser classificada como um organismo vivo, considerando toda a sua complexidade e suas características de dinamismo, crescimento, cooperativismo, adaptabilidade, sustentabilidade, seleção natural, capilaridade, dentre outras. A cidade é um sistema dinâmico e evolutivo em diferentes escalas e agrupamentos, com alta granularidade, semelhante aos processos biológicos de um ecossistema contendo diferentes organismos interagindo entre si, tanto de forma cooperativa como competitiva.
Um organismo cognitivo biológico apresenta uma característica intrínseca, que é a reposição natural ou atualização continuada dos seus elementos constituintes. Assim, classificar uma estrutura urbana como orgânica requer a identificação desses mecanismos de atualização do sistema. As tecnologias correntes permitem a atualização dos programas e dados de forma automática, algo que segue esse preceito. Mas há ainda, inquestionavelmente, uma longa trajetória para que a interoperabilidade de dados e sistemas seja uma realidade. Isso fica ainda mais crítico num contexto de dados disponibilizados que ainda não estão estruturados completamente. Também vale para a expansão e reposição de componentes obsoletos ou danificados que compõem a infraestrutura urbana.
A capacidade cognitiva associada às cidades decorre da superposição de diversos serviços e processos inteligentes ou autoajustáveis. Embora vários aplicativos consigam integrar alguns desses serviços para fins específicos, ainda não há uma natureza totalmente orgânica permeando todo esse ambiente urbano, que atue em tempo real. Por exemplo, tais sistemas são geralmente desenvolvidos em uma estrutura top-down, o que é incompatível com os modelos dos sistemas biológicos, que geralmente evoluem seguindo uma estrutura bottom-up. Desse modo, ainda existe um longo caminho para que a capacidade cognitiva das cidades possa efetivamente seguir os preceitos de estruturas tipicamente orgânicas e evolutivas (Webb, 2007).
Uma das características fundamentais dos seres vivos é exatamente a capacidade de disporem de mecanismos de continuada reposição ou reparação de suas estruturas, de tal forma a estender a sua vida. Esse conceito pode então servir como principal indutor para o desenvolvimento de tecnologias computacionais que tenham qualidade ou estrutura equivalentes, que possam continuamente atualizar ou reparar seus módulos, ajustar seus parâmetros e executar o que for necessário para manter o organismo cognitivo atualizado e servir de forma apropriada ao seu propósito de apoio ao controle do ambiente urbano, em suas várias perspectivas. Adicionalmente, na medida em que a cidade cresce e se transforma, as tecnologias que controlam a sua infraestrutura precisam acompanhar esse processo nos mesmos moldes, para evitar a sistemática de obsolescência das tecnologias urbanas. Isso se torna ainda mais crítico na atualidade, em que as tecnologias evoluem rapidamente e uma infraestrutura urbana pode ficar obsoleta em poucos anos, e sua substituição representar custos insustentáveis para toda a coletividade. Cidades cognitivas deverão ser capazes de estabelecer prioridades, de forma autônoma, sobre quais de suas partes precisam de reparos ou reposições, antecedendo o momento em que falhas levariam a uma indisponibilidade ou ineficiência dos serviços urbanos.
O estabelecimento das cidades inteligentes e cognitivas somente pode ser viabilizado com o aprimoramento das tecnologias de dispositivos eletrônicos, redes de comunicação de banda larga e sistemas computacionais. No que concerne aos dispositivos eletrônicos, houve grande desenvolvimento de sensores, que permitem obter dados das mais diversas naturezas, como localização espacial com grande precisão, condições climáticas, velocidade, diagnósticos ambientais, dentre tantas outras informações. Mais importante ainda, grande parte dos dispositivos eletrônicos, se esses estiverem interligados em rede, pode servir como sensores, disponibilizando uma extensa lista de informações para análise de aspectos coletivos. A corrente tendência de grande granularidade de dispositivos conectados em rede permite se obter informações gerais e especificas com grande aderência às realidades do ambiente urbano. Da mesma forma que uma alta granularidade de sensores, também é válido para os atuadores, que podem modificar as condições da infraestrutura urbana a nível localizado ou global.
Enquanto sensores e atuadores dão conta de identificar e alterar as condições da infraestrutura urbana, cabe aos processos que ficam no interstício entre eles manipular tais informações e tomar decisões. As redes de comunicação e os sistemas de análise, tomada de decisão e controle têm assim papel destacado nessa revolução urbana.
A presença intensiva de dispositivos sensores, incluindo aparelhos eletrônicos, veículos, dispositivos fixos de infraestrutura, smartphones, dentre outros, gera uma quantidade monumental de dados dos mais diversos tipos. Num futuro próximo, essa dimensão de sensores vai aumentar substancialmente, no contexto da internet das coisas (IoT). Com os sensores ligados às redes de comunicação (em redes locais ou globais) e sistemas de armazenamento de dados em nuvem, uma quantidade gigantesca de dados pode ser disponibilizada. Entretanto, essa informação é armazenada de forma desestruturada, e consistindo numa ampla gama de informações de diferentes tipos, naturezas e formatos. No campo de Big Data, o Data Analytics (Hurwitz et al., 2015; Lim et al., 2018) representa a área da computação cujas ferramentas recentemente desenvolvidas permitem a extração de dados para identificar, agrupar, catalogar, selecionar e correlacionar informações disponibilizadas, ou seja, transformar informações sem formatação em informações com significado preciso e utilidade (Townsend, 2013). Diversas técnicas modernas, como aprendizado de máquina (machine learning) e redes neurais (neural networks) (Glassner, 2019a, 2019b), podem ser usadas para extrair informações qualificadas, particularmente na identificação de padrões que possam ser úteis para a tomada de decisão no uso da infraestrutura urbana.
O Deep Learning (Lecun et al., 2015; Sejnowski, 2018), por categorizar as informações a partir de um enorme conjunto de características, permite que a questão do entendimento da mobilidade urbana possa ser codificada em tamanha diversidade de parâmetros, que os padrões, que seriam de difícil medida por outras técnicas, são facilmente identificados com essas tecnologias. Essas técnicas computacionais podem identificar eventuais comportamentos urbanos coletivos com precisão, mesmo em situações em que ainda não são totalmente compreensíveis ou quando não há dados disponíveis para isso (sem previsibilidade). Mas por ter condições de reconhecer esses efeitos, se tornam capazes de prever situações prováveis e, com isso, estabelecer ações antecipadamente para mitigar os efeitos indesejados que não tenham sido previstos.
No contexto das cidades cognitivas, uma vez identificados os padrões nos dados coletados, a inteligência computacional (computational intelligence), a inteligência artificial (artificial intelligence) e a computação cognitiva (cognitive computing) (Netto, 2007) entram em cena para a supervisão e tomada de decisão, em tempo real, com mecanismos adaptativos autônomos (Malone; Bernstein, 2015). Com a tomada de decisão, instruções de controle são, assim, enviadas para os atuadores da infraestrutura urbana. Embora os sistemas concebidos tenham autonomia, suas decisões seguem preceitos previamente definidos e programados, para assim atuar para otimizar o uso da infraestrutura urbana, para o bem-estar coletivo, melhorando a mobilidade, o atendimento de demandas sociais, sistemas de saúde, dentre tantas outras funções para as quais tenham sido concebidos. Dessa forma, esses sistemas podem ser caracterizados como sistemas cognitivos artificiais (artificial cognitive systems) (Vernon, 2014), onde a computação adquire o caráter cognitivo.
Complementarmente, muitas vezes, a base de dados disponível não permite cobrir a totalidade de situações possíveis das demandas à infraestrutura urbana para permitir a previsão de eventos futuros. Ou ainda, a base não tem densidade de dados associados a certas situações, o que poderia levar a previsões imprecisas sobre certas situações. Para essas situações, simulações computacionais podem ser usadas para construir um cenário mais geral e extenso das condições de contorno da infraestrutura urbana, de forma a melhorar a qualidade da tomada de decisão para a otimização do sistema.
Num contexto em que se discute o estabelecimento de novas tecnologias autoadaptadas para a gestão e otimização dos processos urbanos, emerge novamente a percepção do determinismo tecnológico. Essas novas tecnologias apontam para o estabelecimento de um organismo coletivo urbano autônomo e autossustentável, validando a tese do determinismo, ainda mais quando envolve um processo evolutivo intrínseco. Por outro lado, o dinamismo das inter-relações sociais e elementos culturais amortece substancialmente o impacto determinístico de qualquer tecnologia, outorgando um controle decisório maior da sociedade sobre essas tecnologias, mesmo sobre aquelas tecnologias que possam assumir uma estrutura orgânica própria (Bijker et al., 2012; Williams; Edge, 1996).
À primeira vista, uma estrutura urbana autônoma pode provocar uma grande ansiedade na sociedade, que poderia se sentir, de alguma forma, numa condição passiva, ou até subjugada, quando inserida num contexto tecnológico muito mais extenso e autossustentável, como se a tecnologia pudesse evoluir ao ponto de governar de forma autônoma as estruturas coletivas urbanas. Entretanto, é passo fundamental para o estabelecimento das cidades cognitivas criar as condições favoráveis para que a sociedade supere esses temores, que poderiam comprometer todas os potenciais benefícios da aplicação dessas tecnologias.
Mesmo assim, a sociedade também precisa manter-se vigilante da sua ascendência sobre as tecnologias autossustentáveis. A sociedade não ficará, de forma alguma, passiva perante as tecnologias implementadas nas cidades cognitivas. Dessa forma, um ponto importante aqui é a hierarquia na gestão da infraestrutura urbana, a cognição abstrata dessas cidades não pode, de maneira alguma, desafiar a cognição de um cidadão ou de uma coletividade. Ou seja, as tecnologias precisam servir para otimizar as atividades humanas em aglomerados urbanos. A garantia desses preceitos pode facilitar a aceitação coletiva de uma estrutura de cidade cognitiva (Townsend, 2013).
Para assegurar o controle sobre os sistemas artificiais, devem ser construídos sistemas supervisores de maior abrangência, para que eventuais fugas da região de segurança sejam detectadas e bloqueadas, evitando ações que se constituam em perigo, ou sejam inoportunas por ferirem preceitos éticos ou morais. Não há nada mais humano do que a construção de valores éticos e morais, e ao subjugar os sistemas autônomos a esses valores, a ascendência humana sobre eles é garantida. Novamente, de acordo com Fan (2019
), são cinco os pilares éticos a serem observados: responsabilidade, privacidade, transparência, proteção e justiça. Para que cada um deles seja efetivamente garantido pelo ferramental cognitivo, é necessário que tais sistemas tenham sido concebidos com tais premissas.
No processo de contínuo ajuste tecnológico aos anseios da população, debates são fundamentais, e devem tratar, dentre outras coisas, da adequação e aceitação dessas tecnologias como formas de sustentação das estruturas urbanas. É um processo cíclico e continuado por parte dos cidadãos, de reflexão, questionamento, aceitação, revisão, ajustes e correções dessas tecnologias para atender às demandas da cidade. Essas novas tecnologias permitem que esses ajustes possam ocorrer em escalas temporais consideravelmente menores e de forma automática, mas não descartam o objetivo final de, ao fazer uma gestão otimizada da infraestrutura urbana, atender aos anseios da coletividade por uma melhoria na qualidade de vida.
É natural que, nesse momento, seja colocado em questão como estabelecer os critérios norteadores para a implementação dessas tecnologias, para permitir avaliar e estabelecer formas de implantação de sistemas inteligentes cujas decisões não venham a resultar em erros que tragam prejuízos sensíveis a alguns cidadãos, ou que venham a violar preceitos éticos e/ou morais que permeiam aquela sociedade.
Os mecanismos cognitivos artificiais que estão despontando no cenário tecnológico ainda dependem da intervenção humana, e nem parece ser o objetivo almejado eliminar a supervisão humana. Seja pela complexidade das atividades urbanas, seu planejamento e administração, seja pela necessidade de manter a humanidade no controle daquilo que é de seu interesse, a gestão urbana requer pessoas com características específicas. Dessa forma, é necessário pensar no aparato tecnológico como um suporte sofisticado para orientar o planejamento estratégico e apoiar a observação e o controle do ambiente urbano, que continuará sob a gestão de pessoas específicas, geralmente eleitas para tal, com suporte de equipes com formação técnica altamente qualificada e preparadas para realizar a gestão usando essas novas tecnologias.
O uso das tecnologias, que são sistematicamente desenvolvidas para endereçar problemas correntes na sociedade, leva ao surgimento de novos problemas e desafios. Isso requer uma ação continuada e intensiva de diversos setores, desenvolvendo novas soluções e novas formas de atuação, para manter os progressos da sociedade. Uma questão fundamental é a da competência, da integridade e dos valores dos cidadãos eleitos para a gestão urbana, particularmente para gerenciarem todos os processos de atualização tecnológica. Não apenas essas pessoas, mas toda a comunidade a que irão servir devem poder ter meios eficientes e genuínos para apoiar suas iniciativas. Considera-se aqui a possibilidade tecnológica suportada pela ciência de dados para prover uma vasta gama de informações, apresentadas de maneira clara, objetiva e verdadeira, que sirvam para que as comunidades possam entender o que se passa no âmbito de suas cidades (propostas, planejamentos estratégicos, realizações, custos, avaliações sob diferentes métricas e critérios). Dashboards associados a sites e Apps podem manter tais informações atualizadas continuamente, sendo um painel de informações objetivas (reportando fatos). A esses se somam naturalmente outros meios para estimular e suportar discussões para contrapor opiniões, realizar debates, e assim servir para apoiar a população no acompanhamento das ações dos gestores urbanos, bem como para sustentar uma discussão política para novos pleitos e eleições.
Enfim, as novas tecnologias devem servir de apoio para o acompanhamento da realidade urbana, e das propostas que devam ser discutidas no âmbito de toda a comunidade, para que os caminhos tomados estejam de acordo com a vontade manifesta de seus habitantes. Os mecanismos tradicionais de eleições em sistemas democráticos (tipicamente quadrienais) têm esse propósito, mas são insuficientes e imprecisos, considerando a velocidade e o dinamismo das novas tecnologias.
A maior transparência das informações e ações (razões que embasaram as escolhas, os critérios usados para tal, os mecanismos que permitiram as decisões, como ocorre nas licitações) é fundamental para otimizar a gestão da municipalidade. A boa política deve ser estimulada, aquela em que opiniões divergentes são debatidas, mas cujo propósito deve ser o do bem-estar da coletividade. A má política deve ser reprimida, e nesse sentido novas tecnologias, devidamente ajustadas a esse propósito, podem servir como ingrediente facilitador para o acompanhamento dos fatos.
Este trabalho discute a incorporação de novas tecnologias na gestão das cidades, particularmente no contexto da computação cognitiva num ambiente urbano de caráter orgânico, avaliando suas potencialidades e limitações, bem como estimulando a reflexão sobre o desenrolar futuro nesse cenário. Todas essas novas tecnologias vão impactar decisivamente não somente a infraestrutura urbana, mas também todas as relações sociais dentro desse ambiente.
O objetivo aqui não é propor explicitamente soluções para as cidades, e de fato nem mesmo há como fazê-lo pela diversidade de caminhos para isso, mas promover uma discussão e reflexão sobre o impacto dessas novas tecnologias nas atividades e manifestações humanas. Nesse sentido, duas perspectivas importantes: o dia a dia e o planejamento estratégico.
No contexto urbano, os cidadãos deverão ter a sua disposição aparatos (especialmente smartphones) com contínuo aperfeiçoamento, e para os quais novos Apps continuarão a surgir. Há aqui um cenário que se apresenta como autossustentável, em que a possibilidade de acompanhar fatos e de interagir com o meio interfere no que vier a ocorrer. Um bom exemplo são aplicativos de trânsito que servem para acompanhar a tráfego urbano e orientar os motoristas nos melhores caminhos a serem seguidos a cada momento. Ou seja, são sistemas de caráter instantâneo de acompanhamento dos fatos e de intervenção no sistema na medida em que determinam (ou sugerem) os caminhos a serem seguidos. Com isso, propiciam um autoajuste do tráfego urbano às condições existentes a cada momento, ajudando a melhor distribuí-lo, reduzindo assim em média os tempos de viagem.
Não deve ser esperado que os sistemas autoajustados apresentem eficiência plena em quaisquer situações, de modo que intervenções são certamente necessárias. O gestor urbano deve intervir, orientando o comportamento da dinâmica urbana, de acordo com planejamentos estratégicos (médio e longo prazos), bem como monitorando e controlando a operação do sistema. Nesse contexto, e aproveitando o exemplo anterior (aplicativos de apoio aos motoristas), cabe à municipalidade a gestão da orientação do tráfego urbano, por exemplo mediante ajustes on-line nos planos semafóricos, ou de adequação dinâmica da malha viária para melhor atender ao fluxo em diferentes períodos ao longo do dia. E ambos devem se beneficiar das tecnologias inteligentes de suporte disponíveis.
Ainda nesse caso, é possível afirmar que a superposição de duas estratégias parece ser a que leva aos melhores resultados. Por um lado, ferramentas de inteligência computacional são capazes de entender a dinâmica urbana (tráfego, por exemplo) e se antecipar realizando ações corretivas com bases nas previsões feitas. As atuais ferramentas de deep learning permitem um conhecimento profundo da natureza dessas questões, algo associado a uma assinatura que bem representa o objeto tratado. Por outro lado, é possível superpor a essas decisões ajustes instantâneos resultantes de observações em tempo real de situações imprevisíveis, como acidentes, ou impactos de eventos meteorológicos.
De forma equivalente, é possível identificar que, qualquer que seja a dimensão do assunto em questão, ela passa pela participação e envolvimento dos cidadãos, atores no cenário urbano, e como tal contribuindo com as diretrizes e estratégias da evolução urbana. Essa componente tem um aspecto naturalmente bottom-up e que, portanto, tem que ser considerada no conjunto. As tecnologias cognitivas nesse sentido servem para perceber a manifestação dos habitantes e apoiar ou auxiliar nas suas ações, respeitando suas posições e opiniões individuais, de modo a tornar mais claro o anseio coletivo, ao qual deve dar ampla divulgação. E cabe aos gestores da municipalidade, com apoio de outras ferramentas cognitivas e de manipulação de dados, IoT e ciência de dados oferecer a cidade orientações com caráter top-down.
O estabelecimento das cidades cognitivas é um processo em andamento globalmente, com muitos exemplos de implementações de sucesso para diversas funções urbanas. Entretanto, questões envolvendo essas tecnologias continuam a permear toda a sua implementação, e o sucesso dessas tecnologias depende de uma atenção apropriada a tais questões. Vários temas merecem uma reflexão:
As tecnologias devem estar a serviço do ser humano, de modo que o caráter cognitivo das cidades deve estar inserido neste propósito. Deve ser capaz de auxiliar as pessoas, orientando-as, mas também levando em consideração suas opiniões.
A democratização tecnológica deve ser promovida e não inibida. As cidades cognitivas devem corresponder a este anseio, mas há o risco da segregação tecnológica com impacto na diferenciação social. Dessa forma, é importante que as tecnologias urbanas estejam à disposição de todos, sendo acessíveis, tanto do ponto de vista dos custos para o cidadão, como da disponibilização da infraestrutura. Portanto, cabe aos governos municipais desenvolver políticas públicas inclusivas e implantar infraestruturas cuja cobertura se estenda por toda a área urbana. Além disso, cabe à municipalidade, em parceria com empresas de tecnologia do setor privado, criar mecanismos facilitadores para o acesso aos serviços e dispositivos digitais, a custos acessíveis, combatendo, desta forma, a exclusão tecnológica.
Toda tecnologia tem por propósito superar desafios correntes. Mas como sempre na história da humanidade novas tecnologias geram mecanismos irreversíveis. Novas tecnologias, ao resolverem alguns problemas, geram novos problemas e desafios que devem ser, na medida do possível, antecipados e mitigados. Por outro lado, não há como identificar os caminhos decorrentes das novas tecnologias. Novos problemas surgirão e terão que ser tratados.
Otimismo e competitividade são fatores marcantes da humanidade, e devem ser explorados a favor do desenvolvimento tecnológico, reconhecendo que se por um lado as pessoas têm a tendência de aceitar e incorporar as boas novidades, elas também têm que aprender a lidar com as consequências advindas desse processo. O principal meio para prover acesso a todos e condição de uso eficiente das tecnologias é dar a todas as pessoas uma melhor educação, que garanta a todos a competência para poder continuar aprendendo e se adaptando a um mundo cada vez mais tecnológico e virtual.
Em contrapartida, a tecnologia não pode ser percebida de forma messiânica, como algo capaz de resolver todos os problemas.
A tecnologia não pode servir a um desgoverno, onde a naturalidade de um serviço automático e ubíquo leve as pessoas a acreditarem que tudo está sob controle. É necessário evitar a situação em que se tenha a falsa percepção de que os governos se tornam desnecessários, sendo substituídos por uma gerência baseada estritamente na tecnologia, quando passaria a haver uma ditadura tecnológica.
Os sistemas cognitivos urbanos, na medida do possível, devem ser capazes de realizar autoajustes para sua própria preservação, de modo a se adaptar à natural alteração e evolução do cenário urbano, bem como à sua condição altamente dinâmica. E, dessa forma, manter sua capacidade de prestação dos serviços para os quais tenham sido concebidos.
O ser humano deverá estar sempre no comando, de modo a poder acompanhar e gerenciar as tarefas executas pelos sistemas de apoio computacional da cidade cognitiva, intervindo sempre que necessário, seja para reparos pontuais, seja para substituição de uma tecnologia por outra que venha a sucedê-la por se mostrar melhor, mais avançada ou mais eficiente.
A obsolescência é parte desse processo. Sistemas artificiais construídos pelo homem tendem a se tornar obsoletos, ou seja, inadequados às demandas. Atualmente, em face das importantes questões de sustentabilidade, as tecnologias devem, ao ser concebidas e implantadas, prever qual a expectativa de seu tempo de vida, e que mecanismos irão oferecer para ser mais facilmente descartadas ou reintegradas, de modo a mitigar o impacto que possam ter no mundo físico. Ou seja, a sociedade deve ter uma postura que exija que os aspectos de sustentabilidade estejam sempre sendo considerados e respeitados, e o governo e as empresas devem se empenhar para garantir isso.
Sistemas artificiais podem apresentar defeitos, em decorrência da sua obsolescência, ou de falhas no seu projeto. A engenharia trata dessas questões procurando minimizar os problemas que possam advir desse fato, e isso vale para as cidades cognitivas.
As cidades cognitivas são unidades em que o sistema de amparo computacional opera em prol da cidade. É necessário considerar, como em organismos vivos, a interação entre as cidades, ainda que limitada a alguns fatores. As pessoas se deslocam entre diferentes cidades, veículos trafegam de uma para outra, de modo que uma compatibilidade entre elas, ao menos em alguns aspectos, é necessária, devendo ser procurada e implantada. Embora o desenvolvimento de cada cidade seja único, deve-se na medida do possível seguir padrões definidos para interoperabilidade desses sistemas. Por exemplo, um veículo ao estacionar numa vaga pública deve ser automaticamente reconhecido para a cobrança do serviço, evitando que seja necessária a aquisição ou uso de sistemas específicos em cada cidade. Isso também vale na questão da inteligência que progressivamente será atribuída aos veículos, permitindo um trânsito mais seguro e eficiente. Os mecanismos usados devem transcender as cidades, tendo validade nacional ou mesmo global.
Deve-se procurar harmonizar possibilidades de integração entre os modelos distribuídos (nas mãos dos usuários finais) e centralizados (sob controle das administrações municipais) de modo a explorar o melhor que cada um possa oferecer. Cabe lembrar que pela natureza orgânica e dinâmica dos sistemas urbanos, não será possível, e nem mesmo conveniente propor sistemas fechados, proprietários, e que não permitam interlocuções entre seus diversos componentes.
Finalmente, cabe ressaltar a frase expressa por Willian Bruce Cameron (1967) a respeito da relação entre dados e sociedade: “nem tudo que importa é representado por dados, e nem tudo que é representado por dados importa”. Embora tenha havido desde então um enorme avanço na capacidade de coleta e tratamento de dados, o conceito persiste. Há que reconhecer os limites da capacidade de observação e controle que podemos esperar de uma cidade cognitiva, bem como de qualquer sistema de grandes dimensões e complexidade. Nem todos os aspectos urbanos podem (e nem sequer precisam ou devem) ser observados ou controlados. Há, portanto, uma limitação inerente ao caráter mental da cidade cognitiva, que não permite (e nem deve permitir) a ela ter todo o controle sobre seu lado corporal, aquele que sempre existiu, e que continuará existindo, afinal as cidades são o corpo, a infraestrutura física. A mente vem se tornando e deverá ser cada vez mais poderosa como um apoio para o melhor funcionamento deste corpo, com o que, se espera, seus habitantes possam desfrutar de melhores condições de vida, o meio ambiente possa ser mais bem preservado, o espaço urbano possa ser mais resiliente, agradável e seguro, enfim, o futuro urbano possa ser mais promissor.
Há também que se ter cuidado com abusos e exageros (Anthoupoulos, 2017). A fácil disponibilidade de dados e informações leva a sociedade a ser cada vez mais dependente tanto do seu consumo como de sua produção, numa espiral que possa consumir além do que seja plausível. Tanto a geração como o uso da informação são altamente recomendáveis e trazem benefícios evidentes, mas não é necessário saber tudo a respeito de qualquer coisa. Na sociedade moderna, cujas tecnologias propiciam isso a um custo mínimo e em volumes estratosféricos, o benefício do acesso à informação pode facilmente passar a ser um problema em si mesmo, na medida em que os cidadãos fiquem presos à necessidade de se manterem constantemente informados sobre tudo. Isso tem sido observado no uso dos smartphones. E deve servir de lição para que não se almeje construir sistemas cognitivos de apoio ao ambiente urbano que procurem observá-lo e controlá-lo além do necessário. Esse sistema será incompleto e inconsistente, mas servirá para propiciar uma vida melhor àqueles a que servir.
Diversos elementos ainda precisam ser superados para que cidades cognitivas se tornem realidade, por exemplo questões éticas, como a privacidade e individualidade de cada cidadão, e as ferramentas de tomada de decisão e arbitragem, principalmente em situações conflitivas entre diferentes grupos sociais (Van Zoonen, 2016).","['AHUJA K.; KHOSLA, A. Driving the Development, Management, and Sustainability of Cognitive Cities. Practice, Progress and Proficiency in Sustainability Book Series, 2019.', 'ALBINO, V.; BERARDI, U.; DANGELICO, R. M. Smart Cities: Definitions, Dimensions, Performance and Initiatives. Journal of Urban Technology, v.22, n.1, p 3-21, 2015.', 'ANTHOUPOULOS, L. Understanding Smart Cities: A tool for smart government or an industrial trick? S. l.: Springer International, 2017.', 'APPIO, F. P.; LIMA, M.; PAROUTIS, S. Understanding Smart Cities: Innovation ecosystems, technological advancements, and societal challenges. Technological Forecasting and Social Change, v.142, p.1-14, 2019.', 'BIBRI, S. E. The IoT for smart sustainable cities of the future: An analytical framework for sensor-based big data applications for environmental sustainability. Sustainable Cities And Society, v.38, p.230-53, 2018.', 'BIJKER, W. E.; HUGHES, T. P.; PINCH, T. The social constructions of technological systems. Cambridge: The MIT Press, 2nd edition, 2012.', 'CAMERON, W. B. Informal Sociology: A Casual Introduction to Sociological Thinking. New York: Rabon House, 1967.', 'CHILDE, V. G. The Urban Revolution. Tow Planning Review, v.21, n.1, p.3-17, 1950.', 'DA FONSECA, A. C. P.; MOTA, C. G. Fim das Utopias? A cidade de São Paulo e a discussão do urbanismo contemporâneo. Estudos Avançados, v.33, n.95, p.191-202, 2019.', 'D’ONOFRIO, S.; PORTMANN, E. Cognitive Computing in Smart Cities. Informatik Spektrum, v.40, p.46-57, 2017.', 'FAN, S. “What Does Ethical AI Look Like? Here’s What the New Global Consensus Says”, 2019. [Online]. Disponível em: < https://singularityhub.com/2019/09/10/what-does-ethical-ai-look-like-theres-now-a-global-consensus/>.\n» https://singularityhub.com/2019/09/10/what-does-ethical-ai-look-like-theres-now-a-global-consensus', 'GLASSNER, A. Deep Learning: from basics to practice. S. l.: Imaginary Institute, 2019a. v.1.', '_______. Deep Learning: From Basics to Practice. S. l.: Imaginary Institute, 2019b. v.2.', 'HALEGOUA, G. Smart Cities. Cambridge: The MIT Press, 2020.', 'HURWITZ, J. S.; KAUFMANN M.; BOWLES, A. Cognitive Computing and Big Data Analytics. S. l.: Wiley, 2015.', 'KOTHKIN, J. The City: A Global History. S. l.: Modern Library, 2005.', 'LECUN, Y.; BENGIO, Y.; HINTON, G. Deep Learning. Nature, v.521, p.436-44, 2015.', 'LIM, C.; KIM, K. J.; MAGLIO, P. P. Smart cities with big data: Reference models, challenges, and considerations. Cities, v.82, p.86-99, 2018.', 'MALONE, T. W.; BERNSTEIN, M. S. Handboolk of Collective Intelligence. Cambridge: The MIT Press, 2015.', 'NETTO, M. L. Computação Evolutiva e Cognitiva - Simulação em Vida Artificial e Cognição. São Paulo, 2007. Tese (Livre Docência em Engenharia Elétrica) - Escola Politécnica, Universidade de São Paulo.', 'O’FLAHERTY, B. City Economics. Cambridge: Harvard University Press, 2005.', 'PORTMANN, E.; TABACCHI, M. E.; HABENSTEIN, A. (Ed.) Designing Cognitive Cities. S. l.: Springer, 2018.', 'RUHLANDT, R. W. S. The governance of smart cities: A systematic literature review. Cities, v.81, p.1-23, 2018.', 'SEJNOWSKI, T. J. The Deep Learning Revolution. Cambridge: The MIT Press, 2018.', 'TOWNSEND, A. M. Smart Cities: Big Data, Civic Hackers and the Quest for a New Utopia. New York: WW Norton, 2013.', 'VAN ZOONEN, L. Privacy concerns in smart cities. Government Information Quarterly, v.33, n.3, p.472-80, 2016.', 'VERNON, D. Artificial Cognitive Systems - A Prime. Cambridge: The MIT Press, 2014.', 'WEBB, R. The Urban Organism. Nature, v.446, p.869, 2007.', 'WILLIAMS, R.; EDGE, D. The Social Shaping of Technology. Research Policy, v.25, n.6, p. 865-99, 1996.']","['Publicação nesta coleção\n23 Out 2023', 'Data do Fascículo\nSep-Dec 2023']","[' MARCIO LOBO NETTO', ' JOÃO FRANCISCO JUSTO ']","['Universidade de São Paulo, Escola Politécnica, São Paulo, São Paulo, Brasil. marcio.netto@usp.br; joao.justo001@gmail.com ', 'Universidade de São Paulo, Escola Politécnica, São Paulo, São Paulo, Brasil. marcio.netto@usp.br; joao.justo001@gmail.com ']",http://www.scielo.br/scielo.php?script=sci_arttext&pid=S0103-40142023000300345&lang=pt,2024-11-21 09:59:31.233883,Scielo.org
Segurança alimentar: reflexões sobre um problema complexo,"O combate à má alimentação em todas as suas formas, que também se expressa na epidemia da obesidade, é uma das prioridades da Agenda 2030 e dos Objetivos de Desenvolvimento Sustentável. Este artigo traz elementos sobre insegurança alimentar no Brasil, a partir de temas relativos ao crescimento populacional, mudanças climáticas, biodiversidade e sistemas alimentares tradicionais e regenerativos; trata também do papel dos movimentos sociais para a garantia do Direito Humano à Alimentação Adequada. O Grupo de Pesquisa em Nutrição e Pobreza, o Saúde Planetária Brasil, e o Centro de Inteligência Artificial (C4AI) - Eixo AgriBio, entendem que a retomada organizada e sistêmica das frentes apontadas neste artigo de posicionamento, pode constituir um caminho para a articulação entre pesquisa, serviço e políticas públicas na direção do combate à fome e às demais manifestações da má alimentação, enquanto problema complexo prioritário para a garantia do bem-estar social.","A maneira pela qual a sociedade produz e consome alimentos tem profundo impacto na saúde das populações, nas relações sociais e no meio ambiente. A existência da fome no século XXI revela o abismo entre riqueza e conhecimento, de um lado, e desigualdade, de outro. Devemos experimentar, globalmente, um crescimento populacional da ordem de 2 bilhões de pessoas nos próximos 40 anos, o que amplia o desafio em produzir e distribuir melhor os alimentos (Vollset et al., 2020
).
Em meio à epidemia de obesidade e excesso de peso, países em desenvolvimento enfrentam a fome e a desnutrição; a concomitância destas condições caracteriza o que se conhece por múltipla carga de doenças, que afeta especialmente as populações mais pobres (Buoncristiano et al., 2021
).
No Brasil, que deixou o mapa da fome em 2014 ao exibir queda da prevalência de insegurança alimentar de 34,9% das famílias em 2004 para 22,6% em 2013, é alarmante chegar a 2022 com 58,7% nesta condição, ou seja 125,2 milhões de pessoas (Rede Penssan, 2022). Apesar de contraditório, 38% das famílias de agricultores/as e produtores/as rurais de alimentos estão em situação de insegurança alimentar. De acordo com o 2º Inquérito Nacional sobre Insegurança Alimentar no Contexto da Pandemia da Covid-19 (II Vigisan), “a agricultura familiar sofreu o impacto da crise econômica, mas foi especialmente afetada pelo desmonte das políticas públicas voltadas para o pequeno produtor do campo” (Rede Penssan, 2022, p.41).
Diante desses números, muitos são os desafios de desenvolvimento enfrentados no Brasil e no mundo. De fato, o cenário de fome e desnutrição vem sendo discutido em âmbito global há diversas décadas e foi incluído entre as prioridades da Agenda 2030 da ONU por 193 Estados-membros, inclusive o Brasil. Os 17 Objetivos do Desenvolvimento Sustentável (ODS), e suas 169 metas globais traduzem aspirações fundamentais para a preservação da vida e para o desenvolvimento humano pleno; nesse sentido, favorecem a tomada de decisão por parte do poder público e da sociedade civil, na direção da defesa do ambiente, da diminuição das desigualdades sociais, da sustentabilidade e do fortalecimento dos mecanismos de proteção social.
Embora a garantia da alimentação adequada e saudável dependa da consecução de muitas destas metas, o ODS 1 - Erradicação da Pobreza, o ODS2 - Fome Zero e Agricultura Sustentável, e o ODS 10 - Redução das Desigualdades, estabelecem clara relação com a Segurança Alimentar e Nutricional (SAN)1
no Brasil contemporâneo.
Assim, o desenho de uma abordagem resolutiva implica articulação intersetorial que considere os determinantes sociais da fome, e um diagnóstico acerca dos recursos e ações possíveis, para ação imediata, mas também em médio e longo prazos (Burigo Porto, 2021
) para promover desenvolvimento e distribuição de riqueza, ao lado de promover acesso à alimentação.
Um conjunto de ações no início do século contribuiu para que os compromissos assumidos pelo país, tanto internamente quanto em âmbito internacional, tenham resultado em diminuição da pobreza e da fome; a experiência acumulada na construção destas condições reúne informação e conhecimento, a serviço de um projeto de gestão pública voltado para o bem-estar social.
Este artigo traz elementos que podem contribuir para a análise do cenário atual sobre a insegurança alimentar no Brasil, a partir dos estudos sobre o tema no âmbito dos Grupos de Pesquisa Nutrição e Pobreza, e Saúde Planetária Brasil (ambos do IEA/USP), e do Centro para Inteligência Artificial - Eixo AgriBio (C4AI-AgriBio). Dessa forma, expomos desafios e potencialidades dos movimentos sociais, da agricultura familiar e de sistemas alimentares resilientes, de políticas públicas de apoio à SAN, assim como a ameaça do dominante sistema de produção de alimentos. Trazemos ainda considerações sobre como a tecnologia da informação pode contribuir para o entendimento e o apoio à solução desses desafios, que dependem de dados.
A conectividade internacional dos sistemas de produção e consumo de alimentos tem sido evidenciada recentemente pelos desafios colocados com a pandemia global de Covid-19 e a guerra na Ucrânia. Cadeias globais de produção de alimentos e insumos agrícolas foram afetados, com consequente crescimento da fome e da insegurança alimentar pelo mundo e, especificamente, no Brasil (FAO et al., 2022; Rede Penssan, 2022). Duas outras questões globais tornam ainda mais desafiantes as conexões entre produção e consumo de alimentos no Brasil: a demografia e o clima.
O cenário médio projetado pela Divisão de População da ONU em 2022 aponta algumas tendências: saltaremos dos quase 8 bilhões de pessoas atualmente para cerca de 9,7 bilhões em 2050, e 10,4 bilhões em 2100, com a maior parte desse crescimento até 2050 sendo concentrado na África Subsaariana; outra tendência relevante mostra que crescerá a percentagem de pessoas com mais de 65 anos (United Nations, 2022). Enquanto o mundo ainda enfrenta desafios para combater a fome e insegurança alimentar, a tendência demográfica global nos impõe ao desafio de aumentar a produção de alimentos para, nos próximos anos, garantir o consumo de mais 2 bilhões de habitantes; boa parte deste crescimento populacional ocorrerá em regiões que têm enfrentado dificuldades históricas para alimentar sua população, o que colocará pressão sobre os sistemas alimentares globais.
Além disso, com o aumento da expectativa de vida global e a diminuição da taxa de crescimento vegetativo, cresce a demanda por recursos para o setor saúde e diminui a parcela de trabalhadores da sociedade, colocando mais pressão sobre a produção, o que é especialmente relevante para o Brasil. A população brasileira, hoje próxima aos 215 milhões, deve crescer até por volta de 2050, chegando aos 231 milhões por volta de 2050 e caindo para 185 milhões em 2100 (IBGE, 2022). Mesmo que a variação populacional brasileira não seja tão grande como a de outros países, a mudança do perfil etário é bastante significativa e trará desafios para o sistema alimentar e produtivo como um todo: atualmente, quase 10% dos brasileiros têm mais de 65 anos, segundo o cenário médio da Divisão de População da ONU, em 2050 serão 21,9% da população total, e em 2100 serão 33,5% (United Nations, 2022).
As mudanças climáticas aumentam ainda mais o desafio da segurança alimentar. Segundo o relatório mais recente do Painel Intergovernamental de Mudanças Climáticas (IPCC) (Masson-Delmotte et al., 2022), caso a emissão de gases de efeito estufa continue nos níveis atuais, atingiremos antes de 2030 o aumento de temperatura de 1,5 ºC comparado aos níveis pré-industriais, e 2 °C antes de 2050. Esse aumento de temperatura traz consequências indeléveis para a produção de alimentos, afetando produtividade, área cultivada, presença de pragas, preços e oferta, gerando implicações negativas não apenas para a segurança alimentar, mas também para a erradicação da pobreza e da desigualdade, e esses efeitos já vem sendo sentidos, dado que já temos um aumento entre 1,1 e 1,2 °C (Alpino et al., 2022
; Masson-Delmotte et al., 2022; Shukla et al., 2022
). O tema foi objeto de acordo na forma de um plano de quatro anos para agricultura e Segurança Alimentar pactuado no Painel Intergovernamental sobre Mudanças Climáticas ocorrido na COP 27 em 2022, a fim de garantir as metas previamente estabelecidas pela ONU para 2030. Denominado FAST - Food and Agriculture for Sustainable Transformation Initiative, o pacto tem como objetivo central “implementar ações concretas que possam resultar em melhoria da quantidade e da qualidade das contribuições financeiras voltadas ao clima para transformar a agricultura e os sistemas alimentares até 2030”.2
Os signatários “reconhecem a prioridade fundamental de garantir a segurança alimentar e eliminar a fome, bem como as vulnerabilidades dos sistemas alimentares às mudanças climáticas”. A mudança na temperatura gera aumento de eventos climáticos extremos como ondas de calor, secas, inundações, entre outros. Há aumento no estresse hídrico das plantas e até mudanças na composição do solo, afetando gravemente a produção de cereais essenciais para a segurança alimentar global, como o trigo, milho e arroz. O calor ainda afeta os ecossistemas marinhos, com a previsão de perda de 1,5 milhões de toneladas de alimentos provenientes do oceano com aumento de 1,5 °C, e de 3 milhões de toneladas com aquecimento de 2 °C (Masson-Delmotte et al., 2022). Para além das questões de disponibilidade de alimentos, a desestabilização de sistemas alimentares causada por mudanças climáticas pode gerar crises econômicas graves que aumentam a insegurança alimentar, cenário para o qual o Brasil é extremamente vulnerável: segundo o Cepea-Esalq/USP toda a cadeia de produção, serviços, indústria e insumos da agricultura e pecuária representou 27,6% do PIB brasileiro em 2021 (CENTRO DE ESTUDOS..., 2022), e sua desestabilização impulsiona desemprego, perda de renda e inflação no preço dos alimentos, aumentando a insegurança alimentar.
Ao mesmo tempo que a produção de alimentos é imensamente afetada pelas mudanças climáticas, é forçoso reconhecer também o caráter fundamental desta como causadora. O Brasil é o quinto maior emissor de gases de efeito estufa do mundo segundo o Observatório do Clima, e entre as emissões de 2020, 27% foram provenientes da agropecuária (sendo 75% desse valor gerados pela produção bovina), e outros 46% por mudanças no uso de terra e florestas, em especial, desmatamento e conversão de áreas naturais em lavouras e pastagens (Potenza et al., 2021). São 60 milhões de hectares de vegetação nativa convertidos em pastagem no Brasil nos últimos 30 anos (Mapbiomas, 2022), resultando em enorme quantidade de gases de efeito estufa liberados na atmosfera, e colocando o sistema de produção de alimentos no Brasil no centro da questão climática nacional e global.
A primeira Conferência Nacional de SAN, ocorrida em 1994, recuperou a propositura do termo “Segurança Alimentar e Nutricional” estabelecida no Plano Nacional de mesmo nome, elaborado em 1985 e não implementado. Resultado de diversas ações nascidas no âmbito das organizações sociais e universidades, a Política Nacional de Alimentação, em 1999, acompanha a Cúpula Mundial de Alimentação, realizada em 1996, e pavimenta o caminho para a promulgação da Lei Orgânica de Segurança Alimentar e Nutricional em 2006, e a inclusão do Direito Humano à Alimentação Adequada na Constituição Federal, em 2010.
Movimentos sociais, como o Movimento dos Trabalhadores Rurais Sem Terra (MST) e o Movimento dos Pequenos Agricultores (MPA), contribuem para a efetivação do Direito Humano à Alimentação Adequada (DHAA), por meio da produção e da facilitação de acesso a alimentos saudáveis com baixo impacto ambiental para nossa população, além de promover a resiliência no campo e justiça alimentar.
O MST, criado em 1984 em Cascavel (PR), está presente em 24 estados brasileiros, sendo composto por 450 mil famílias assentadas e cerca de 90 mil famílias acampadas. Essas famílias estão organizadas por meio da agricultura familiar camponesa atuando em 1.900 associações comunitárias, 160 cooperativas e 120 agroindústrias (Motoryn, 2022
).
Em seu Congresso Nacional de 2007, o MST fez a opção pela produção agroecológica de alimentos em todos seus assentamentos, em contraponto à agricultura convencional (Movimento dos Trabalhadores... 2007 MST, 2022). A agroecologia pressupõe a produção de alimentos sem o uso de agrotóxicos, proporcionando uma interação entre o ser humano e o meio ambiente pelas vias sustentáveis de produção, além do respeito aos saberes tradicionais. Também são exemplos de aplicação da agroecologia o reflorestamento, a recuperação de nascentes, o cultivo de sementes não transgênicas e a prática de cultivar diversas lavouras em um mesmo terreno, conhecida como policultura, o que possibilita a devolução de nutrientes variados para a terra (Oliveira, 2022
).
Segundo a Política Nacional de Agroecologia e Produção Orgânica (Pnapo), agroecologia, ou produção de base agroecológica, é:
[...] aquela que busca otimizar a integração entre capacidade produtiva, uso e conservação da biodiversidade e dos demais recursos naturais, equilíbrio ecológico, eficiência econômica e justiça social, abrangida ou não pelos mecanismos de controle de que trata a Lei nº 10.831, de 2003, e sua regulamentação. (Brasil, 2012, online)
Desde o início da pandemia por Covid-19, o MST já doou mais de 4,2 mil toneladas de alimentos e cerca de 860 mil marmitas para pessoas em vulnerabilidade social (Motta, 2021
).
De acordo com o Censo Agropecuário 2017, o Brasil conta com 5.073.324 estabelecimentos rurais, que ocupam uma área total de 351.289.816 ha. Em relação à utilização das terras, comparando com o Censo Agropecuário anterior, de 2006, percebe-se uma redução de 34% da área utilizada para lavouras permanentes e um acréscimo de 14% daquela destinada a lavouras temporárias. Houve também redução de 18% da área de pastagens naturais, e crescimento de 10% da área utilizada para pastagens plantadas. O Censo Agropecuário 2017 mostrou, ainda, elevação da quantidade de hectares destinados a matas naturais e plantadas, cujos percentuais foram, respectivamente, de 12% e 83%. Em relação à área, há 4,5 milhões estabelecimentos destinados à produção agropecuária no país com menos de 100 ha, cerca de 89% do total; estes ocupam uma área de 71.804.615 ha, que corresponde a aproximadamente 20% das terras cultivadas (IBGE, 2019).
O Censo de 2017 apontava a existência de 3,9 milhões de unidades de produção da Agricultura Familiar (AF), nas quais a gestão da propriedade é compartilhada pela família e a atividade produtiva agropecuária é a principal fonte geradora de renda. São cerca de 77% do total de estabelecimentos rurais, que correspondem a 23% da área de todos os estabelecimentos agropecuários do país (80,9 milhões de ha). Em termos de valor da produção, este segmento equivale a 23% de toda a produção agropecuária brasileira, cerca de R$ 107 bilhões, empregando 67% do pessoal ocupado no setor, em torno de 10,1 milhões de pessoas (IBGE, 2019).
Quando analisados os dados relativos aos tipos de produção, destaca-se o importante papel da agricultura familiar na produção de alimentos consumidos pelos brasileiros. Se considerarmos as lavouras temporárias, os agricultores familiares produzem, em relação ao total consumido: 67% do abacaxi, 58% da abóbora, 58% da cebola, 42% do feijão preto, 56% do feijão verde e 70% da mandioca. Já nas lavouras permanentes, a agricultura familiar é a grande responsável pela produção de 35% do café arábica, 50% do café conilon, 49% da banana, 66% do caju, 36% do limão, 49% da tangerina, 58% da acerola, 79% do açaí, 73% do maracujá, 31% da uva de mesa e 46% da goiaba, dentre outros (Mitidiero Jr., 2022).
Por outro lado, quando se considera a produção de hortícolas, as pequenas propriedades até 10 ha praticamente dominam a produção, sendo responsáveis por 53% de toda a abobrinha produzida no país, bem como 62% da alface, 32% da batata-doce, 53% da berinjela, 47% do brócolis, 62% da couve-flor, 49% do pimentão, 37% do repolho, 27% do tomate estaqueado (de mesa) e 64% da vagem (ibidem).
O Brasil está entre os dez países com a maior área cultivada do planeta (Miranda, 2018
). Essa extensa área agrícola produz alimentos para grande parte da população mundial, abastecendo diversos mercados no exterior, além do mercado interno brasileiro. Em 2020, o Brasil foi o quarto maior exportador de grãos e o maior exportador de carne bovina do mundo (Embrapa, 2021).
Para atender ao crescimento populacional, da ordem de 3,7 bilhões de pessoas nos anos 1970 para mais de 7 bilhões (United Nations, 2014) a produção mundial de alimentos dobrou (Faostat, 2014). Esse panorama de produção agrícola está associado ao uso da terra e juntos são os principais responsáveis pelo desmatamento e pela perda de biodiversidade.
Esses dados comprovam a importância da agricultura familiar para a produção de alimentos, dado que respondem pela maior parte da produção destinada ao consumo humano interno e empregam a maior massa de trabalhadores, mesmo ocupando um quarto da área atualmente destinada à agropecuária. Paradoxalmente, o financiamento público destinado ao setor distribui recursos de forma desigual: o crédito para médios e grandes produtores, cuja produção é majoritariamente destinada ao mercado de commodities, chega a ser superior em seis vezes àquele destinado ao agricultor familiar, segundo dados de 2017-2020 (Proença et al., 2021
). Esses dados revelam uma opção voltada para a exploração dos recursos naturais do país com foco no mercado internacional, e não nas demandas internas por alimento.
O estabelecimento dos preços dos alimentos, regulado exclusivamente pelo mercado, é outro importante aspecto e merece revisão. Especialmente para os itens básicos da cesta de consumo, medidas fiscais e o estabelecimento de estoques reguladores são potentes moduladores de acesso. A produção de alimentos da AF e por parte de movimentos sociais como os aqui mencionados oferece uma oportunidade para a otimização de financiamentos e fortalecimento de cadeias de valor voltadas à SAN.3
O Brasil é um dos maiores consumidores de agroquímicos e agrotóxicos do planeta. Em 2015, uma pesquisa feita pela ONG Campanha Permanente Contra os Agrotóxicos e Pela Vida em parceria com a Associação Brasileira de Saúde Coletiva (Abrasco) mostrou que o consumo brasileiro era de 7,6 litros por pessoa (Grigori, 2019
).
O país encerrou o ano de 2021 com 562 agrotóxicos registrados, um aumento de 14% em relação ao ano anterior, um recorde histórico desde o ano de 2000, quando a série histórica iniciou. Dados do Ministério da Agricultura, Pecuária e Abastecimento (Mapa) mostram um aumento no número de registros a partir de 2016 e uma intensificação ainda maior nos anos seguintes: em 2015 foram registrados 139 pesticidas, em 2016 foram 277, em 2018 foram registrados 449, 2019 foram 474 e 2020 foram 493 novos registros (Salati, 2022
).
O processo de aprovação de um pesticida para comercialização e uso no Brasil é regulamentado pela Lei n.7.802/1989, conhecida como Lei dos Agrotóxicos (Brasil, 1989), que regulamenta desde a pesquisa até a fiscalização do uso do produto final. A regulamentação é conduzida pela Agência Nacional de Vigilância Sanitária (Anvisa), o Instituto Brasileiro do Meio Ambiente e dos Recursos Naturais Renováveis (Ibama) e o Ministério da Agricultura, Pecuária e Abastecimento (Mapa).
Em fevereiro de 2022, a Câmara Federal aprovou o Projeto de Lei n.6.299/2002 que visa substituir a Lei dos Agrotóxicos (Brasil, 2002), e que foi enviado para apreciação pelo Senado Federal, o que não havia ocorrido até o fechamento deste texto (janeiro de 2023).
Em manifesto contrário a esse Projeto de Lei, a Sociedade Brasileira para o Progresso da Ciência (SBPC) aponta que ele modifica o sistema de registro de agrotóxicos, retira poder da Anvisa e Ibama, e traça novas regras sobre a pesquisa, experimentação, produção, rotulagem, transporte, armazenamento, comercialização, utilização, importação e exportação, assim como, o destino final dos resíduos e das embalagens de agrotóxicos no Brasil (SBPC, 2022, p.1). E continua dizendo que
[...] entre os aspectos que tornam seu conteúdo altamente preocupante, estão o afrouxamento das exigências e prazos impostos pelos órgãos governamentais competentes na análise do uso destes agrotóxicos. Também suaviza a utilização de nomenclatura que deixa clara à população a reconhecida toxicidade e ecotoxicidade destes compostos. Além disso, centraliza as tarefas de análise, aprovação e fiscalização destes produtos no Ministério de Agricultura, Pecuária e Abastecimento (Mapa), excluindo o poder decisório dos órgãos governamentais de saúde e meio ambiente, como a Anvisa e o Ibama.
A análise da SBPC sublinha diversos elementos do PL n.6.299/2002 que contribuirão, caso sejam ratificados, para a fragilização dos sistemas alimentares e para o comprometimento da qualidade dos alimentos, tais como:
ausência de critérios claros para a aprovação ou proibição de registro de agrotóxicos
comprometimento da aceitação dos produtos nacionais no mercado internacional
esvazia a participação da sociedade ao privar instituições, como de defesa do consumidor por exemplo, de pedirem impugnação ou cancelamento de registro de produtos com reconhecido risco
alteração da denominação “agrotóxico” para “Produto de controle ambiental” quando usado em florestas, ou pesticida
possibilidade de uso de agrotóxico não registrado caso o pedido não seja analisado de forma conclusiva em dois anos.
Os integrantes do Grupo de Trabalho (GT) Agrotóxicos e Saúde da Fiocruz afirmam, entre outras coisas, que a proposta trará “prejuízos para o ambiente e à saúde da população” e “danos irreparáveis aos processos de registro, monitoramento e controle de riscos e dos perigos dos agrotóxicos no Brasil” (Sampaio, 2022
).
De acordo com a ONU, os pesticidas são responsáveis por cerca de 200 mil mortes por envenenamento agudo a cada ano, 99% das quais ocorrem em países em desenvolvimento, onde as regulamentações de saúde, segurança e meio ambiente são frágeis e aplicadas com menos rigor. Embora os registros sobre o uso global de pesticidas estejam incompletos, é geralmente aceito que as taxas de aplicação aumentaram dramaticamente nas últimas décadas (United Nations, 2017).
A ocorrência de exposição simultânea dos trabalhadores a diversos princípios ativos, a subnotificação das ocorrências de intoxicação, e o despreparo dos profissionais das unidades de atenção básica em saúde para a realização da notificação, principalmente naquelas localizadas em áreas rurais, ao lado das ocorrências de intoxicação aguda, são frequentes (Brasil, 2018).
A análise da água potável consumida pelos habitantes de mais de 2.300 municípios brasileiros revelou a ocorrência de até 27 diferentes agrotóxicos, sobretudo nos estados de Santa Catarina, Paraná, São Paulo, Mato Grosso do Sul, Mato Grosso e Tocantins (Brasil, 2018).
A despeito do diligente trabalho desenvolvido por organizações da sociedade civil, como o Instituto de Defesa do Consumidor, e da academia, como a Fundação Oswaldo Cruz, há uma carência de dados atualizados e falta transparência na sua divulgação por parte do Governo Federal, a despeito da vigência da Lei de Acesso à Informação, Lei n.12.527, de 18 de novembro de 2011.
Investir em sistemas de monitoramento e dar visibilidade às informações relativas a volume e sistemas de produção de alimentos, são medidas que contribuem para a soberania alimentar e para a democratização do acesso à informação.
A produção de alimentos na agricultura familiar e de plantas cultivadas em larga escala é beneficiada por agentes polinizadores, como abelhas, besouros, borboletas, aves, morcegos e outros grupos de animais (BPBES/REBIPP, 2019). Esses agentes contribuem para a segurança alimentar em todo o planeta, pois mais de três quartos dos principais tipos de culturas alimentares globais dependem, em algum nível, da polinização animal para aumentar o rendimento ou melhorar a qualidade, sendo os responsáveis por impulsionar 35% do volume global de produção agrícola (IPBES, 2016) e 40% do suprimento de nutrientes para a dieta da população mundial (Eilers et al., 2011
).
Espécies de plantas dependentes de polinizadores abrangem frutas, verduras, legumes, sementes, nozes e oleaginosas, sendo alimentos contribuintes de macro e micronutrientes essenciais para nutrição humana, além de compostos bioativos (BPBES/REBIPP, 2019). De modo geral, as culturas dependentes de polinização possuem concentrações mais altas de vitamina A, vitamina C, lipídios, potássio, cálcio, flúor e ácido fólico (Eilers et al., 2011
), enquanto as culturas não dependentes de polinizadores proporcionam maior teor de carboidratos (Porto et al., 2021
).
A polinização é um recurso natural que garante uma diversidade de alimentos nutritivos, mas também promove a manutenção e a variabilidade genética de plantas nativas que sustentam a biodiversidade e está relacionada ao conhecimento tradicional. Dessa forma, a polinização pode ser considerada como serviço ecossistêmico de provisão, serviço ecossistêmico de regulação e serviço ecossistêmico cultural (BPBES/REBIPP, 2019; Costanza et al., 2017
). Atualmente, o serviço de polinização na produção de alimentos em nível global, foi estimado monetariamente entre 235 bilhões e 577 bilhões de dólares para as culturas dependentes (IPBES, 2016). No Brasil, o valor monetário de contribuição dos polinizadores na produção agrícola foi estimado em 12 bilhões de dólares por ano (Giannini et al., 2015
). Portanto, a perda destes agentes, além de afetar a segurança alimentar, pode atingir diretamente a economia mundial (Gallai et al., 2009
).
Apesar do importante papel dos polinizadores, esses agentes vêm sofrendo severas ameaças à sua conservação. Entre elas destacam-se a fragmentação e perdas de ambientes naturais com a mudança no uso da terra, o uso indiscriminado de agrotóxicos, a monocultura, as mudanças climáticas, a poluição ambiental e a competição com espécies invasoras (BPBES/REBIPP, 2019; IPBES, 2016). Segundo um histórico de cobertura e uso da terra nos biomas brasileiros entre os anos 1985 e 2021, o bioma Amazônia perdeu 11,5% de sua vegetação nativa; a Caatinga 10,1%; o Cerrado 20,9%; a Mata Atlântica 5,9%; o Pampa 29,5% e o Pantanal teve ganho de vegetação nativa de 2,3%, sendo resultado da perda de superfície de água (Mapbiomas, 2022). O desmatamento de vegetação nativa provoca déficit de recursos para muitas espécies nativas de polinizadores que, consequentemente, desaparecem do ambiente (Campbell et al., 2022
).
A conservação do serviço ecossistêmico de polinização em ambientes agrícolas e urbanos é possível mediante estratégias que proporcionam recursos alimentares, áreas de abrigo e de reprodução, por exemplo: manter áreas naturais livres de distúrbios; plantar cerca viva ao redor dos cultivos agrícolas; implementar corredores ecológicos nas cidades e em áreas agrícolas; promover a intensificação ecológica da paisagem agrícola; recuperar áreas degradadas com espécies nativas atrativas aos polinizadores e plantar espécies de plantas nativas com flores em jardins urbanos e residenciais (Garibaldi et al., 2015; Nascimento et al., 2020
). As políticas públicas têm um papel significativo na implementação de ações para a conservação dos polinizadores, e o conhecimento científico, indígena e local deve ser um subsídio para os formuladores dessas políticas e tomadores de decisão (BPBES/REBIPP, 2019).
O Brasil está entre os países de maior biodiversidade do planeta, abriga seis biomas e a cultura de diversos povos e comunidades tradicionais. Entretanto, o desconhecimento sobre a diversidade e a falta de acesso a alimentos, por grande parte da população, restringe a alimentação atual a uma pequena diversidade de ingredientes mesmo com a crescente demanda por melhores alternativas alimentares.
Paralelo a esse panorama, a expansão agrícola tem se mostrado como um importante motivador da perda da biodiversidade ocasionado especialmente pela forma de produção e consumo atual. Segundo FAO e Unep (2020), a adoção de práticas agroflorestais e de produção agroecológica tem se mostrado como uma estratégia importante para restaurar a produtividade de terras agrícolas degradadas. Além disso, elas podem impulsionar a adoção de dietas mais saudáveis, que valorizem a biodiversidade especialmente no seu uso para conservação tanto das espécies quanto para melhor uso da terra (Hunter et al., 2019
).
Dentre as espécies de importância econômica e nutricional, muitas remontam a milhares de anos antes da domesticação e das origens das culturas atuais. Ao longo da história, povos indígenas e comunidades locais e tradicionais têm sido os responsáveis por administrar diversos ecossistemas e culturas sendo ainda guardiões de alimentos e recursos genéticos. As suas formas de produção favorecem sistemas alimentares que promovem dietas saudáveis e resilientes, além do baixo impacto ambiental. A cultura de subsistência, extrativismo e criação de animais costumam ser os principais meios de vida destes grupos e são conduzidos de modo a manter a diversidade e formas de utilização que agregam o conhecimento associado a formas de cultivos que consideram os ecossistemas locais.
Dada a importância do conhecimento tradicional de povos indígenas e comunidades quilombolas, o seu reconhecimento como guardiões da biodiversidade e administradores de territórios pode contribuir para superar os desafios combinados de mudança climática, segurança alimentar, conservação da biodiversidade e combate ao mau uso da terra e água (Hunter; Borelli; Gee, 2020
).
Algumas políticas públicas corroboram diretamente e indiretamente com a SAN. Um importante e recente marco para a garantia da SAN da população brasileira foi a revisão e atualização do Guia Alimentar para a População Brasileira, que integra uma das estratégias da diretriz de promoção e alimentação adequada e saudável, consolidada na Política Nacional de Alimentação e Nutrição (PNAN) (Brasil, 2013). Esse é um documento oficial, publicado pelo Ministério da Saúde, com o propósito de promover a alimentação adequada e saudável em todos os espaços, com diretrizes para gestores, profissionais de saúde, e para todos os cidadãos. Esse documento tem sido considerado como referência internacional, especialmente por considerar a alimentação saudável em seu contexto mais amplo, o que remete também aos impactos socioculturais e ambientais das escolhas alimentares (Monteiro et al., 2015
).
Uma das mais reconhecidas políticas públicas de alimentação no mundo é o Programa Nacional de Alimentação Escolar (PNAE). O programa oferece alimentação escolar diariamente a aproximadamente 40 milhões de estudantes da educação básica pública por meio de repasses financeiros de caráter suplementar enviados aos estados e municípios.
O PNAE pode ser considerado como uma das principais ações de combate à fome no Brasil, não somente por sua abrangência e por beneficiar as crianças em uma fase especialmente crítica do seu desenvolvimento, mas também porque contribui como fonte de renda para a agricultura familiar visto que, do valor dos repasses como disposto na lei que regulamenta o PNAE, se prevê:
[...] mínimo 30% (trinta por cento) devem ser utilizados na aquisição de gêneros alimentícios diretamente da agricultura familiar e/ou do empreendedor familiar rural ou de suas organizações, priorizando-se os assentamentos da reforma agrária, as comunidades tradicionais indígenas e comunidades quilombolas. (Brasil, 2009, art. 14)
Outra ação governamental inserida nas políticas públicas de segurança alimentar e nutricional e que incentiva a aquisição de alimentos pela agricultura familiar é o Programa de Aquisição de Alimentos (PAA). As compras governamentais de alimentos por meio de órgãos públicos destinam-se a unidades de educação, assistência social, segurança, justiça, saúde e organizações não governamentais. Dessa maneira, contribuem com a geração de renda para esses agricultores e, de forma complementar, melhorias nas condições de alimentação de pessoas que se encontram em situação de vulnerabilidade social e/ou insegurança alimentar (Salgado et al., 2022
).
Por sua vez, o Programa de Alimentação do Trabalhador (PAT) também foi outra estratégia do governo para promoção da SAN, instituída pelo Estado em 1976, e atualmente regulamentado pelo Decreto n.10.854, de 10 de novembro de 2021 (Brasil, 2021), com o objetivo de atender prioritariamente os trabalhadores de baixa renda com subsídio financeiro às empresas que oferecem alimentação aos seus trabalhadores. Esse Programa atendeu, em 2018, aproximadamente 18 milhões de trabalhadores, contudo sofre com limitações decorrentes de sua formulação e implementação; apesar da expressiva cobertura, são escassos os resultados quanto à qualidade das refeições servidas (Costa-Souza et al., 2018). Além disso, a atual regulamentação do PAT retrocedeu ao revogar decretos que garantiam a oferta de alimentação adequada através de parâmetros nutricionais e responsabilidade técnica do PAT pelo profissional nutricionista, colocando em risco o objetivo do programa.
A complexidade dos sistemas alimentares e da SAN se reflete na abrangência das áreas do conhecimento e dos fatores envolvidos. Disso decorre que as políticas públicas e a tomada de decisão em qualquer nível requerem a consideração de muitas variáveis e de dados relativos a elas. Porém, a realidade é que esses dados não são facilmente disponíveis, acessíveis e processáveis pelos atores que os demandam. Isso ocorre por vários motivos, entre os quais: os dados não estão digitalizados, pois foram coletados em formato analógico; os dados não estão atualizados (exemplo: o Censo 2020 que só ocorreu em 2022); os dados já digitalizados não estão acessíveis, ainda que sejam públicos e que a Lei de Acesso à Informação, já citada, assim o estipule; os diversos conjuntos de dados estão disponíveis em resoluções espaciais e/ou temporais diferentes; os dados não seguem padrões, de modo que podem não ter compatibilidade sintática e/ou semântica imediata. Essas questões oferecem campo para a atuação dos profissionais da computação, que valendo-se de diversas técnicas e procedimentos, e juntamente com os especialistas nos problemas (por exemplo, SAN), podem atuar para resolvê-los ou contorná-los. Iniciativas mais estruturantes podem auxiliar nesse processo, como as de padronização de dados, e as de dados abertos.
Nesse contexto se insere a parceria com o Centro de Inteligência Artificial4
em seu eixoAgriBio (C4AI-AgriBio), por meio da qual têm sido desenvolvidas métodos e ferramentas de apoio ao entendimento e solução dos problemas relativos à SAN. Seguindo uma metodologia baseada em ciclo de vida dos dados, as atividades são voltadas para aquisição, padronização e processamento de dados oriundos de fontes distintas e heterogêneas, que representam e capturam a complexidade dos sistemas envolvidos e a multidisciplinaridade inerente à SAN. Tem-se trabalhado também na construção de uma infraestrutura para abrigar os dados coletados de sistemas públicos e/ou de parceiros, e na construção de ferramentas de análise e apoio à tomada de decisão. Com apoio de pesquisadores de vários setores, trabalha-se para buscar uma representação visual e amigável de cenários complexos de informação. Isso é fundamental para uma tomada de decisão colaborativa entre atores da sociedade.
Um exemplo de trabalho fruto dessa parceria são os estudos referentes à alimentação escolar a partir de dados de despesas do PNAE, coletados do website do Fundo Nacional de Desenvolvimento da Educação (FNDE). Eles são tratados com algoritmos de aprendizagem estatística para se obter uma base de dados robusta que permita fazer diversas análises relativas à disponibilidade de alimentos, à origem/destino das compras, avaliar a dependência de polinizadores nos itens dessa dieta, entre outros. Como se trata de um programa nacional, obter os dados de todo o país é um grande desafio, seja do ponto de vista da interface de acesso aos dados, seja do ponto de vista da falta de padronização no preenchimento das informações das notas fiscais das compras. Ainda assim, constitui-se em uma fonte valiosa para se analisar o PNAE sob diversos pontos de vista. Esse trabalho é um bom exemplo da aplicação de Inteligência Artificial, pelo uso de meios automáticos para extração, transformação e carregamento de dados (processo conhecido como ETL), garantindo a integridade e uso dos dados.
Outro trabalho importante que avança comitantemente é o estudo do uso de técnicas de otimização e modelos de aprendizagem não supervisionada, para melhorar a identificação de variáveis relevantes em bancos de dados com variáveis pertencentes a múltiplas dimensões. No caso específico da fome em megacidades, este trabalho está auxiliando a identificar as áreas de maior e menor risco de ocorrência de fome, considerando variáveis econômicas, ambientais e sociais. Ademais, também estão sendo desenvolvidas ferramentas web a serem disponibilizadas gratuitamente a pesquisadores e tomadores de decisão para permitir a realização de análises estatísticas e espaciais da ocorrência de fome em cidades de diferentes portes sem a necessidade de conhecimento dos modelos de otimização ou de programação.
O C4AI-AgriBio tem atuado também em iniciativas internacionais e nacionais relativas a dados abertos (open data), dentro do conceito de ciência aberta (open science), que são demandas transversais a múltiplas áreas, incluindo aquelas de interesse ao tema da SAN. Um exemplo é a Rede GO-FAIR, uma iniciativa internacional que teve origem em 2018 na Europa e atualmente está presente em diversos países, que visa implementar os princípios FAIR (acrônimo do inglês Findable, Accessible, Interoperable, Reusable), tornando os dados localizáveis, acessíveis, interoperáveis e reutilizáveis. A Rede GO FAIR Agro Brasil é uma rede de implementação regional e temática que visa estimular a adoção dos princípios FAIR no âmbito dos sistemas produtivos agropecuários e também aqueles oriundos de pesquisas em ciências agrárias (Drucker et al. 2021). Dentre seus objetivos, há aspectos técnicos, voltados à implementação de padrões de dados e metadados e repositórios de dados confiáveis, e aspectos relacionados à capacitação de pessoas e mudança cultural. A Rede está sendo construída coletivamente e estruturada em grupos de trabalho que estão trabalhando para tornar os dados agropecuários passíveis de reutilização, contribuindo com o avanço da ciência e com a tomada de decisão no setor.
Em outro âmbito, a Parceria para Governo Aberto, ou Open Government Partnership (OGP) envolve parcerias governamentais mundiais e consiste em estabelecer compromissos entre estado e sociedade civil voltados à transparência de governos e, portanto, de dados. No Brasil ela é liderada pela Controladoria Geral da União (CGU).5
O 5º Plano de Governo Aberto do Brasil estabeleceu o Compromisso 5: “Cadeias Agropecuárias e Dados Abertos” para a abertura e integração de bases de dados de cadeia agropecuária, elencando riscos, impactos e viabilidade. Em especial, a colaboração consiste em estabelecer metodologias e protocolos de metadados e uso de vocabulários controlados, para garantia de interoperabilidade, integração e transparência dos dados.
Assim, a ciência de dados e a inteligência artificial podem contribuir sobremaneira para superar os desafios da SAN, atuando ao longo de todo o processo, desde a obtenção de dados, até o provimento de ferramentas para apoio à tomada de decisão. A grande quantidade de variáveis, a grande quantidade de dados (big data) ou as vezes a falta de dados (small data) requerem o uso de técnicas adequadas para a manipulação dos dados. A automatização de processamentos pode poupar tempo e recursos além de permitir identificar tendências e comportamentos nos dados que podem promover insights importantes sobre as questões em análise.
Para o The Global Panel on Agriculture and Food Systems for Nutrition (2016), uma alimentação saudável é aquela que elimina a fome, é segura, reduz desnutrição e deficiências nutricionais, promove a saúde e é produzida de forma sustentável, ou seja, por meio de sistemas alimentares regenerativos que garantam alimentação de qualidade também para as gerações futuras.
A coordenação de todos os elementos constitutivos de um sistema alimentar (ambiente, pessoas, processos, infraestrutura, instituições, dentre outros) e as atividades que sustentam as etapas de produção, processamento, distribuição, preparação e consumo de alimentos, podem, ou não, promover soberania em uma nação. Em um estado soberano, para além da boa alimentação, os cidadãos são partícipes dos resultados socioeconômicos e ambientais (FAO, 2018). Sistemas de produção de alimentos regenerativos e resilientes incluem ecossistemas, sistemas humanos, sistemas de energia, sistemas econômicos e sistemas de saúde, que fornecem insumos essenciais para o sistema alimentar
Essa visão de sistemas alimentares sustentáveis fundamenta-se no reconhecimento de que a alimentação é um direito humano fundamental e inseparável da justiça social (HLPE, 2017), a considerar que tanto a subnutrição quanto a obesidade são manifestações generalizadas da insegurança alimentar e nutricional. É importante reconhecer que o agente primordial da segurança/insegurança alimentar é o sistema alimentar, que é um dos impulsionadores tanto da saúde quanto da degradação ambiental (Hammond; Dubé, 2012
; Tilma; Clark, 2014; Willet et al., 2019). A centralidade dos sistemas alimentares do ponto de vista da saúde planetária foi destacada na Declaração de São Paulo sobre Saúde Planetária. O texto ressalta o potencial para atender as necessidades alimentares globais, atingir a justiça social e diminuir o impacto nos sistemas naturais. Ressalta ainda que o futuro da saúde planetária - incluindo a saúde e bem-estar humanos, será determinado pelo modo como esse setor avançar em termos das práticas agrícolas e das opções de alimentos (Myers; Pivor; Saraiva, 2021
).
Nesse contexto se inserem as três graves ameaças globais à saúde e à sobrevivência humana: as pandemias de subnutrição e de obesidade - que incluem sua relação com o desenvolvimento de doenças crônicas não transmissíveis (DCNT) - e as mudanças climáticas. Elas estão interligadas, e juntas constituem uma sindemia global (Swinburn et al., 2019
).
Mudanças na produção e nas dietas atuais para dietas sustentáveis são uma das respostas para minimizar os impactos deletérios dos padrões de consumo alimentar atuais sobre o meio ambiente e a nutrição, e, consequentemente, na saúde das populações e do planeta.
De acordo com a Organização das Nações Unidas para Agricultura e Alimentação (FAO) e a Organização Mundial da Saúde (OMS), dietas saudáveis sustentáveis são “padrões alimentares que promovem todas as dimensões da saúde e bem-estar dos indivíduos; têm baixa pressão e impacto ambiental; são acessíveis, acessíveis, seguros e equitativos; e são culturalmente aceitáveis” (FAO, 2018). Em relação a isso, a revista científica Lancet comissionou cientistas (Comissão EAT-Lancet6
), que propuseram um modelo de dieta saudável e sustentável que visa proporcionar saúde à população e ao planeta, denominada “Dieta de Saúde Planetária”. Essas recomendações baseiam-se no consumo predominante de legumes, verduras, frutas e grãos integrais e no consumo reduzido de carnes, peixes, ovos, cereais refinados e tubérculos (Willett et al., 2019
). Para avaliar a adesão às recomendações de alimentação saudável e sustentável propostas pela Comissão EAT-Lancet, foi desenvolvido um indicador (Cacau et al., 2021
), que foi utilizado em um estudo nacional de base populacional realizado no Brasil. O escore total médio do Planetary Health Diet Index (PHDI) na população brasileira foi de 45,9 pontos (IC 95% 45,6:46,1) em um escore total que pode variar de 0 a 150 pontos. A adesão à dieta EAT-Lancet foi baixa em todas as regiões brasileiras. No entanto, a dieta planetária tem sofrido críticas, em particular por propor uma dieta universal, sem considerar as particularidades culturais e cenários epidemiológicos distintos dos povos.
Para Willett et al. (2019
), a dieta deveria ter uma diversidade de alimentos de origem vegetal; pequenas quantidades de alimentos de origem animal; gorduras insaturadas ao invés de saturadas e pequenas quantidades de grãos refinados, alimentos ultraprocessados e açúcares adicionados. Além disso, seria necessário reduzir o desperdício de alimentos em 50% e não aumentar a quantidade de terras para produção de alimentos.
No contexto brasileiro, o Guia Alimentar para População Brasileira já assumiu uma abordagem de sistema alimentar, levando em conta aspectos como os impactos ambientais provocados pela alimentação, bem como as influências do ambiente alimentar e dos modos de vida no padrão alimentar das populações (Gabe et al., 2019). O Guia considera formas de produção e distribuição dos alimentos e privilegia os sistemas alimentares social e ambientalmente sustentáveis, se constituindo como uma importante estratégia para implementação da diretriz de promoção da alimentação adequada e saudável que integra a Política Nacional de Alimentação e Nutrição.
Nesse cenário, o Grupo de pesquisa Nutrição e Pobreza, o Saúde Planetária Brasil, e o C4AI-AgriBio, entendem que a retomada organizada e sistêmica das frentes apresentadas neste artigo de posicionamento, entre outras ações que certamente devem ser somadas, aponta um caminho para a articulação entre pesquisa, serviço e políticas públicas para o combate à fome e às demais manifestações da má alimentação. O uso da Inteligência Artificial ao lado do conhecimento acumulado sobre sistemas alimentares sustentáveis e políticas públicas, oferece uma oportunidade para a organização, sistematização e aproveitamento de dados de forma a gerar simulações e cenários que contribuam para o enfrentamento do grave - e inaceitável - cenário de fome do Brasil atual.","['AGÊNCIA CÂMARA DE NOTÍCIAS. Para Fiocruz, falta transparência na divulgação de informações sobre agrotóxicos. Brasília, DF, 11 maio 2022. Disponível em: <https://www.camara.leg.br/noticias/874613-para-fiocruz-falta-transparencia-na-divulgacao-de-informacoes-sobre-agrotoxicos/>. Acesso em: 27 set. 2022.\n» https://www.camara.leg.br/noticias/874613-para-fiocruz-falta-transparencia-na-divulgacao-de-informacoes-sobre-agrotoxicos', 'ALPINO, T. D. M. A. et al. Os impactos das mudanças climáticas na Segurança Alimentar e Nutricional: uma revisão da literatura. Ciência & Saúde Coletiva, v.27, p.273-86, 2022. DOI 10.1590/1413-81232022271.05972020.\n» https://doi.org/10.1590/1413-81232022271.05972020.', 'ARANHA, A. Mistura de agrotóxicos na água continua sem controle, Fiocruz propõe regras mais rígidas. Repórter Brasil, 13 maio 2020. Disponível em: <https://reporterbrasil.org.br/2020/05/mistura-de-agrotoxicos-na-agua-continua-sem-controle-fiocruz-propoe-regras-mais-rigidas/>. Acesso em: 27 set. 2022.\n» https://reporterbrasil.org.br/2020/05/mistura-de-agrotoxicos-na-agua-continua-sem-controle-fiocruz-propoe-regras-mais-rigidas', 'BPBES/REBIPP. Relatório temático sobre Polinização, Polinizadores e Produção de Alimentos no Brasil. 2019. Marina Wolowski; Kayna Agostini; André Rodrigo Rech; Isabela Galarda Varassin; Márcia Maués; Leandro Freitas; Liedson Tavares Carneiro; Raquel de Oliveira Bueno; Hélder Consolaro; Luisa Carvalheiro; Antônio Mauro Saraiva; Cláudia Inês da Silva. Maíra C. G. Padgurschi (Org.). São Carlos: Cubo, 2019. 184p. http://doi.org/10.4322/978-85-60064-83-0\n» http://doi.org/10.4322/978-85-60064-83-0', 'BRASIL. Lei n.7.802, de 11 de julho de 1989. Lei dos Agrotóxicos. Diário Oficial da União: seção 1, Brasília, DF, p.11459, 12 jul. 1989.', '_______. Projeto de Lei n.6.299/2002. Brasília, DF, 2002. Disponível em: <https://www.camara.leg.br/proposicoesWeb/fichadetramitacao?idProposicao=46249>. Acesso em: 27 out. 2022.\n» https://www.camara.leg.br/proposicoesWeb/fichadetramitacao?idProposicao=46249', '_______. Fundo Nacional para o Desenvolvimento da Educação (FNDE). Lei n.11.947, de 16 junho de 2009. Dispõe sobre o atendimento da alimentação escolar e do Programa Dinheiro Direto na Escola aos alunos da educação básica. Diário Oficial da União: seção 1, Brasília, DF, p. 2, 17 jun. 2009.', '_______. Decreto n.7.794 de 20 de agosto de 2012. Institui a Política Nacional de Agroecologia e Produção Orgânica. Diário Oficial da União: seção 1, Brasília, DF, p. 4, 21 ago. 2012.', '_______. Ministério da Saúde. Secretaria de Atenção à Saúde. Departamento de Atenção Básica. Política Nacional de Alimentação e Nutrição. Brasília, DF: Ministério da Saúde, 2013.', '_______. Ministério da Saúde. Secretaria de Vigilância em Saúde. Departamento de Vigilância em Saúde Ambiental e Saúde do Trabalhador. Relatório Nacional de Vigilância em Saúde de Populações Expostas a Agrotóxicos. Brasília, DF: Ministério da Saúde, 2018.', '_______. Resolução n.6, de 8 de maio de 2020. Dispõe sobre o atendimento da alimentação escolar aos alunos da educação básica no âmbito do Programa Nacional de Alimentação Escolar - PNAE. Diário Oficial da União, Brasília, DF, 8 maio 2020.', '_______. Decreto n.10.854, de 10 de novembro de 2021. Regulamenta disposições relativas à legislação trabalhista […]. Diário Oficial da União: seção 1, Brasília, DF, ano 159, n.212, p.2-9, 11 nov. 2021.', 'BUONCRISTIANO, M. et al. Socioeconomic inequalities in overweight and obesity among 6- to 9-year-old children in 24 countries from the World Health Organization European region. Obesity Reviews, v.22, n.S6, p.e13213, 2021. DOI 10.1111/obr.13213.\n» https://doi.org/10.1111/obr.13213.', 'BURIGO, A. C.; PORTO, M. F. Agenda 2030, saúde e sistemas alimentares em tempos de sindemia: da vulnerabilização à transformação necessária. Ciência & Saúde Coletiva, v.26, n.10, p.4411424, 2021. DOI 10.1590/1413-812320212610.13482021.\n» https://doi.org/10.1590/1413-812320212610.13482021.', 'CACAU, L. et al. Development and Validation of an Index Based on EAT-Lancet Recommendations: The Planetary Health Diet Index. Nutrients, v.13, n.5, p.1698, 2021. DOI 10.3390/nu13051698.\n» https://doi.org/10.3390/nu13051698.', 'CAMPBELL, A. J. et al. High bee functional diversity buffers crop pollination services against Amazon deforestation. Agriculture, Ecosystems & Environment, v.326, 2022. DOI 10.1016/j.agee.2021.107777.\n» https://doi.org/10.1016/j.agee.2021.107777.', 'CAMPELLO, T.; BORTOLETTO, A. P. Da fome à fome: diálogos com Josué de Castro. São Paulo: Cátedra Josué de Castro: Zabelê Comunicação: Editora Elefante, 2022.', 'CARNEIRO, F. F. et al. (Org.) Dossiê ABRASCO: um alerta sobre os impactos dos agrotóxicos na saúde. Rio de Janeiro: EPSJV; São Paulo: Expressão Popular, 2015. Disponível em: <https://www.abrasco.org.br/dossieagrotoxicos/wp-content/uploads/2013/10/DossieAbrasco_2015_web.pdf>. Acesso em: 27 set. 2022.\n» https://www.abrasco.org.br/dossieagrotoxicos/wp-content/uploads/2013/10/DossieAbrasco_2015_web.pdf', 'CENTRO DE ESTUDOS AVANÇADOS EM ECONOMIA APLICADA; CONFEDERAÇÃO NACIONAL DA AGRICULTURA E PECUÁRIA. PIB do agronegócio brasileiro de 1996 a 2021. [Piracicaba], 2022. Disponível em: <https://www.cepea.esalq.usp.br/br/pib-do-agronegocio-brasileiro.aspx>. Acesso em: 26 out. 2022.\n» https://www.cepea.esalq.usp.br/br/pib-do-agronegocio-brasileiro.aspx', 'COSTA, H. PL do veneno: modernização ou retrocesso? Congresso em Foco, 4 mar. 2022. Disponível em: <https://congressoemfoco.uol.com.br/area/congresso-nacional/pl-do-veneno-modernizacao-ou-retrocesso/>. Acesso em: 27 set. 2022.\n» https://congressoemfoco.uol.com.br/area/congresso-nacional/pl-do-veneno-modernizacao-ou-retrocesso', 'COSTA-SOUZA, J.; VIEIRA-DA-SILVA, L. M.; PINELL, P. A socio-historical approach to policy analysis: the case of the Brazilian Workers’ Food Policy. Cadernos de Saúde Pública, v.34, n.1, p.e00140516, 2018. DOI 10.1590/0102-311X00140516.\n» https://doi.org/10.1590/0102-311X00140516.', 'COSTANZA, R. et al. Twenty years of ecosystem services: how far have we come and how far do we still need to go? Ecosystem services, v.28, p.1-16, 2017. DOI 10.1016/j.ecoser.2017.09.008.\n» https://doi.org/10.1016/j.ecoser.2017.09.008.', 'DRUCKER, D. P. et al. Implantação da Rede Temática GO-FAIR Agro Brasil: primeiros passos. In: CONGRESSO BRASILEIRO DE AGROINFORMÁTICA, 13., 2021, Bagé. Anais .... Bagé: Unipampa, 2021. p.164-71. 2177-9724 Organizado por Ana Paula Lüdtke Ferreira.', 'EILERS, E. J. et al. Contribution of Pollinator-Mediated Crops to Nutrients in the Human Food Supply. PLoS ONE, v.6, n.6, p.e21363, 2011. DOI 10.1371/journal.pone.0021363.\n» https://doi.org/10.1371/journal.pone.0021363.', 'EMPRESA BRASILEIRA DE PESQUISA AGROPECUÁRIA (EMBRAPA). Brasil é o quarto maior produtor de grãos e o maior exportador de carne bovina do mundo. 1º de junho de 2021, Brasília, DF. Disponível em: <https://www.embrapa.br/busca-de-noticias/-/noticia/62619259/brasil-e-o-quarto-maior-produtor-de-graos-e-o-maior-exportador-de-carne-bovina-do-mundo-diz-estudo>.\n» https://www.embrapa.br/busca-de-noticias/-/noticia/62619259/brasil-e-o-quarto-maior-produtor-de-graos-e-o-maior-exportador-de-carne-bovina-do-mundo-diz-estudo', 'FOOD AND AGRICULTURE ORGANIZATION OF THE UNITED NATIONS (FAO) et al. The State of Food Security and Nutrition in the World 2022: Repurposing food and agricultural policies to make healthy diets more affordable. Rome: FAO, 2022. DOI 10.4060/cc0639en.\n» https://doi.org/10.4060/cc0639en.', 'FOOD AND AGRICULTURE ORGANIZATION OF THE UNITED NATIONS. FAOSTAT. Rome, 2014. Disponível em: <http://faostat.fao.org/>. Acesso em: 26 out. 2022.\n» http://faostat.fao.org', 'FOOD AND AGRICULTURE ORGANIZATION OF THE UNITED NATIONS. Sustainable food systems: Concept and framework. Rome, 2018. Disponível em: <https://www.fao.org/3/ca2079en/CA2079EN.pdf>. Acesso em: 26 out. 2022.\n» https://www.fao.org/3/ca2079en/CA2079EN.pdf', 'FOOD AND AGRICULTURE ORGANIZATION OF THE UNITED NATIONS; UNITED NATIONS ENVIRONMENTAL PROGRAMME (FAO-UNEP). The State of the World’s Forests 2020: Forests, biodiversity and people. Rome, 2020. DOI 10.4060/ca8642en. Disponível em: <https://www.fao.org/3/ca8642en/ca8642en.pdf>. Acesso em: 26 out. 2022.\n» https://doi.org/10.4060/ca8642en\n» https://www.fao.org/3/ca8642en/ca8642en.pdf', 'GABE, K.; JAIME, P. C.; REIS, L. C. Guias alimentares e a classificação de alimentos NOVA. In: MARCHIONI, D. M.; GORGULHO, B. M.; STELUTI, J. (Org.) Consumo alimentar: guia para avaliação. Barueri: Manole, 2019.', 'GALLAI, N. et al. Economic valuation of the vulnerability of the world agriculture confronted with pollination decline. Ecological Economics, v.68, p.810-21, 2009. DOI 10.1016/j.ecolecon.2008.06.014.\n» https://doi.org/10.1016/j.ecolecon.2008.06.014.', 'GARIBALDI, L. A. et al. Aplicações do protocolo de avaliação socioeconômica de práticas amigáveis aos polinizadores no Brasil. Rio de Janeiro: Funbio, 2015. 71p.', 'GIANNINI, T. C. et al. The Dependence of Crops for Pollinators and the Economic Value of Pollination in Brazil. Journal of Economic Entomology, v.108, n.3, p.849-57, 2015. DOI 10.1093/jee/tov093.\n» https://doi.org/10.1093/jee/tov093.', 'GLOBAL PANEL ON AGRICULTURE AND FOOD SYSTEMS FOR NUTRITION. Food systems and diets: facing the challenges of the 21st century. London: GPAFSN, 2016. Disponível em: <https://glopan.org/sites/default/files/ForesightReport.pdf>. Acesso em: 26 out. 2022.\n» https://glopan.org/sites/default/files/ForesightReport.pdf', 'GRIGORI, P. Afinal, o Brasil é o maior consumidor de agrotóxico do mundo? Abrasco [Notícias], 27 jun. 2019. Disponível em: <https://www.abrasco.org.br/site/noticias/opiniao/afinal-o-brasil-e-o-maior-consumidor-de-agrotoxico-do-mundo/41450/>. Acesso em: 30 set. 2022.\n» https://www.abrasco.org.br/site/noticias/opiniao/afinal-o-brasil-e-o-maior-consumidor-de-agrotoxico-do-mundo/41450', 'HAMMOND, R. A.; DUBÉ, L. A systems science perspective and transdisciplinary models for food and nutrition security. Proceedings of the National Academy of Sciences of the United States of America, v.109, n.31, p.12356-63, 2012. DOI 10.1073/pnas.0913003109.\n» https://doi.org/10.1073/pnas.0913003109.', 'HIGH LEVEL PANEL OF EXPERTS ON FOOD SECURITY AND NUTRITION (HLPE). Nutrition and food systems: a report by the High Level Panel of Experts on Food Security and Nutrition. Rome: FAO, 2017. Disponível em: <https://www.fao.org/documents/card/en/c/I7846E/>. Acesso em: 26 out. 2022.\n» https://www.fao.org/documents/card/en/c/I7846E', 'HUNTER, D. et al. The potential of neglected and underutilized species for improving diets and nutrition. Planta, v.250, n.3, p.709-29, 2019. DOI 10.1007/s00425-019-03169-4.\n» https://doi.org/10.1007/s00425-019-03169-4.', 'HUNTER, D.; BORELLI, T.; GEE, E. Biodiversity, food and nutrition: a new agenda for sustainable food systems. New York: Routledge, 2020. 296p. Disponível em: <http://www.b4fn.org/fileadmin/templates/b4fn.org/upload/documents/The_Books/BFN_full_2020_compressed.pdf>. Acesso em: 26 out. 2022.\n» http://www.b4fn.org/fileadmin/templates/b4fn.org/upload/documents/The_Books/BFN_full_2020_compressed.pdf', 'IBAMA. Ministério do Meio Ambiente. Relatórios de Comercialização de Agrotóxicos. Brasília, DF, 2022. Disponível em: <http://www.ibama.gov.br/agrotoxicos/relatorios-de-comercializacao-de-agrotoxicos>. Acesso em: 27 set. 2022.\n» http://www.ibama.gov.br/agrotoxicos/relatorios-de-comercializacao-de-agrotoxicos', 'INSTITUTO BRASILEIRO DE GEOGRAFIA E ESTATÍSTICA (IBGE). Censo agropecuário 2017: resultados definitivos. Rio de Janeiro, 2019. (Volume 8). Disponível em: <https://biblioteca.ibge.gov.br/visualizacao/periodicos/3096/agro_2017_resultados_definitivos.pdf>. Acesso em: 2 set. 2022.\n» https://biblioteca.ibge.gov.br/visualizacao/periodicos/3096/agro_2017_resultados_definitivos.pdf', '_______. Projeção da população do Brasil e Unidades da Federação por sexo e idade para o período 2010-2060. Brasília, DF, 2022. Disponível em <https://www.ibge.gov.br/apps/populacao/projecao/index.html>. Acesso em: 26 ago. 2022.\n» https://www.ibge.gov.br/apps/populacao/projecao/index.html', 'INTERGOVERNMENTAL PANEL ON CLIMATE CHANGE. Climate Change and Land: An IPCC Special Report on Climate Change, Desertification, Land Degradation, Sustain\xadable Land Management, Food Security, and Greenhouse gas fluxes in Terrestrial Ecosystems Sum\xadmary for Policymakers, Intergovernmental Panel on Climate Change. Geneva, 2019. Disponível em: <https://www.ipcc.ch/site/assets/uploads/sites/4/2021/07/210714-IPCCJ7230-SRCCL-Co mplete-BOOK-HRES.pdf>. Acesso em: 26 out. 2022.\n» https://www.ipcc.ch/site/assets/uploads/sites/4/2021/07/210714-IPCCJ7230-SRCCL-Co mplete-BOOK-HRES.pdf', 'IPBES. The methodological assessment report on scenarios and models of biodiversity and ecosystem services. 2016. S. Ferrier, K. N. Ninan, P. Leadley, R. Alkemade, L. A. Acosta, H. R. Akçakaya, L. Brotons, W. W. L. Cheung, V. Christensen, K. A. Harhash, J. Kabubo-Mariara, C. Lundquist, M. Obersteiner, H. M. Pereira, G. Peterson, R. Pichs-Madruga, N. Ravindranath, C. Rondinini and B. A. Wintle (eds.). Secretariat of the Intergovernmental Science-Policy Platform on Biodiversity and Ecosystem Services, 2016. 348p.', 'MAPBIOMAS. Mapeamento anual de cobertura e uso da terra no Brasil. [S. l.], ago. 2022. (Coleção 7). Disponível em: <https://mapbiomas-br-site.s3.amazonaws.com/Fact-Sheet-Colecao7.pdf>. Acesso em: 29 ago. 2022.\n» https://mapbiomas-br-site.s3.amazonaws.com/Fact-Sheet-Colecao7.pdf', 'MASSON-DELMOTTE, V. P. et al. (Ed.) Global Warming of 1.5°C: An IPCC Special Report on the impacts of global warming of 1.5°C above pre-industrial levels and related global greenhouse gas emission pathways, in the context of strengthening the global response to the threat of climate change, sustainable development, and efforts to eradicate poverty. Cambridge, UK: Cambridge University Press, 2022. DOI 10.1017/9781009157940.005.\n» https://doi.org/10.1017/9781009157940.005.', 'MIRANDA, E. E. Áreas cultivadas no Brasil e no mundo. Agronalysis, Rio de Janeiro, v.38, n.2, p.25-27, 2018. Disponível em: <https://bibliotecadigital.fgv.br/ojs/index.php/agroanalysis/article/view/77453>. Acesso em: 29 ago. 2022.\n» https://bibliotecadigital.fgv.br/ojs/index.php/agroanalysis/article/view/77453', 'MITIDIERO JUNIOR, M. A. Censo agropecuário 2017: o que revela o censo do golpe? Marília: Lutas Anticapital, 2022.', 'MONTEIRO, C. A. et al. Dietary guidelines to nourish humanity and the planet in the twenty-first century. A blueprint from Brazil. Public Health Nutrition, v.18, n.13, p.2311-22, Sept. 2015. DOI 10.1017/S1368980015002165.\n» https://doi.org/10.1017/S1368980015002165.', 'MOTORYN, P. MST completa 38 anos com arrecadação histórica contra a fome e campanha nas redes sociais. Brasil de Fato, Brasília, DF, 22 jan. 2022. Disponível em: <https://www.brasildefato.com.br/2022/01/22/mst-completa-38-anos-com-arrecadacao-historica-contra-a-fome-e-campanha-nas-redes-sociais>. Acesso em: 16 set. 2022.\n» https://www.brasildefato.com.br/2022/01/22/mst-completa-38-anos-com-arrecadacao-historica-contra-a-fome-e-campanha-nas-redes-sociais', 'MOTTA, C. MST: Comida boa e sem veneno na mesa dos brasileiros. E na cozinha dos chefs. Rede Brasil Atual, 2 maio 2021. Disponível em: <https://www.redebrasilatual.com.br/cidadania/2021/05/comida-boa-sem-veneno-mesa-brasileiros-cozinha-chefs/>. Acesso em: 6 set. 2022.\n» https://www.redebrasilatual.com.br/cidadania/2021/05/comida-boa-sem-veneno-mesa-brasileiros-cozinha-chefs', 'MOVIMENTO DOS TRABALHADORES RURAIS SEM TERRA. Carta do 5º Congresso Nacional do MST. [S. l.], 2007. Disponível em: <https://mst.org.br/2007/06/17/carta-do-5o-congresso-nacional-do-mst/>. Acesso em: 6 set. 2022.\n» https://mst.org.br/2007/06/17/carta-do-5o-congresso-nacional-do-mst', 'MYERS S. S.; PIVOR J. I.; SARAIVA, A. M. The São Paulo Declaration on Planetary Health. The Lancet, v.398, n.10308, p.1299, 2021. DOI 10.1016/S0140-6736(21)02181-4.\n» https://doi.org/10.1016/S0140-6736(21)02181-4.', 'NASCIMENTO, V. T. et al. Tropical urban areas support highly diverse plant-pollinator interactions: An assessment from Brazil. Landscape and Urban Planning, v.198, 103801, 2020. DOI 10.1016/j.landurbplan.2020.103801.\n» https://doi.org/10.1016/j.landurbplan.2020.103801.', 'OLIVEIRA, C. O que o MST tem feito em contraponto ao agronegócio predatório no Brasil? Brasil de Fato, São Paulo, 4 jun. 2022. Disponível em: <https://www.brasildefato.com.br/2022/06/04/o-que-o-mst-tem-feito-em-contraponto-ao-agronegocio-predatorio-no-brasil>. Acesso em: 6 set. 2022.\n» https://www.brasildefato.com.br/2022/06/04/o-que-o-mst-tem-feito-em-contraponto-ao-agronegocio-predatorio-no-brasil', 'PELIANO, A. M. M. Uma batalha incansável contra a fome, a pobreza e a desigualdade social. Organizador Fernando Rezende. Brasília, DF: Ipea, 2022.', 'PEREZ, F.; MOREIRA, J. C.; DUBOIS, G. S. Agrotóxicos, Saúde e Ambiente: uma introdução ao tema. In: PERES, F., MOREIRA, J. C. (Org.) É veneno ou é remédio? agrotóxicos, saúde e ambiente. Rio de Janeiro: Editora Fiocruz, 2003. Cap. 1. Disponível em: <https://portal.fiocruz.br/sites/portal.fiocruz.br/files/documentos/cap_01_veneno_ou_remedio.pdf>. Acesso em: 27 set. 2022.\n» https://portal.fiocruz.br/sites/portal.fiocruz.br/files/documentos/cap_01_veneno_ou_remedio.pdf', 'PICOLOTTO, E. Os atores da construção da Categoria agricultura familiar no Brasil. Revista de Economia e Sociologia Rural. 2018.52. 63-84.', 'PIGNATI, W. Entenda por que o Brasil é o maior consumidor de agrotóxicos do mundo. Entrevistado por Mariana Lucena. Revista Galileu, 5 dez. 2018. Disponível em: <https://renastonline.ensp.fiocruz.br/sites/default/files/arquivos/recursos/entenda_por_que_o_brasil_e_o_maior_consumidor_de_agrotoxicos_do_mundo._galileu.pdf>. Acesso em: 5 out. 2022.\n» https://renastonline.ensp.fiocruz.br/sites/default/files/arquivos/recursos/entenda_por_que_o_brasil_e_o_maior_consumidor_de_agrotoxicos_do_mundo._galileu.pdf', 'PLATAFORMA BRASILEIRA DE BIODIVERSIDADE E SERVIÇOS ECOSSISTÊMICOS; REDE BRASILEIRA DE INTERAÇÕES PLANTA-POLINIZADOR. Relatório temático sobre Polinização, Polinizadores e Produção de Alimentos no Brasil. São Carlos: Editora Cubo, 2019. 184p.', 'PORTO, R. G. et al. Pollinator-dependent crops in Brazil yield nearly half of nutrients for humans and livestock feed. Global Food Security, v.3, p.100587, 2021. DOI 10.1016/j.gfs.2021.100587.\n» https://doi.org/10.1016/j.gfs.2021.100587.', 'POTENZA, R. F. et al. Análise das emissões brasileiras de e suas implicações para as metas climáticas do Brasil 1970 - 2020 gases de efeito estufa. Brasília, DF: SEEG, 2021.', 'POTTS, S. G. et al. (Ed.) Summary for policymakers of the assessment report of the Intergovernmental Science-Policy Platform on Biodiversity and Ecosystem Services on pollinators, pollination and food production. Bonn: Secretariat of the Intergovernmental Science-Policy Platform on Biodiversity and Ecosystem Services, 2016. 36p.', 'PROENÇA, R. P. C. et al. Cenário e perspectivas do sistema alimentar brasileiro frente à pandemia de Covid-19. Demetra, v.16, p.e55953, 2021. DOI 10.12957/demetra.2021.55953.\n» https://doi.org/10.12957/demetra.2021.55953.', 'REDE PENSSAN. II Inquérito Nacional sobre Insegurança Alimentar no Contexto da Pandemia da COVID-19 no Brasil: II VIGISAN: relatório final/Rede Brasileira de Pesquisa em Soberania e Segurança Alimentar - PENSSAN. São Paulo: Fundação Friedrich Ebert: Rede PENSSAN, 2022.', 'SALATI, P. Após novo recorde, Brasil encerra 2021 com 562 agrotóxicos liberados, sendo 33 inéditos. G1, 18 jan. 2022. Disponível em: <https://g1.globo.com/economia/agronegocios/noticia/2022/01/18/apos-novo-recorde-brasil-encerra-2021-com-562-agrotoxicos-liberados-sendo-33-ineditos.ghtml>. Acesso em: 14 set. 2022.\n» https://g1.globo.com/economia/agronegocios/noticia/2022/01/18/apos-novo-recorde-brasil-encerra-2021-com-562-agrotoxicos-liberados-sendo-33-ineditos.ghtml', 'SALGADO, R. J. S. F.; SOUZA, W. J.; FERREIRA, M. A. M. Compra institucional de produtos da agricultura familiar: avaliando a execução do Programa de Aquisição de Alimentos pelas universidades federais. Revista de Economia e Sociologia Rural, v. 60, número especial, p. e248030, 2022. DOI 10.1590/1806-9479.2021.248030.\n» https://doi.org/10.1590/1806-9479.2021.248030.', 'SAMPAIO, C. “PL do Veneno” causará “danos irreparáveis”, diz Fiocruz em nota enviada aos senadores. Brasil de Fato, Fortaleza, 14 fev. 2022. Disponível em: <https://www.brasildefato.com.br/2022/02/14/pl-do-veneno-causara-danos-irreparaveis-diz-fiocruz-em-nota-enviada-aos-senadores>. Acesso em: 27 set. 2022.\n» https://www.brasildefato.com.br/2022/02/14/pl-do-veneno-causara-danos-irreparaveis-diz-fiocruz-em-nota-enviada-aos-senadores', 'SHUKLA, P. R. et al. (Ed.) Climate Change 2022: Mitigation of Climate Change. Contribution of Working Group III to the Sixth Assessment Report of the Intergovernmental Panel on Climate Change. Cambridge, UK: Cambridge University Press, 2022. DOI 10.1017/9781009157926.001.\n» https://doi.org/10.1017/9781009157926.001.', 'SOCIEDADE BRASILEIRA PARA O PROGRESSO DA CIÊNCIA. SBPC posiciona-se contra a “PL do Veneno”. São Paulo, 7 mar. 2022. Disponível em: <http://portal.sbpcnet.org.br/noticias/sbpc-se-posiciona-contra-o-pl-do-veneno/>. Acesso em: 27 set. 2022.\n» http://portal.sbpcnet.org.br/noticias/sbpc-se-posiciona-contra-o-pl-do-veneno', 'SWINBURN, B. A. et al. The global syndemic of obesity, undernutrition, and climate change: The Lancet Commission report. The Lancet, v.393, p. 791-846, 2019. DOI 10.1016/S0140-6736(18)32822-8.\n» https://doi.org/10.1016/S0140-6736(18)32822-8.', 'TILMAN, D.; CLARK, M. Global diets link environmental sustainability and human health. Nature, v.515, p.518-22, 2014. DOI 10.1038/nature13959.\n» https://doi.org/10.1038/nature13959.', 'UNITED NATIONS. World Population Prospects: The 2012 Revision. [New York]: Population Division of the Department of Economic and Social Affairs of the United Nations Secretariat, 2014. Disponível em: <https://population.un.org/wpp/>. Acesso em: 26 out. 2022.\n» https://population.un.org/wpp', '_______. General Assembly. Human Rights Council. Report of the Special Rapporteur on the right to food. [New York], 24 Mar. 2017. Disponível em: <https://reliefweb.int/report/world/report-special-rapporteur-right-food-ahrc3448>. Acesso em: 26 out. 2022.\n» https://reliefweb.int/report/world/report-special-rapporteur-right-food-ahrc3448', '_______. World Population Prospects 2022: Summary of Results. [New York]: Department of Economic and Social Affairs, Population Division, 2022. Disponível em: <https://www.un.org/development/desa/pd/sites/www.un.org.development.desa.pd/files/wpp2022_summary_of_results.pdf>. Acesso em: 28 out. 2022.\n» https://www.un.org/development/desa/pd/sites/www.un.org.development.desa.pd/files/wpp2022_summary_of_results.pdf', 'VOLLSET S. E. et al. Fertility, mortality, migration, and population scenarios for 195 countries and territories from 2017 to 2100: a forecasting analysis for the Global Burden of Disease Study. The Lancet, v.396, n.10258, p.1285-1306, 2020. DOI 10.1016/S0140-6736(20)30677-2.\n» https://doi.org/10.1016/S0140-6736(20)30677-2.', 'WILLETT, W. et al. Food in the Anthropocene: the EAT-Lancet Commission on healthy diets from sustainable food systems. The Lancet, v.393, p.447-92, 2019. DOI 10.1016/S0140-6736(18)31788-4, 2019.\n» https://doi.org/10.1016/S0140-6736(18)31788-4', 'WORLD FOOD PROGRAMME. Estado da Alimentação Escolar no Mundo 2020. Roma: Programa Mundial de Alimentos, 2021.']","['Publicação nesta coleção\n23 Out 2023', 'Data do Fascículo\nSep-Dec 2023']","[' SEMÍRAMIS MARTINS ÁLVARES DOMENE ', ' KAYNA AGOSTINI ', ' GABRIEL NATALE PINTO DE ALMEIDA ', ' RAFAELLA GUIMARÃES MORAES CAMARGO ', ' ALINE MARTINS DE CARVALHO ', ' FERNANDO ELIAS CORRÊA ', ' ALEXANDRE CLÁUDIO BOTAZZO DELBEM ', ' SARA STEFANI DOMINGOS ', ' DEBORA PIGNATARI DRUCKER ', ' DIRCE MARIA LOBO MARCHIONI ', ' ISABELA PRADO MARTINS ', ' UIARA BANDINELI MONTEDO ', ' EVANDRO MARCOS SAIDEL RIBEIRO ', ' RAQUEL DE ANDRADE CARDOSO SANTIAGO ', ' ROBERTO FRAY DA SILVA ', ' FILIPI MIRANDA SOARES ', ' JOSIANE STELUTI ', ' ANTÓNIO MAURO SARAIVA ']","['Universidade Federal de São Paulo, Departamento de Políticas Públicas e Saúde Coletiva, Instituto Saúde e Sociedade, São Paulo, Brasil. semiramis.domene@unifesp.br; jsteluti@unifesp.br ', 'Universidade Federal de São Carlos, Departamento de Ciências da Natureza, Matemática e Educação, Centro de Ciências Agrárias, São Carlos, São Paulo, Brasil. kayna@ufscar.br ', 'Instituto de Ensino e Pesquisa, Programa de Pós-Graduação em Economia dos Negócios, São Paulo, Brasil. gabrielnpa@al.insper.edu.br ', 'Universidade Federal de São Paulo, Programa de Pós-Graduação Interdisciplinar em Ciências da Saúde, Santos, São Paulo, Brasil. guimaraes.rafaella@unifesp.br ', 'Universidade de São Paulo, Departamento de Nutrição, Faculdade de Saúde Pública, São Paulo, Brasil. alinenutri@usp.br; marchioni@usp.br ', 'Universidade de São Paulo, Instituto de Estudos Avançados, Center for Artificial Intelligence C4AI, São Paulo, Brasil. fecorrea@usp.br; roberto.fray.silva@gmail.com ', 'Universidade de São Paulo, Instituto de Ciências Matemáticas e de Computação, Center for Artificial Intelligence (C4AI), São Paulo, Brasil. acbd@icmc.usp.br ', 'Universidade Federal de São Carlos, Programa de Pós-Graduação em Agricultura e Ambiente, São Carlos, São Paulo, Brasil. sarastefani@estudante.ufscar.br ', 'Embrapa Agricultura Digital, Grupo de Pesquisa de Modelagem Agroambiental e Geotecnologias, Brasília, Distrito Federal, Brasil. debora.drucker@embrapa.br ', 'Universidade de São Paulo, Departamento de Nutrição, Faculdade de Saúde Pública, São Paulo, Brasil. alinenutri@usp.br; marchioni@usp.br ', 'Universidade Federal de São Paulo, Programa de Pós-Graduação em Nutrição, São Paulo, Brasil. isabela.prado@unifesp.br ', 'Universidade de São Paulo, Departamento de Engenharia de Produção, Center for Artificial Intelligence (C4AI), São Paulo, Brasil. uiara.montedo@usp.br ', 'Universidade de São Paulo, Departamento de Administração, Faculdade de Economia, Administração e Contabilidade, São Paulo, Brasil. esaidel@usp.br ', 'Universidade Federal de Goiás, Faculdade de Nutrição, Goiânia, Goiás, Brasil. racsantiago@gmail.com ', 'Universidade de São Paulo, Instituto de Estudos Avançados, Center for Artificial Intelligence C4AI, São Paulo, Brasil. fecorrea@usp.br; roberto.fray.silva@gmail.com ', 'Center for Artificial Intelligence (C4AI), São Paulo, Brazil', 'Universidade Federal de São Paulo, Departamento de Políticas Públicas e Saúde Coletiva, Instituto Saúde e Sociedade, São Paulo, Brasil. semiramis.domene@unifesp.br; jsteluti@unifesp.br ', 'Universidade de São Paulo, Instituto de Estudos Avançados, Escola Politécnica, Center for Artificial Intelligence (C4AI), São Paulo, Brasil. saraiva@usp.br ']",http://www.scielo.br/scielo.php?script=sci_arttext&pid=S0103-40142023000300181&lang=pt,2024-11-21 09:59:34.306705,Scielo.org
A capacidade dos trending topics em pautar o debate: agenda setting do algoritmo,"O algoritmo das redes sociais funciona com um sistema complexo de inteligência artificial para criar uma linha de tempo que retenha usuários e garanta permanência de tela. Por meio de assuntos que viram tendência, o algoritmo pauta o debate público através de uma lógica: os temas surgem, na maioria das vezes, no Twitter, em contas de políticos, jornalistas ou influenciadores, e migram para outras redes. Considerando a possibilidade de produção artificial de trendings no Twitter, através do uso de robôs, os debates que são gerados podem representar um desequilíbrio no sistema político. Partindo de pesquisa bibliográfica e análise de documentos, este artigo faz uma reflexão sobre o modo como determinados procedimentos tecnológicos podem influenciar diretamente a formação da opinião pública.","Em 2006, o Facebook criou uma funcionalidade que viria a mudar as relações sociais no dia a dia e que, posteriormente, após diversas alterações, chegaria a interferir no debate político em eleições, o EdgeRank.1
Criado inicialmente por um engenheiro da empresa chamado Serkan Piantino, o EdgeRank é um conjunto de códigos que classifica um conteúdo na plataforma de acordo com três critérios básicos: a afinidade, o peso e a data em que foi criado aquele conteúdo. Em 2011, o Facebook abandonou o EdgeRank2
para usar um novo algoritmo,3
dessa vez com ""100.000 pesos individuais para produzir o feed de notícias"",4
segundo Lars Backstrom,5
para a revista MarTech.
O conjunto de códigos que se comunica com outro conjunto de códigos, a fim de estabelecer rotinas, padrões, comportamentos e de exibir, na tela do usuário, um determinado resultado para uma ação, denomina-se ""Interface de Programação de Aplicações"" (API, Application Programming Interface, em inglês). Por ser feita para comunicar com outras aplicações, a API é, na maioria das vezes, invisível ao usuário final. É através desses conjuntos de códigos que as redes sociais criam os feeds de notícias, que se popularizaram com características que são similares na maioria das redes sociais atuais: feed com rolagem infinita, puxar para atualizar, duplo clique para curtir e outras ações que transformaram a nossa rotina digital, o que propicia maior usabilidade e deixa a experiência dos interagentes mais intuitiva.
Esses comportamentos, redes e características criaram sistema de sugestão e exibição de conteúdo conhecido popularmente por algoritmo, um conjunto de API que estabelece critérios para exibir conteúdos na tela do usuário, buscando, na maioria das vezes, duas métricas: tempo de tela e interação. É através do tempo de tela que as plataformas conseguem mensurar o interesse do usuário, e é através da interação que as plataformas conseguem vender espaço para anunciantes.
Tanto o Twitter quanto o Facebook e as demais redes sociais sobrevivem dessa lógica. Criam API para se comunicarem com a interface, sugerindo conteúdo, buscando aumentar o tempo de tela e incentivando o usuário a interagir com outros interagentes nas plataformas, gerando dados para aumentar o interesse de anunciantes.
Esse interesse dos anunciantes acaba se tornando um dos principais, se não o principal, guia para construção de design, interface gráfica, cores e quaisquer outros elementos que consigam prender a atenção do usuário.6
A lógica econômica interfere e influencia diretamente na experiência do usuário, e, por serem empresas com bilhões de usuários ativos mensais,7
essa lógica acaba interferindo na internet como um todo. Algo análogo ao que Bourdieu (1996) chamou de ""subordinação estrutural"" dentro de um ""mercado de bens culturais"".
Esse universo relativamente autônomo (o que significa dizer também, é claro, relativamente dependente, em especial com relação ao campo econômico e ao campo político) dá lugar a uma economia às avessas, fundada, em sua lógica específica, na natureza mesma dos bens simbólicos, realidades de dupla face, mercadorias e significações, cujo valor propriamente simbólico e o valor mercantil permanecem relativamente independentes. (p. 162)
A mesma lógica aplica-se ao mundo da comunicação. Nesse sentido, ainda que haja uma transposição de realidades, seria possível compreender as redes sociais como produtos que se voltam aos interesses do mercado e aos interesses políticos ao mesmo tempo. Ou seja, acabamos conhecendo um algoritmo que serve para prender o usuário em retenção de tela, viabilizando o consumo de um produto, que pode estar diretamente atrelado a interesses políticos e econômicos. O comportamento do usuário, por sua vez, estruturado pela própria rede, será também estruturante, alimentando o algoritmo, gerando dados que o sofisticam cada vez mais.
Esse conceito é o que determina o sistema de inteligência artificial a aprendizado de máquina. Uma estrutura que aprende com a rotina dos usuários, criando um padrão de forma estruturante para novos conteúdos e novos usuários nas plataformas.
O sucesso das redes envolve diversas lógicas sociais e econômicas, mas é certo que esses algoritmos das redes são tratados como segredo de mercado. É natural compreender que qualquer funcionário de uma dessas redes sociais tenha em seu contrato a obrigação para assinar algum tipo de NDA (Acordo de Não Divulgação),8
garantindo que códigos, dados e processos ali desenvolvidos não sejam levados para outra empresa ou expostos na imprensa. O algoritmo pode ser considerado um dos capitais simbólicos de uma rede, e a capacidade do algoritmo reter o usuário na plataforma acaba se tornando segredo de mercado.
Da mesma maneira, também é compreensível que, pela quantidade de usuários e dados em suas plataformas,9
exista uma divisão de tarefas por equipes ou grupos. Cada equipe cuida de uma funcionalidade específica dentro da plataforma, seja como são disponibilizadas as fotos, seja como são enviadas as mensagens para um celular, seja ainda como é definida uma tarefa quando o usuário não está ativo. Há uma certa divisão manufatureira do trabalho na produção dessas redes, que gera uma espécie de alienação do trabalho produzido, quando um programador desenvolve uma API em específico para contribuir com um determinado algoritmo. A complexidade do trabalho impede que apenas um programador realize as rotinas; com isso, não há um entendimento por completo sobre como funcionam as regras de todos os serviços e sistemas dentro de uma plataforma. Esse elemento nos chama a atenção para o fato de que o comportamento de uma rede social não pode ser compreendido totalmente pelos seres humanos que a estruturam, o que nos faz questionar se é possível aplicar a ideia de intencionalidade e de responsabilidade às consequências das redes sociais. Disso decorre uma questão ética que demanda novos parâmetros de análise.
Um outro elemento importante para esse debate, para além do fato dos construtores das redes serem múltiplos e atuarem sem a compreensão do funcionamento total da plataforma, é o envolvimento dos interagentes na produção do próprio algoritmo. O usuário é, nesse sentido, também produtor do serviço que ele consome. Um exemplo disso pode ser visto em um experimento do Google chamado Google Quick Draw,10
pelo qual os próprios usuários ensinam um algoritmo de inteligência artificial a reconhecer formas e desenhos.
Com esses experimentos e esses códigos de inteligência artificial, as redes constroem o que é conhecido como machine learning12
ou o aprendizado de máquina, importante para o aprimoramento constante do feed de notícias no Facebook ou do feed de fotos no Instagram.13
A presença dessa tecnologia cria uma situação inédita nas relações midiáticas, porque também contribui para colocar sob suspeita a intencionalidade de uma comunicação. Os interagentes, ao buscar por assuntos de seu interesse, visitar páginas, clicar em links, curtir imagens e vídeos, fornecem informações que geram padrões de reconhecimento, alimentando o funcionamento do sistema. Dessa forma, o gosto e o interesse, ao darem início ao processo de coleta de dados, devolvem ao usuário informações em sintonia, alimentando e prolongando a perspectiva que deu início ao processo. Há, portanto, uma tendência de manutenção das perspectivas e opiniões. Contudo, essa relação sinérgica entre o interagente e as informações com as quais ele está interagindo cria uma abertura a novos conteúdos, produtos e perspectivas que pode ser muito persuasiva. As decisões passam a ser tomadas com a influência, ainda que parcial, dos algoritmos, e o aprendizado de máquina passa a ser um dos responsáveis por acertar de maneira cada vez mais precisa gostos, desejos e vontades dos usuários. Essa realidade cria uma tendência no marketing de produtos, que, ao ser aplicada ao marketing político, cria uma situação ética urgente, que precisa ser conhecida e debatida.
Este artigo procura contribuir para esse debate, questionando, a partir de características técnicas, o funcionamento das redes sociais do ponto de vista político. A partir de um olhar para o Twitter, o artigo pretende investigar a hipótese de que essa rede tecnossocial exerce influência sobre as demais redes, em especial sobre temas políticos. Pelas características da plataforma, é possível reconhecer o uso de robôs, capazes de deixar notícias, não necessariamente verdadeiras, entre os trending topics, o que gera, muitas vezes, debates orgânicos, inclusive em outras plataformas. Considerando a hipótese da agenda setting, tentamos olhar para o Twitter como uma plataforma que dita, muitas vezes, os temas debatidos nas interações sociais, independentemente de sua veracidade. Nesse sentido, emerge um debate ético sobre a forma como procedimentos tecnológicos influenciam diretamente a formação da opinião pública.
O Twitter é uma rede social com características muito específicas e que virou a preferida de muitos políticos. É bastante comum líderes usarem o Twitter para se comunicar virtualmente com sua audiência ou até mesmo anunciar em primeira mão políticas públicas pela plataforma. Com pouco mais de 16 milhões de usuários,14
o Twitter não é equivalente ao eleitorado brasileiro, mas, nos últimos anos, essa rede social passou a funcionar como um termômetro do debate político no Brasil e em muitos outros países.
A plataforma é recorrentemente um meio utilizado por autoridades para se comunicar diretamente com suas bases, o que a tornou uma ferramenta de tomada de decisões, além de, muitas vezes, pautar a imprensa e penetrar boa parte do debate político. No episódio número 96 podcast Foro de Teresina, produzido pela revista Piauí, um dos integrantes, o jornalista José Roberto de Toledo, faz uma análise do papel do Twitter em tempos em que as redes sociais com mais acesso são o Facebook, WhatsApp e Instagram. Diz Toledo que ""O Twitter não é um espelho da sociedade, mas sim um espelho do debate político, e ali o que a gente está medindo é o engajamento, a força dos atores e o quanto eles conseguem mobilizar suas bases"".15
Para entender essa métrica de engajamento e a importância do Twitter para os políticos e chefes de estado, uma agência de comunicação com sede em 6 países, a BCW,16
analisou o comportamento dos líderes em época de redes sociais, chamando esse estudo de ""nova diplomacia"", ou ""Twiplomacy"". O estudo analisou 1.089 contas17
de chefes de estado, governos e ministros de relações exteriores, mostrando diversos momentos e situações diplomáticas durante a pandemia.
No estudo, fica claro que os chefes de estado utilizam o Twitter para estabelecer relações com outros chefes de estado; com a sua população; para prestar contas para a população (accountability); e incentivar, durante a pandemia, a população a se cuidar. Por exemplo, o primeiro-ministro do Reino Unido, Boris Johnson, anunciou ""o primeiro gabinete digital"" pelo Twitter. E disse que a mensagem é ""fique em casa, proteja o sistema de saúde nacional, salve vidas"", conforme mostra a Figura 2.


É muito comum que figuras políticas postem uma frase, uma opinião no Twitter e, em seguida, tirem um print de seu tuíte e o utilizem em outras redes.18
Mas é muito incomum o contrário, encontrar algum print de uma postagem de outras redes (seja Facebook, Instagram ou qualquer outra) na linha do tempo de alguma figura pública no Twitter. Nesse sentido, é possível afirmar que, em algumas circunstâncias, o Twitter pauta outras redes sociais. Com esse engajamento e tipo de uso, é seguro dizer que o Twitter pode ser considerado um espelho do debate político e de seus atores, e não exatamente um espelho da sociedade. É no Twitter que está, de forma ativa, a maioria dos líderes políticos e é no Twitter que é possível mensurar, de forma mais detalhada, o volume de engajamento19
de determinados temas.
Essa mensuração só é possível, porque o Twitter tem uma característica determinante para que as análises políticas sejam realizadas. Possui uma API aberta para busca de conteúdo e extração de dados. O Facebook, o Instagram, o Google e o Youtube não fornecem dados precisos sobre o conteúdo de outras contas, sobre o conteúdo não proprietário. Ou seja, é impossível saber com precisão qual foi o alcance de um vídeo no Facebook, de uma foto no Instagram de um determinado perfil, mas é possível saber com precisão o engajamento de um tuíte de um líder político ou até mesmo de um tema.
Por exemplo, durante a construção deste artigo, um tema ganhou relevância nas redes sociais, a prisão do estrategista do presidente Donald Trump, Steve Bannon.20
Com um pouco de conhecimento técnico e algumas horas de programação, foi possível extrair diretamente da plataforma, de forma oficial, quais os conteúdos mais populares sobre o tema.21
Esse tipo de extração, ordenado por relevância, com métricas detalhadas e de forma oficial, não é permitido nem no Facebook, nem no Instagram e tampouco no YouTube. É possível também criar uma espécie de mapa de engajamento, conforme a Figura 3.


Dados do Twitter são relevantes porque podem indicar tanto o humor do momento quanto a mobilização de bases de apoio ou de oposição em relação a certo ator político ou assunto. Essa possibilidade de medir, em tempo real, a reação a uma fala, a um evento ou até a um programa de TV fez do Twitter o preferido para programas de televisão ou até mesmo para debates políticos.
Além da extração de dados, o Twitter criou um termo que se tornou popular a ponto de virar uma obsessão para grandes marcas, políticos e influenciadores: os trending topics. Uma palavra, uma frase ou um tópico que seja mencionado mais do que a média dos outros temas é considerado uma tendência. Essas tendências são listadas pelo próprio Twitter, indicando o que está sendo comentado no mundo ou em alguma região em específico.
É através dos trending topics, por exemplo, que é possível entender a reação de um público a um determinado discurso de um candidato durante um debate eleitoral. Ou através dos trending topics é possível investigar qual parte de uma entrevista divulgada em um canal está impactando mais o público. E é justamente nos trending topics que políticos baseiam algumas de suas ações nas redes.
O problema é que da mesma maneira que pelo Twitter é possível ter uma extração de dados de forma oficial, também é no Twitter que é possível criar mais facilmente robôs que interagem com outros perfis ou com determinado tema. Através de uma série de códigos, é possível, por exemplo, programar uma conta do Twitter para responder todos os tuítes que elogiem um determinado candidato, como também é possível criar uma rotina de programação que poste a cada 3 minutos um conteúdo aleatório com uma hashtag ou com uma palavra-chave.
Isso faz com que os robôs no Twitter ajudem a criar falsas tendências, inflando, muitas vezes de forma enganosa, uma propensão ao debate de um tema que, sem os robôs, não existiria. Esse comportamento não seria tão prejudicial se esses robôs criassem engajamento apenas entre si, mas, a partir do momento que um conteúdo criado por um robô se torna tendência, usuários reais, políticos e influenciadores digitais, em geral, passam a se engajar nesse mesmo tema. Um tema possivelmente inflado por uma conta falsa, através de um conjunto de códigos, pode despertar a curiosidade de um influenciador ou de um político e tornar-se um conteúdo orgânico em outra rede, como o Facebook ou o Instagram. O fato de um tema estar entre os trending topics indica maior possibilidade de engajamento nas postagens realizadas em contas sobre o mesmo tema. Ou seja, em busca da audiência, visando ao capital simbólico (Bourdieu, 1997), que repercute em capital econômico ou político, os trending topics, falsos ou verdadeiros, são alimentados por influenciadores e pessoas públicas, que não querem perder a oportunidade de manutenção ou crescimento se sua audiência.
Nesse sentido, essa situação nova permite o levantamento de uma hipótese polêmica, a de que o Twitter funcione como operador de agendas. Análogo à hipótese da agenda setting,22
o Twitter pode ser visto como uma autoridade de rede, que pode se realizar a partir da confluência entre a intencionalidade do programador e o uso dinâmico de rotinas de programação. Para compreender o ineditismo dessa situação, é preciso entender que há uma parcela de imprevisibilidade no algoritmo, que decorre do comportamento dos usuários, mas também da influência exercida pela API nesse comportamento.
Em um dos debates nas eleições presidenciais de 2018, o Twitter foi usado de forma institucional como métrica de mensuração de engajamento e como pauta de perguntas para os presidenciáveis. No debate da Gazeta, ocorrido em 8 de setembro de 2018,23
a hashtag #GazetaEstadaoJP, com o famoso ícone do Twitter, ficou na tela com a quantidade de vezes em que foi usada.
Além disso, durante os intervalos, um quadro com os ""candidatos mais mencionados no Twitter"" era exibido, com tuítes relevantes, escolhidos por uma curadoria do debate, mostrando algumas mensagens dos usuários.24
Elas chegaram a ser lidas pela equipe do debate e, após a exibição, a própria equipe informou que o número total de mensagens chegou a 171.374.
Vimos que o Twitter tem essa particularidade de fornecer dados públicos de métricas e engajamento com suas publicações. Mas como isso influencia outras redes? O Twitter acaba se tornando não um retrato fiel da sociedade, mas, sim, um retrato do debate político, no qual atores conseguem visualizar métricas através de dados que a própria plataforma disponibiliza. É possível medir o engajamento, a força dos agentes e o quanto cada político consegue mobilizar suas bases. É muito comum um debate se iniciar no Twitter e ganhar força a ponto de ficar visível na própria plataforma. À medida que cresce o engajamento dos usuários no tema, eles passam a exportar o debate para outras redes. De forma contrária, isso quase nunca acontece; é muito raro ver um debate se iniciar no Facebook, por exemplo, e migrar para o Twitter.
A forma como o feed se organiza e a agilidade da escrita são possíveis explicações para esse protagonismo. Outro fator está diretamente ligado às características trazidas pela Web 2.0: convergência digital e mobilidade, que permitem aos interagentes ações multifocais. A linguagem do Twitter aposta na impessoalidade, na velocidade e na interconexão de temas e debates. Uma pessoa diante da TV emitirá sua opinião no Twitter de forma imediata, como no exemplo do debate eleitoral da Gazeta/Estadão/Jovem Pan citado acima. Outro motivo significativo é a opacidade das outras redes. Não é possível saber o que está nos trending topics do Facebook, por exemplo. Por fim, o elemento mais importante: o algoritmo.
O fato de o Twitter ser uma rede transparente permite que pesquisadores estudem o comportamento das informações e encontrem pistas relevantes sobre a forma como o debate público ocorre na internet. Essa realidade é um fator a mais que motiva os profissionais do marketing político a usarem a rede social como espaço laboratorial para traçar estratégias de qualificação da imagem de candidatos e como caminho de interferência na conjuntura política, por meio da produção de debates na esfera pública. Essa interferência, muitas vezes, ocorre com o uso de robôs.
Em outubro de 2021, o Twitter publicou, através de seis pesquisadores, um artigo em uma revista acadêmica da Universidade de Cornell, Nova York. Nesse artigo, foram examinadas algumas características da rede: o algoritmo, a linha do tempo e como se comportam as postagens nessa linha do tempo. O objetivo era saber se existe uma amplificação ou priorização do conteúdo político de viés A ou B no algoritmo. A resposta que queriam encontrar é se políticos específicos teriam prioridade no algoritmo só por emitirem certas opiniões e pertencerem a determinados partidos políticos. A intencionalidade dessa pesquisa revela a preocupação da empresa com o potencial de interferência na formação da opinião pública e, ao mesmo tempo, denota uma atitude responsável.
Com ""centenas de milhões de tuítes""25
analisados em sete países, em um total de 2 milhões de contas, os pesquisadores fizeram uma pergunta crucial que permeou a pesquisa: “alguns tipos de grupos políticos são amplificados por algoritmos em detrimento a outros?”.
O resumo, publicado pelo blog da própria empresa, é que em seis dos sete países (todos, menos a Alemanha), os ""tuítes postados por contas de políticos alinhados a ideias de direita receberam mais amplificação algorítmica do que os tuítes de políticos alinhados à esquerda, quando estudados como um grupo"" (Huszár et al., 2021, p. 4). Esse resultado mostra que, por algum motivo, o algoritmo aprende, através de técnicas de machine learning, que é importante dar mais visibilidade a tuítes ligados à direita.
O estudo mostra que tuítes políticos têm maior amplificação simplesmente por serem tuítes políticos.26
E que políticos identificados como de direita têm uma relevância para o algoritmo ainda maior, simplesmente por serem de direita, seja qual for o conteúdo postado. ""Este efeito é mais forte no Canadá (liberais 43% versus 167% conservadores) e no Reino Unido (trabalhadores 112% versus conservadores 176%)"" (ibid., p. 5).
Outro dado interessante é que, apesar de grupos se comportarem com ampliação por algoritmo conforme demonstrado, ao se analisar individualmente as contas de políticos, alguns ligados à esquerda também têm seus tuítes amplificados, o que demonstra que não são necessariamente suas ideias, mas, talvez, como as expressam através de tuítes. Segundo o estudo,
Vemos que comparar os partidos políticos com base na amplificação agregada de todo o partido, ou com base na amplificação individual de seus membros, leva a conclusões aparentemente diferentes: enquanto a amplificação individual não está associada à filiação partidária, a amplificação do grupo agregado pode ser diferente para cada partido. Esses resultados não são contraditórios, considerando que diferentes políticos podem chegar a sobrepor audiências entre si. Mesmo que a amplificação de políticos individuais não esteja correlacionada com sua filiação política, quando consideramos aumentos em seu alcance combinado, podem surgir correlações em nível de grupo (Ibid., p. 5)
Em seu blog oficial, o Twitter declarou que essa amplificação do conteúdo é problemática, já que o algoritmo é construído de forma automática, através de sistemas de aprendizado de máquina, e que é necessária uma análise de causa mais profunda para determinar quais mudanças são necessárias para reduzir os impactos adversos do algoritmo na linha do tempo dos usuários.
O Twitter, portanto, reconhece a necessidade de agir de forma responsável e imparcial, compreendendo que o resultado da machine learning pode contribuir para distorções na formação da opinião pública. No entanto, a realização dessas correções enfrenta a dificuldade da complexidade do algoritmo, produzido por várias pessoas, que resulta na dificuldade de seu conhecimento absoluto.
O algoritmo virou uma realidade das redes. Tanto nas redes da empresa Meta, Facebook e Instagram, como no microblog Twitter e também no Google, o algoritmo funciona como um modo de otimizar performance e reter o usuário com mais tempo de tela. É plausível supor que, assim como no Twitter, o Facebook também tenha um algoritmo que privilegie conteúdos de direita. Essa hipótese é ainda mais sólida a partir da análise de um documento vazado por uma ex-funcionária do Facebook, Frances Haugen (G1 (2021)
, que disponibilizou, à imprensa, o que hoje é chamado de #FacebookPapers, um consórcio internacional de veículos que possuem acesso aos documentos revelados pela denunciante.
Os documentos falam sobre algo que é chamado de ""conteúdo cívico"", um tipo de informação que o Facebook aparentemente não define bem em lugar nenhum, mas envolve publicações em torno de política. No Brasil, três veículos tiveram acesso aos documentos vazados. Folha de S.Paulo (Mello e Alonso, 2021
), Estadão (2021)
e Núcleo (2021)
. Dentre o material produzido pelos veículos, é possível ter acesso a algumas partes em que se diz que, no Brasil, apenas 3% dos usuários concentraram boa parte do ""conteúdo cívico"" em sua plataforma no ano de 2018. Basicamente, essa ""voz cívica"" (termo usado pela empresa) está concentrada sob um pequeno grupo de atores. Mas, na ocasião, ninguém sabia ao certo o motivo pelo qual aquilo estaria ocorrendo. Assim como no Twitter, o aprendizado de máquina do algoritmo do Facebook produziu um resultado que os engenheiros não puderam prever.
Segundo a própria empresa, em comunicado enviado aos veículos que estão fazendo a cobertura (Spagnuolo, Martins e Menezes, 2021), esse resultado do algoritmo é preocupante por quatro motivos: usuários sentem-se silenciados, não confortáveis em participar; usuários podem estar perdendo conexões significativas ou ideias cívicas devido a um ranking sistemático; pode haver um número pequeno de usuários controlando o alcance massivo de informações, criando um risco elevado de desinformação viral;27
e existe a possibilidade da presença de redes subterrâneas de distribuição e com mau comportamento atuando no debate público.
São muitas perguntas em aberto: “Como quantificar o impacto desse processo para as eleições nos EUA, no Brasil, no Brexit28
ou em outros países?”; “Essa é uma tendência das redes ou da sociedade em geral?”; “Como fazer para equalizar o algoritmo?”.
O Twitter alterou sua linha do tempo em 2016, passando a se assemelhar a outras redes. Vimos que o EdgeRank, o primeiro sistema de algoritmo de linha do tempo em redes sociais, tornou-se referência e balizou o desenvolvimento das plataformas. Essas mudanças são fundamentais para se compreender como essas mudanças influenciaram o debate político como um todo.
Em entrevista com o cientista de dados da empresa Lagom Data,29
Marcelo Soares, foi perguntado sobre a lógica das redes no debate político. Soares respondeu que os algoritmos acabam contaminando o que deve e o que não deve ser notícia ou estar em destaque nos portais de notícia, baseado em número de cliques e potencial de viralização. É nesse sentido que o pensamento de Bourdieu (1997) contribui com uma nova perspectiva. Os profissionais de mídia passaram a entender o tipo de informação que gera mais engajamento e o horário mais eficiente de postagem. Com isso, em função da monetização, os profissionais passaram a priorizar conteúdos em detrimento de outros, gerando distorções preocupantes. Com Bourdieu, seria possível ampliar o leque de perguntas: “O resultado das eleições nos EUA, no Brasil e no Brexit não contou com uma cultura conservadora e individualista, distante da coisa pública e aderente a discursos superficiais?”.
Após 2016, quando houve eleições gerais no Facebook e surgiu o debate sobre uso de dados e sobre a empresa Cambridge Analytica,30
o Facebook tomou algumas medidas para impulsionamento de conteúdo e tráfego pago. A partir das próximas eleições, não seria mais possível impulsionar conteúdo pago para mensagens negativas sobre outros candidatos ou partidos, e todos os gastos com anúncios seriam transparentes,31
em uma ferramenta que a plataforma chamou de ""biblioteca de anúncios"".32
Seja em 2016 pelo próprio Facebook, seja recentemente pelo Twitter, é notório que o problema de privacidade de dados e priorização do algoritmo são temas constantes nas plataformas. Manyika, Silberg e Presten (2019), em artigo publicado na Harvard Business Review, repositório de artigos da Universidade de Harvard, investigam o viés humano nos algoritmos e nos sistemas de inteligência artificial. O artigo não deixa claro se há uma pesquisa específica em alguma das plataformas de maneira específica, mas mostra que há uma reprodução de preconceitos e priorização de certos temas, mesma conclusão a que chegaria o Twitter dois anos depois com um estudo interno.
Para solucionar esses preconceitos e o viés humano nos sistemas de inteligência artificial, propõem os autores que é necessário ter interferência humana nos sistemas de inteligência artificial, algo que chamam de ""human in the loop"",33
ou em uma tradução livre, ""humano no processo"". Para os pesquisadores, é necessário que sejam processados os dados de antemão, que se alterem algumas decisões do sistema e que sejam incorporadas definições de justiça no próprio processo de treinamento (ibid.).
Este artigo procurou apresentar alguns dados técnicos para compreender a realidade de funcionamento das redes tecnossociais, compreendendo seu comportamento a partir do funcionamento dos algoritmos. Além de caracterizar a forma como o debate público pode ser distorcido em função do machine learning, presente nas APIs, alertamos para o fato de que o universo tecnológico não é suficiente para compreender o comportamento das informações. O Twitter, por ser uma plataforma aberta, que permite a extração de dados, possibilita que pesquisadores tenham informações sobre o comportamento dos interagentes e possam cruzar essas informações com o comportamento das informações.
O processo de criação de dados nas redes e a priorização pelos algoritmos, que resulta em popularização ou viralização de conteúdo, acabam por influenciar a esfera pública, colonizam os debates presentes em espaços de sociabilidade e dão contornos ideológicos para as visões de mundo dos cidadãos. Ao que tudo indica, essas rotinas de programação fortalecem certo tipo de discurso e geram distorções na opinião pública.
A identificação do Twitter como a rede preferida de pessoas públicas, influenciadores, jornalistas e políticos profissionais, somada à possibilidade de se programar robôs para atuarem no comportamento das informações, leva-nos à questão central deste artigo. Se o Twitter usualmente prescreve os temas que serão exportados e debatidos em outras redes através de seus trending topics, saber que eles podem ser produzidos artificialmente nos obriga a questionar sobre a rede como operador ideológico.
Se, de fato, o Twitter é sujeito determinante na formação da agenda de outras redes, há que se relativizar o papel do algoritmo, que deixa de ser um protagonista que nos deixa na vala comum da casualidade e passa a ser um elemento maquínico de reforço de intencionalidades humanas. Trata-se de um sistema de inteligência artificial estruturado por uma inteligência humana e que estrutura comportamentos e discursos em um ciclo vicioso através do resultado dessa inteligência, mas que pode ser iniciado por uma meta política explícita, como a vitória em um processo eleitoral.
Mesmo que haja uma preocupação do Twitter com as possíveis distorções no debate público causado por seu algoritmo, seu modo de produção e a forma como envolve o machine learning apontam para a complexidade da situação. Rouvroy e Berns (2015)
alertam que
[...] nossos comportamentos jamais foram tão conduzidos – observados, registrados, classificados, avaliados – como agora com esta base estatística, e isto com base em função de códigos de inteligibilidade e critérios absolutamente opacos à compreensão humana. A inofensividade, a “passividade” do governo algorítmico é apenas aparente: o governo algorítmico “cria” uma realidade ao menos tanto quanto ele a registra. Ele suscita “necessidades” ou desejos de consumo, mas, desta maneira, despolitiza os critérios de acessos a certos lugares, bens ou serviços; ele desvaloriza a política (uma vez que não haveria mais nada a decidir, a resolver em situações de incertezas, posto que estas são antecipadamente desarmadas); o governo algorítmico dispensa as instituições, o debate público; ele substitui a prevenção (em proveito apenas da preempção). (Ibid., p. 48)
Segundo os autores, a situação a que nomeiam “governo algoritmo” reforça o processo de despolitização, retirando a possibilidade de tomada de decisões. Ora, se é possível concordar com os autores a respeito do universo subjetivo maquínico que se fabrica com a interferência de redes em nosso cotidiano, constantes no interior do universo de interações simbólicas; também é verdade que é possível relativizar o diagnóstico prescrito em relação à desvalorização da política. A situação em relação ao Twitter trazida por este artigo é uma circunstância em que se identifica a presença de intencionalidade, no momento em que se programam robôs para fabricar trending topics e consequentes viralizações na esfera digital discursiva. Paradoxalmente, esse argumento de valorização do papel da política aponta para um realismo que temos de combater politicamente. Uma distorção no desenvolvimento do debate político e da opinião pública, certamente, traz uma questão ética fundamental.
Por fim, mas não menos importante, é preciso reconhecer que o sucesso da expansão do debate conservador nas redes ultrapassa a atuação dos algoritmos. Ainda que haja essa intencionalidade por parte de alguns setores políticos, os robôs de forma isolada não seriam suficientes para explicar a facilidade com que determinadas informações viralizam. Grupos progressistas também se valem de robôs, mas o comportamento das informações não é tão eficiente, conforme demonstra a pesquisa de Huszár et al. (2021). A variável que faz a diferença no comportamento dos tipos discursivos é, possivelmente, a intensidade do engajamento, diferente nos dois grupos. É muito provável que o público mais conservador tenha um ativismo mais eficiente do que o público progressista, o que ativa o algoritmo de maneira mais contundente.
Nesse sentido, concluímos com um outro paradoxo. O elemento em que identificamos a presença política, que revela o engajamento de discursos conservadores e, muitas vezes reacionários, que explica a afinidade de determinadas ideias com os algoritmos das redes, é caracterizado pela despolitização. Esses comportamentos estão distantes do civismo, do comportamento coletivista e de esforços que buscam a formação de consensos. Esses comportamentos, em geral, alinham-se a comportamentos individualistas, que reduzem as decisões públicas a matemáticas simplistas, alimentando discursos de superfície e de banalização da política.







","['BELLI, L. (2021). Examining algorithmic amplification of political content on Twitter. Disponível em: https://blog.twitter.com/en_us/topics/company/2021/rml-politicalcontent Acesso em: 21 nov 2021.\n» https://blog.twitter.com/en_us/topics/company/2021/rml-politicalcontent', 'BOURDIEU, P. (1996). As regras da arte: gênese e estrutura do campo literário. São Paulo, Companhia das Letras.', 'BOURDIEU, P. (1997). Sobre a televisão. Rio de Janeiro, Jorge Zahar.', 'ESTADÃO (2021). Facebook Papers: grupo monopolizou conteúdo nas eleições brasileiras de 2018, Estadão. Disponível em: https://link.estadao.com.br/noticias/empresas,facebook-papers-grupo-monopolizou-conteudo-nas-eleicoes-brasileiras-de-2018,70003903253 Acesso em: 25 nov 2021.\n» https://link.estadao.com.br/noticias/empresas,facebook-papers-grupo-monopolizou-conteudo-nas-eleicoes-brasileiras-de-2018,70003903253', 'G1 (2021). Quem é Frances Haugen. Disponível em: https://g1.globo.com/tecnologia/noticia/2021/10/05/quem-e-frances-haugen-a-engenheira-que-quer-salvar-o-facebook.ghtml Acesso em: 21 nov 2021.\n» https://g1.globo.com/tecnologia/noticia/2021/10/05/quem-e-frances-haugen-a-engenheira-que-quer-salvar-o-facebook.ghtml', 'HUSZÁR, F. et al. (2021). Algorithmic Amplification of Politics on Twitter. Nova York, Cornell University, v. 1.', 'INTERVALO DE CONFIANÇA. (2019). Os institutos de pesquisa estão mentindo? Disponível em: https://intervalodeconfianca.com.br/2019/07/28/pauta-01-os-institutos-de-pesquisa-estao-mentindo/ Acesso em: 15 nov 2021.\n» https://intervalodeconfianca.com.br/2019/07/28/pauta-01-os-institutos-de-pesquisa-estao-mentindo/', 'MANYIKA, J.; SILBERG, J.; PRESTEN, B. (2019). What do we do about the biases in AI? Harvard Business Review. Disponível em: https://hbr.org/2019/10/what-do-we-do-about-the-biases-in-ai Acesso em: 29 nov 2021.\n» https://hbr.org/2019/10/what-do-we-do-about-the-biases-in-ai', 'McCOMBS, M. E.; SHAW, D. L. (2000). “A função do agendamento dos media, 1972”. In: TRAQUINA, N. O poder do jornalismo: análise e textos da teoria do agendamento. Coimbra, Minerva.', 'MCGEE, M. (2023). EdgeRank is dead: Facebook’s news feed algorithm now has close to 100k weight factors. Disponível em: https://martech.org/edgerank-is-dead-facebooks-news-feed-algorithm-now-has-close-to-100k-weight-factors/ Acesso em: 25 nov 2021.\n» https://martech.org/edgerank-is-dead-facebooks-news-feed-algorithm-now-has-close-to-100k-weight-factors/', 'MELLO, P. C.; ALONSO, L. (2021). Relatório do Facebook alerta para circulação de violência, mas empresa não prioriza Brasil. Folha de S.Paulo. Disponível em: https://www1.folha.uol.com.br/mundo/2021/11/relatorio-do-facebook-alerta-para-circulacao-de-violencia-na-plataforma-no-brasil.shtml Acesso em: 25 nov 2021.\n» https://www1.folha.uol.com.br/mundo/2021/11/relatorio-do-facebook-alerta-para-circulacao-de-violencia-na-plataforma-no-brasil.shtml', 'NÚCLEO (2021). A cobertura brasileira do Facebook Papers. Disponível em: https://www.nucleo.jor.br/fbpapers/ Acesso em: 15 nov 2021.\n» https://www.nucleo.jor.br/fbpapers/', 'ROUVROY, A.; BERNS, T. (2015). Tecnopolíticas e vigilância: governamentalidade algorítmica e perspectivas de emancipação: o díspar como condição de individuação pela relação? Revista EcoPós, v. 18. n. 2, pp. 1-7. Disponível em: https://revistaecopos.eco.ufrj.br/eco_pos/issue/view/254 Acesso em: 29 nov 2021.\n» https://revistaecopos.eco.ufrj.br/eco_pos/issue/view/254', 'SPAGNUOLO, S.; MARTINS, L.; MENEZES, S. (2021). No Facebook, poucos usuários concentram muito engajamento. Núcleo. Disponível em: https://www.nucleo.jor.br/reportagem/2021-11-25-concentracao-usuarios-facebook/ Acesso em: 23 nov 2021.\n» https://www.nucleo.jor.br/reportagem/2021-11-25-concentracao-usuarios-facebook/', 'TWIPLOMACY (2020). Twiplomacy Study 2020. Disponível em: https://twiplomacy.com/blog/twiplomacy-study-2020/ Acesso em: 14 nov 2021.\n» https://twiplomacy.com/blog/twiplomacy-study-2020/', 'TWITTER (2021). Examining algorithmic amplification of political content on Twitter. Disponível em: https://blog.twitter.com/en_us/topics/company/2021/rml-politicalcontent Acesso em: 15 nov 2021.\n» https://blog.twitter.com/en_us/topics/company/2021/rml-politicalcontent']","['Publicação nesta coleção\n04 Set 2023', 'Data do Fascículo\nSep-Dec 2023']","[' Rafael de Paula Aguiar Araújo ', ' Igor Fediczko Silva ']","[' Pontifícia Universidade Católica de São Paulo, Faculdade de Ciências Sociais, Programa de Estudos Pós-Graduados em Ciências Sociais. São Paulo, SP/Brasil.rafael.araujo1977@gmail.com', ' Pontifícia Universidade Católica de São Paulo, Faculdade de Ciências Sociais, Programa de Estudos Pós-Graduados em Ciências Sociais. São Paulo, SP/Brasil igordisco1@gmail.com']",http://www.scielo.br/scielo.php?script=sci_arttext&pid=S2236-99962023000301123&lang=pt,2024-11-21 09:59:37.001177,Scielo.org
Decisão judicial assistida por inteligência artificial e o Sistema Victor do Supremo Tribunal Federal,"A digitalização dos processos judiciais e a modernização dos sistemas dos tribunais impulsionaram o uso de inteligência artificial no Poder Judiciário, especialmente devido à sobrecarga de processos nas cortes superiores. O projeto Victor, liderado pelo STF e em colaboração com a Universidade de Brasília, busca automatizar a separação de Recursos Extraordinários por Tema de Repercussão Geral. No entanto, a aplicação da IA no setor público requer consideração dos princípios da legalidade, impessoalidade, moralidade, publicidade e eficiência estabelecidos na Constituição. O estudo aborda o conflito entre os princípios da eficiência e da legalidade em relação ao uso do programa Victor. A pesquisa incluiu histórico e tipos de IA, métodos de aprendizado de máquina e análise de softwares de IA em tribunais brasileiros. Os resultados destacam a eficiência do programa Victor, embora ressaltem problemas como resumos inadequados de decisões. A conclusão enfatiza a necessidade de transparência perante o uso de IA, propondo a adição de movimentações nos processos eletrônicos para indicar intervenção do Victor, permitindo revisões quando necessário.","A tecnologia das inteligências artificiais começou a ser estudada como disciplina acadêmica nos anos 1950. Desde aquela época, percebia-se o potencial disruptivo desse tipo de tecnologia. Além disso, já se discutia como seria possível fazer com que a máquina passasse a funcionar de forma similar ao cérebro humano.1
Desde então, as inteligências artificiais vêm sendo utilizadas nos mais diversos campos de estudo e ramos profissionais, dentre os quais encontramos o Direito.2
Foi nos anos 1970 que a intersecção entre Direito e inteligência artificial começou a ser identificada.3
Hoje, aproximadamente quarenta anos depois, já se discutem formas de controle da tecnologia de inteligências artificiais, tanto no âmbito estatal, quanto no âmbito privado. O temor é que a tecnologia avance para níveis nos quais a humanidade já não terá meios para controlá-la.4
Pode-se citar, por exemplo, a carta subscrita por mais de mil estudiosos do assunto - dentre os quais Elon Musk e Steven Wosniak - requerendo a suspensão de tecnologias de IA superiores ao ChatGPT 4 por um período de pelo menos seis meses.5
No campo do Direito, o grande temor dos estudiosos é que o uso de inteligências artificiais por órgãos julgadores acarrete a substituição de magistrados pela nova tecnologia. No Brasil, a inteligência artificial de maior relevância é aquela utilizada pelo Supremo Tribunal Federal - o Projeto Victor.
O Projeto Victor foi desenvolvido pelo STF em parceria com a Universidade de Brasília e participaram do projeto estudantes de Direito, Engenharia de Software, Informática e outros. O projeto tem duas funções principais: separar os documentos principais dos processos que chegam à corte superior e classificar os recursos por Tema de Repercussão Geral.
A IA Victor, por mais bem desenvolvida que seja, não está imune a limites. Evidentemente, o projeto foi criado para garantir mais eficiência no trâmite dos processos judiciais que entram no STF, realizando, supostamente, tarefas com mais rapidez e acurácia que servidores humanos.
Entretanto, uma análise cuidadosa e responsável do programa Victor deve ser realizada, por conta de dois problemas. Um deles, é um problema que pode acontecer na programação de qualquer inteligência artificial: o problema dos vieses. Outra questão a ser analisada - a da hipernormatização artificial - existe, em verdade, no próprio sistema de Repercussões Gerais e é intensificado pelo uso da IA Victor.
Se não analisadas cuidadosamente, essas duas questões podem fazer com que recursos que subam ao Supremo Tribunal Federal não sejam apreciados em sua integralidade. Se esse for o caso, um empreendimento que visou originalmente a garantia da eficiência acabaria por ofender o princípio da legalidade. Ter-se ia um conflito entre dois princípios elencados pela Constituição Federal no caput do art. 37, os quais vinculam a atuação da Administração Pública.
No presente trabalho, será apresentado primeiramente o contexto histórico da criação das Inteligências Artificiais, desde sua concepção nos campi dos Estados Unidos até sua inserção no mundo do Direito. Em seguida, serão apresentados em mais detalhes o problema dos vieses e da hipernormatização artificial, sendo apresentadas medidas estatais que visam remediar esse tipo de problema. Por fim, será realizada a análise da atuação do Projeto Victor sob a ótica do princípio da eficiência e do princípio da legalidade, sendo sugeridas medias para que a eficiência seja mantida e a legalidade integralmente respeitada.
O estudo da inteligência artificial e a origem dessa tecnologia podem ser traçados até a década de 1950. Nos Estados Unidos, houve uma confluência de estudiosos - matemáticos, engenheiros, psicólogos, neurocientistas - interessados em replicar a forma de pensar dos humanos nas máquinas. Entre os anos de 1950 e 1960, é possível citar três momentos que funcionaram como catalisador para a pesquisa das IAs: a Session on Learning Machines (1955); o Summer Research Program on Artificial Intelligence (1956) e o simpósio Mechanization of Thought Processes (1958).
A Session on Learning Machines foi realizada no âmbito da Conferência Conjunta de Computadores da Costa Oeste em Los Angeles (Western Joint Computer Conference in Los Angeles). Nessa conferência, o foco foi na discussão sobre como a máquina poderia copiar a atividade do sistema nervoso humano, com o reconhecimento de que a tecnologia na época era totalmente incapaz de criar uma inteligência sequer capaz de emular o pensamento humano.6
O Summer Research Program on Artificial Intelligence foi realizado na Universidade de Dartmouth. Houve significativo progresso nas premissas teóricas básicas para o funcionamento da inteligência artificial com relação às conclusões chegadas na conferência mencionada no parágrafo anterior. Em um requerimento para financiamento do programa à Fundação Rockefeller, o pesquisador Claude Shannon sintetizou como deveria ser traduzida a forma de pensar humana para a máquina: o comportamento humano, em todas as suas acepções, deveria ser descrito de forma sintética, lógica e precisa para que a máquina pudesse replicá-lo.7
No simpósio Mechanization of Thought Processes, as bases da linguagem que viria a funcionar como o input da inteligência artificial - a informação de entrada, que será processada e utilizada pela máquina para tomar uma decisão - foram estabelecidas, sobretudo no trabalho apresentado pelo cientista John McCarthy (1927-2011), denominado de Programs with Common Sense.8
Um ano depois do simpósio, em 1959, o termo machine learning, ou aprendizado de máquina, foi utilizado pela primeira vez.9
Nos anos 1960 e 1970, o estudo da Inteligência Artificial se concentrou na tentativa de fazer as máquinas reconhecerem objetos e imagens tridimensionais com o máximo de fidelidade ao cenário real possível. Além disso, é de 1967 o a criação do primeiro chatbot da história, chamado de Eliza. O robô foi programado para simular uma conversação, respondendo perguntas como se fosse um psicólogo.10
Ainda, foi nessa época que surgiram as primeiras IAs capazes de resolver jogos e quebra-cabeças. Contudo, o destaque para esse recorte temporal - e relevante para a presente pesquisa - é o interesse manifestado pelas grandes empresas de tecnologias e, sobretudo, pelo governo norte-americano, na figura do Departamento de Defesa11
. Isto é, percebe-se que pela primeira vez que um órgão da Administração Pública nota o potencial das tecnologias de inteligência artificial, ainda que o objetivo, na época, fosse a segurança nacional - o que faz sentido, considerando-se o contexto da Guerra Fria. Foi também nesse período que se começou a buscar aliar o uso da Inteligência Artificial ao Direito.12
Entretanto, a prolífica produção acadêmica no campo das Inteligências Artificiais arrefeceria no decorrer da década de 1980. Ainda que na década anterior os Estados tivessem começado a demonstrar interesse no uso dessa tecnologia, outras tecnologias de defesa ainda pareciam ser mais eficientes na defesa. Novamente, deve-se lembrar que a corrida armamentista ainda era uma prioridade para os Estados Unidos na década de 1980, ainda que não de forma tão intensa quanto na década de 1960.
A década de 1990 representou o maior salto relativo no âmbito das Inteligências Artificiais por uma razão - a difusão da Internet. Agora, as IAs dispunham de um reservatório de informações a serem usadas como input virtualmente infinitos, sobretudo com o surgimento do Google, também nesse período.13
Nos anos 2000, observamos o início da aplicação das IAs nos mais diversos campos. Foram instaladas em veículos para serem dirigidos automaticamente, em assistentes virtuais (Alexa, Cortana, Google Assistant), entre outros.14
Como relatado, desde o surgimento do termo Inteligência Artificial, foi percebido que a forma de torná-la mais eficiente era buscar copiar o funcionamento do raciocínio humano. Entretanto, o raciocínio humano possui por vezes um caráter intuitivo15
, inicialmente estranho às máquinas - estas recebem uma informação e, por uma série de proposições lógicas, chegam a um resultado. Já o ser humano, sobretudo em questões mais complexas, pondera os elementos lógicos de uma determinada proposição com questões culturais, emocionais e sociais para encontrar uma resposta. Essa forma de raciocínio é sobretudo relevante no Direito. De fato, não é incomum encontrar casos em que a lei se defronta com determinado princípio ou direito fundamental - estes com conteúdo normativo abstrato e, por vezes, subjetivo e casuístico.
No início do estudo das Inteligências Artificiais, as máquinas precisavam de um estoque de informações de entrada (input) e de orientações para chegar a um resultado (output). Esse método de programação das IAs, contudo, não é suficiente para realização de tarefas mais complexas. A forma encontrada para estreitar esse espaço entre o pensamento humano e o pensamento das máquinas foi o de fazer com que aprendessem a “pensar por si mesmas”. É o chamado machine learning.16
As inteligências artificiais podem ser classificadas em dois grandes grupos, que se dividem em outros menores. A primeira classificação é quanto ao tamanho do binômio input/output; a outra é quanto o nível de aprendizado da máquina.
Como classificação em input/output, podemos citar três tipos de IA: IA Focada, IA Generalizada e IA Superinteligente.17
Em essência, elas se diferem quanto à forma e a extensão das informações de entrada e de saída.
A IA Focada, ou IA Fraca, possui uma grande quantidade de dados armazenados para resolver uma tarefa específica. A IA Generalizada, ou IA Forte, não precisa, necessariamente, ter uma base de dados limitada ou realizar uma tarefa específica. Por meio dos algoritmos de sua programação e do machine learning,18
pode realizar tarefas e inferências lógicas mais complexas do que a IA Focada para realizar uma extensa lista de tarefas. É o estado atual das Inteligências Artificiais. Finalmente, pode-se citar as IAs Superinteligentes - estas superam os humanos em todas as tarefas. Ainda não existem e não se sabe se o ser humano será capaz de projetá-las.19
Quanto ao tipo de aprendizagem de máquina (machine learning), pode-se citar as seguintes: aprendizagem supervisionada, aprendizagem não supervisionada e aprendizagem por reforço.
A aprendizagem supervisionada, tanto o input como o output precisam ser, incialmente, controlados por um supervisor humano (ou outra IA20
). Essas IAs são comumente utilizadas para identificação. Por exemplo: é fornecido à máquina um produto de nome A que pertence à categoria X; um produto de nome B que pertence à categoria Y; e assim por diante. Dessa forma, caso um usuário hipotético requeira à máquina um exemplo de produto pertencente à categoria X, ela pode fornecer o exemplo do produto A21
. Importante ressaltar que, aqui, a máquina é, de certa forma, ensinada a pensar e a fornecer as respostas corretas por um supervisor.
Na aprendizagem não supervisionada, a IA tem somente as informações de entrada, sendo que encontra o output por conta própria22
. Nesse modelo, seguindo o exemplo citado no parágrafo anterior, a máquina recebe diversas informações iniciais, mas não a que categoria pertencem. Dessa forma, a própria máquina precisa agrupar as informações iniciais em clusters23
- grupo de informações com características em comum. Ao contrário do exemplo dado para a IA supervisionada, aqui, a IA não sabe de antemão que o produto X pertence à categoria A - ela chega a essa conclusão sozinha.
Há ainda a aprendizagem por reforço, muito utilizada em jogos eletrônicos e na robótica. Nesse modelo, a IA realiza uma série de suposições lógicas, sendo que ela é “recompensada” se a proposição for correta e “punida” se incorreta.24
Por fim, cita-se a forma mais avançada de aprendizado de máquina: deep learning. Se trata do atributo de a máquina conseguir resolver problemas de altíssima complexidade a partir do funcionamento de Redes Neurais Profundas (Deep Neural Networks). Considerando que a inteligência artificial funciona em camadas compostas por “neurônios artificiais”, nesse sistema de Redes Neurais Profundas, todos os neurônios de uma camada se conectam com todos os neurônios da camada seguinte. Isso permite melhor integração do sistema e um funcionamento mais harmônico, sendo capaz de resolver problemas progressivamente mais complexos.25
Para citar somente alguns exemplos, a tecnologia de deep learning vem sendo usada para tratar de algumas doenças como câncer, fibrose cardíaca, tuberculose, detecção de parasitas.26
O avanço nas tecnologias de IA permitem que ela seja utilizada em domínios onde antes acreditava-se que somente o pensamento humano poderia existir. É o caso do Direito. Ainda que, como já citado, não seja possível para a máquina copiar o elemento intuitivo do pensamento ou as nuances particulares de cada casa concreto, o uso de IAs Generalizadas e do método de deep learning permite aos profissionais do Direito uma atuação mais célere e precisa. Contudo, e isso é especialmente relevante para o âmbito do presente trabalho, não se deve esquecer que o uso da Inteligência Artificial pela Administração Pública e Pelo Poder Judiciário está inserida em um contexto em que existem limitações positivadas a seu exercício.27
Desde o início dos estudos em inteligência artificial no âmbito acadêmico, tem-se buscado aproximar, o máximo possível, a atuação da máquina à forma humana de pensar e raciocinar. Por essa razão, investe-se tanto em recursos compatíveis com o aprendizado de máquina (machine learning). Como relatado anteriormente, até mesmo o mecanismo de funcionamento de inteligências artificiais que utilizam machine learning busca copiar o funcionamento das redes neurais humanas. Em razão disso, muitos acreditam que diversas profissões - e isso inclui profissões da área do Direito - estão defasadas e que serão extintas em pouco tempo. Entretanto, as Inteligências Artificiais não são onipotentes, como se vê em filmes de ficção-científica e se argumenta em fóruns da internet.
Nesse mesmo sentido, é comum escutar que uma das principais vantagens da máquina com relação ao ser humano - e isso é especialmente válido para o ramo do Direito - é sua objetividade. Afinal, uma máquina que não tem sentimentos não poderia realizar um julgamento de um caso concreto maculado por noções subjetivas.
Esse primeiro argumento - da objetividade - é uma discussão antiga no campo da metodologia científica e não está subordinado ao estudo das inteligências artificiais. Muitos consideram que um magistrado, por exemplo, deve se distanciar o máximo possível do caso concreto para que a decisão seja objetivamente a mais adequada. Busca-se afastar a subjetividade do operador do Direito em prol de uma análise mecânica da realidade. Aí entraria o papel das inteligências artificiais no processo decisório, que seria, teoricamente, mais indicada para uma análise pragmática de casos jurídicos.
Contudo, assim como a discussão entre objetividade e subjetividade é antiga, também o é a constatação de que a objetividade pura é impossível de ser atingida. Isso porque quando se diz que uma determinada decisão não é objetiva, o indivíduo que realiza a acusação parte de uma análise subjetiva. Isto é, o próprio ato de apontar a subjetividade parte de um juízo de valor individual.28
A ilusão da objetividade da máquina também é quebrada quando se discute o problema dos vieses. Como será mostrado posteriormente, uma máquina pode tomar decisões e realizar análises enviesadas sem que ela tenha sido, efetivamente, programada intencionalmente com esse vício. Se uma determinada inteligência artificial - ainda que programada com mecanismos de deep learning - é criada com uma base de dados enviesadas em seu input, seu output estará, inevitavelmente, contaminado.
Especificamente no Direito brasileiro, o elemento subjetivo do processo decisório não pode ser menosprezado. Isso porque, em muitos casos, encontra-se soluções para casos concretos através da aplicação e do raciocínio através de princípios constitucionais. Não raramente, casos em que não existe previsão legal específica ou que não foram decididos anteriormente são decididos com base em uma análise principiológica.
No âmbito do Direito Administrativo, a discussão quanto à violação (ou não) de princípios administrativos está presente na maioria das ações envolvendo agentes públicos. Isso porque é impossível decidir o que que que seja, nessa esfera, sem que sejam levados em conta os princípios elencados no art. 37 da Constituição Federal aos quais a Administração Pública deve respeito: legalidade, impessoalidade, moralidade, publicidade e eficiência. Nessa área do Direito, a violação a princípios é de tamanha importância que é tipificada na Lei de Improbidade Administrativa (Lei n° 8.429/92, modificada pela Lei n° 14.230/21), em seu art. 9°.
Recentemente, com o advento do Chat GPT, o temor quanto à substituição do trabalhador humano pela máquina e a necessidade de regulação das tecnologias de inteligência artificial foram revigorados.
O ChatGPT, criado pela empresa americana Open AI e lançado no final de 2022, é uma espécie do gênero de inteligências artificiais conhecidas como Generative Pre-trained Transformer. Essa tecnologia funciona prevendo qual será a próxima palavra possível a ser incluída em um texto, sendo capaz de escrever textos complexos que simulam com relativa fidelidade a escrita humana. No ambiente acadêmico, discute-se novas formas de identificar a autenticidade dos trabalhos acadêmicos, uma vez que, em muitos casos, os textos criados pelo ChatGPT são indistinguíveis de um texto criado por um aluno médio.
Entretanto, no campo do Direito, o ChatGPT apresenta limites evidentes, alguns que podem ser ultrapassados com o tempo e outros que são impossíveis de ser contornados, seja por essa inteligência artificial específica ou por outras de forma geral.
Em estudo realizado na Universidade de Minnesota, o ChatGPT foi colocado para responder quatro provas em quatro matérias diferentes do curso de Direito: Direito Constitucional: Federalismo e Separação de Poderes; Benefícios Empregatícios; Taxação e Responsabilidade Civil. O resultado final, uma vez calculada a média das notas obtidas nas provas de cada disciplina - que incluíam questões de múltipla escolha e dissertativas - foi de C+, o que seria o equivalente, no Brasil, de uma nota entre 7,5 e 7,9. 29
Concluiu-se que o ChatGPT respondia de forma mista as questões discursivas: em algumas, apresentava respostas próximas àquelas de estudantes de alto nível e em outras errava totalmente. Nesse mesmo estudo, os pesquisadores apontaram para o fato de que, quando o ChatGPT errava determinada questão, errava de forma grosseira. Quanto às questões de múltipla escolha, o ChatGPT teve desempenho significativamente inferior ao obtido nas respostas discursivas. Isso se foi mais evidente em matérias que apresentavam questões envolvendo matemática: na matéria de Taxação, o ChatGPT acertou 8 questões de 29. 30
Foram detectados, nessa pesquisa, alguns problemas na redação das respostas discursivas pelo ChatGPT: em alguns casos, em questões com diversas perguntas, a primeira era respondida corretamente, enquanto que as demais apresentavam respostas totalmente desconexas com o tópico proposto. Além disso, em muitas respostas, a IA conseguia identificar qual seria o dispositivo legal e os precedentes a serem aplicados no caso concreto, mas não conseguia relacioná-los especificamente às circunstâncias. Em muitas questões, o ChatGPT também discorria extensamente sobre os temas propostos, apresentando conceitos, teorias e doutrinas que diziam respeito à temática do caso concreto, mas sem relacioná-los aos acontecimentos específicos propostos.
Ainda que uma ferramenta promissora, a Inteligência Artificial não tem capacidade para substituir um magistrado ou um advogado, podendo servir somente como ferramenta acessória. No caso do juiz, a máquina não tem o discernimento necessário para avaliar casos com base em princípios ou mesmo aplicar normas positivadas em casos concretos muito diferentes daqueles com os quais sua base de dados foi construída.
No caso dos advogados, ainda que uma defesa preliminar dos clientes, com pesquisas de precedentes e legislações aplicáveis, possa ser realizada, a revisão humana permanece sendo indispensável para casos mais complexos. Além disso, não se sabe se as máquinas são capazes de se adaptar às diferentes circunstâncias verificadas no decorrer de um processo judicial, ainda que tratem rigorosamente do mesmo assunto.
O uso da inteligência artificial é, entretanto, uma ferramenta de utilidade extrema para realização de atividades administrativas ou atividades-meio, ressalvada a possibilidade de supervisão humana e a necessidade de garantia da explicabilidade - revisão do jurisdicionado dos atos praticados pela inteligência artificial que afetaram seu direito subjetivo.
Como explicado no primeiro tópico, a tentativa de aliar o uso da inteligência artificial ao Direito data da década de 1970. Nos primeiros anos, a atividade da IA se restringia a encontrar documentos ou termos necessários para que o trabalho do servidor fosse facilitado. Nessa época, a IA era dirigida para funções específicas em áreas extremamente delimitadas do Direito.
Cite-se, por exemplo, o software TAXMAN, desenvolvido na Universidade de Rutger em Nova Jersey em 1972. O programa atuava na área de fiscalização de sociedades por ações e era direcionado para identificação de mudanças no contrato que resultassem (ou não) em isenções fiscais.31
Mais recentemente, em 2015, foi criado o sistema ROSS na Universidade de Toronto, com o auxílio da IA Watson da empresa americana IBM. O sistema se diferencia de outros do gênero por conseguir responder perguntas formuladas em linguagem natural (não-algorítmica) e sugerir, inclusive, leitura de doutrinas e decisões relevantes para a resolução do caso concreto. 32
No Brasil, a modernização e informatização do Poder Judiciário data do ano de 2001, com a Lei n° 10.259/2001, que institui o Juizado Especial no âmbito da Justiça Federal.33
Pela primeira vez, percebeu-se o cuidado do legislador, observando a tendência de avanços tecnológicos característica do início dos anos 2000, em deixar positivada a possibilidade de o Poder Judiciário recorrer aos meios eletrônicos quando necessário. No mesmo ano, o Supremo Tribunal Federal firmou convênio com o Banco Central do Brasil (BACEN) para instaurar a ferramenta de busca de bens denominada de BACENJUD (SISBAJUD, nos dias de hoje). 34
Percebe-se, entretanto, que nesse período não houve uso da Inteligência Artificial em si, tendo o início da década de 2000 funcionado com um prólogo para a modernização do Poder Judiciário brasileiro que ocorreria entre 2010 e hoje. Cita-se o ano de 2010 como uma virada de paradigma no âmbito da tecnologia da informação pois foi o ano de instauração do Processo Judicial Eletrônico (PJe) na Vara de Natal da Justiça Federal do Rio Grande do Norte.35
Contudo, conforme mostra relatório coordenado pelo Ministro Luis Felipe Salomão do STJ, junto à Fundação Getúlio Vargas, a explosão de projetos envolvendo Inteligências Artificiais no Judiciário ocorreu em 2018. Entre 2018 e junho de 2020 - apenas dois anos de diferença - foram encontrados 64 projetos de aplicação de IA em 47 tribunais do Brasil. A pesquisa inclui o Supremo Tribunal Federal (STF), o Superior Tribunal de Justiça (STJ), o Tribunal Superior do Trabalho (TST), os Tribunais Regionais do Trabalho, os Tribunais Regionais Federais e os Tribunais de Justiça.36
Deve-se levar em conta, ainda, que a pesquisa nem sequer inclui os projetos utilizados no âmbito da Administração Pública propriamente dita, como por exemplo, as IAs Alice, Monica e Sofia utilizadas pelo TCU.
Há ainda o sistema conhecido como Plataforma Sinapses, utilizado pelo Conselho Nacional de Justiça, implantado em 2018. A Plataforma, ainda que não seja uma Inteligência Artificial em si, tem como função principal a pesquisa desse tipo de tecnologia e como novos features podem ser incluídos em novas IAs e em IAs já existentes. Entre esse features, está o treinamento supervisionado de modelos que utilizam o machine learning.37
No Superior Tribunal de Justiça, a IA utilizada é conhecida como Sócrates e já está em sua versão 2.0. Já nessa versão, o sistema consegue compilar casos semelhantes e até mesmo indicar qual dispositivo de lei foi tido como violado - este último feature não disponível na primeira iteração do projeto.38
No Tribunal Superior do Trabalho, utiliza-se a IA conhecida como Bem-te-vi, que envia automaticamente para os gabinetes dos ministros os autos de processos com a mesma classe processual, com a informação adicional da tempestividade (ou não) da interposição de determinado recurso. 39
É necessário pontuar, aqui, que a modalidade de IA utilizada não pode ser outra que não a IA Supervisionada. Isso porque, ainda que a tempestividade seja somente um requisito de admissibilidade do recurso e aparente ser estritamente objetivo, existem casos em que a análise de um supervisor se faz importante. É a situação de necessidade de comprovação de feriado local para garantir a tempestividade do recurso, prevista no art. 1.003, §6° do CPC. A programação da IA deve estar intimamente ligada com a supervisão humana nesse caso, pois não seria de se espantar se a IA considerasse como intempestivo determinado recurso pois não possui a função de analisar feriados locais.
Outra inteligência artificial com atuação relevante no processo decisório da demanda é a IA Elis, utilizada pelo Tribunal de Justiça de Pernambuco (TJPE). Utilizada em processos de execução fiscal, ela consegue até mesmo verificar a competência do tribunal e a presença de prescrição40
.
Pode-se citar ainda as inteligências artificiais utilizadas pelo TCU: Alice, Sofia e Monica. Alice é o acrônimo de “Análise de Licitações e Editais” e tem como função auxiliar na análise da legalidade de um procedimento de licitação. Consegue, entre outras atividades: verificar certidões exigidas pelo TCU, o impedimento de empresas em contratar a Administração Pública, a concorrência entre sócios, etc. 41
. Já Monica e Sofia atuam no controle da atuação dos próprios auditores do TCU, verificando erros em textos ou informações que não foram relacionadas em outros processos correlatos.42
No quesito utilização do machine learning, o destaque vai para a IA Dra. Luzia, utilizada pelas Procuradorias Jurídicas dos estados. Ao contrário da maior parte das IAs utilizadas pelo Judiciário, a Dra. Luzia se utiliza do aprendizado de máquina para, além de monitorar prazo e gerenciar processo, elaborar petições de forma automática.43
Como discutido no tópico anterior, a capacidade decisória das Inteligências Artificiais ainda é limitada. Ainda que sua capacidade de processamento e organização de decisões seja infinitamente maios que a de um servidor público humano, a IA ainda tem dificuldade em captar elementos intuitivos de raciocínio que podem fazer com que a decisão de determinado caso penda para um lado ou para outro, sobretudo quando se discute ponderação de princípios. No direito brasileiro, cabe uma discussão quanto ao prejuízo (ou ausência dele), nesses casos, ao acesso à justiça e aos limites éticos da utilização da máquina.
Como relatado no tópico anterior, a IA ainda não está em um estágio em que pode ser aplicada sem supervisão. Isso é relevante na esfera do Direito e ainda mais quando se discute a atuação do Supremo Tribunal Federal, pois possui como função precípua a análise de casos em que algum direito constitucional ou mesmo fundamental está em jogo. Predominantemente, as Inteligências Artificias utilizadas no judiciário realizam atividades de natureza administrativa. Contudo, uma vez que a IA passe a interferir no processo decisório do magistrado, é importante apontar que ainda existem limites éticos - e, hoje em dia, legais - para sua aplicação, o que demanda a interferência e supervisão humana.
Uma das primeiras ilusões que se tem quanto à utilização da máquina para auxiliar em decisões é o de sua imparcialidade. É acreditada às IAs uma certa objetividade mecânica - como a máquina não possui valores ou posições políticas, acredita-se que suas decisões são imparciais e que possuem mais valor do que a decisão do humano.44
Isso sem contar a alegada maior capacidade técnica de produção de decisões, uma vez que dispõem como base de dados a totalidade da Internet ou dos precedentes dentro de um tribunal, por exemplo. Contudo, a máquina não está alheia a vieses e influências externas, mesmo que de forma não intencional.45
A tecnologia não existe dissociada do ambiente em que foi criada.46
Ainda que a Ciência venha buscando a replicação automática de máquinas já algum tempo - o que possui implicações éticas por si só - quase todas as inteligências artificiais foram programadas por um ser humano. O processo de funcionamento de uma IA, em termos gerais, é quase sempre o mesmo: recepção de output (informação de entrada), seguida do processamento e tendo como final o output. Por lógica, percebe-se que o output é totalmente dependente das duas etapas anteriores. Portanto, qualquer corrupção na entrada ou na forma de processar a informação pode resultar em uma formação enviesada. Como discutido, o problema é amplificado se essa informação enviesada prejudica o acesso à justiça ou até mesmo reproduz alguma forma de preconceito.
Esse fenômeno pode ser descrito como “valor implícito na inteligência artificial jurídica” (value embedded in legal artificial intelligence). Essa problemática vem sendo discutida desde as primeiras tentativas de automatização no serviço público, sobretudo na experiência norte-americana. Por valor implícito na inteligência artificial jurídica, entenda-se a presença de certas tendências implícitas na atuação da inteligência artificial, provenientes de sua própria programação ou não. 47
Existem casos em que valores implícitos podem estar presentes na atuação da IA por conta de sua programação. Por exemplo, cita-se o software COMPAS (Co Correctional Offender Management Profiling for Alternative Sanctions), utilizado por determinadas cortes de Justiça Criminal nos Estados Unidos, que busca prever a possibilidade de reincidência dos jurisdicionados. Esse software é programado com base nos dados obtidos através da atuação policial em determinados estados do país. Portanto, se os policiais atuam de forma injustificadamente mais dura contra determinadas minorias, o software acaba reproduzindo essa tendência e realizando previsões essencialmente racistas.48
Outra problemática a ser discutida no contexto de inteligências artificiais jurídicas, sobretudo quando utilizadas por magistrados, é o da hipernormatização artificial. Esse fenômeno não está restrito às inteligências artificiais, podendo ocorrer em qualquer sistema legal que utilize como base argumentativa os precedentes de cortes superiores.49
No caso específico do sistema de Repercussões Gerais, a hipernormatização pode ser detectada com facilidade.
A Repercussão Geral tem previsão nos arts. 1.035 a 1.041 do CPC e diz respeito ao julgamento de Recursos Extraordinários pelo STF onde se verifica a existência de questões relevantes do ponto de vista econômico, político, social ou jurídico que ultrapassem os interesses subjetivos do processo. Ao final do julgamento, a Corte elabora uma Tese: basicamente, um resumo com os principais elementos fáticos e jurídicos que originaram a decisão. Contudo, há ocasiões em que a Tese elaborada não engloba todo o conteúdo dos votos dos Ministros. Dessa forma, se a Tese for excessivamente simplificada, pedidos em instâncias inferiores, que possuíam as condições para deferimento previstas nos votos originais dos Ministros do STF - mas não na Tese de Repercussão Geral - poderiam vir a ser indeferidos. Esse é o fenômeno conhecido como hipernormatização. A partir do momento em que casos passam a ser movimentados no STF por uma Inteligência Artificial, com base nas Teses de Repercussão Geral, o fenômeno a ser observado passa se chamar hipernormatização artificial.
Fausto Santos de Morais afirma que a hipernormatização artificial pode ocorrer em virtude de duas classes de fatores diferentes: fatores normativos e fatores fáticos. A hipernormatização por fatores normativos acontece quando um julgador aplica a determinado caso uma regra originária, ainda que, com o passar do tempo, a aplicação daquela regra originária tenha sido alterada50
.
Para exemplificar, pode-se citar a Teoria da Taxatividade Mitigada, aplicada para definir o cabimento de Agravos de Instrumento. Esse recurso tem previsão no art. 1.015 do CPC e é utilizado para combater as decisões interlocutórias que versam sobre as matérias previstas nos dispositivos.51
Até 2018, a maior parte dos julgados entedia que o rol apresentado no art. 1.015 era taxativo - as hipóteses de interposição de Agravo de Instrumento eram limitadas àquelas elencadas no dispositivo. Contudo, o STJ, no REsp 1696396/MT e no REsp 1704520/MT, ambos de relatoria da Ministra Nancy Andrighi, entenderam que o rol do art. 1.015 seria de taxatividade mitigada, isto é, poder-se-ia interpor Agravo de Instrumento contra decisões não abarcadas pelo dispositivo, contanto que fosse verificada urgência decorrente da inutilidade do julgamento da questão no recurso de apelação. Retornando ao fato normativo da hipernormatividade artificial, é evidente que a máquina teria muita dificuldade em decidir qualquer coisa, mesmo que para triar os recursos, com base em uma interpretação jurídica subjetiva que - em uma visão binária - contraria o que está escrito no art. 1.015.
Há também o fator fático, já discutido anteriormente. É o caso da simplificação exagerada da Tese de Repercussão Geral que deixa de mencionar elementos fáticos que foram relevantes para as decisões nos votos dos Ministros do STF. Exemplo disso é a Tese fixada no RE 494.601/RS. A tese afirma tão somente que o sacrifício de animais em cerimônias de religiões de matriz africana é constitucional. Entretanto, a íntegra da decisão dos ministros condicionava essa constitucionalidade a dois fatores: que o animal sacrificado não sofresse e que sua carne fosse consumida no ritual. Portanto, determinada cerimônia de culto africano que sacrifique um animal sem observar os dois requisitos anteriores não é constitucional pela decisão dos ministros, mas o é pela simplificação da Tese.52
Diante do problema dos vieses, da hipernormatização artificial e outros problemas de natureza ética decorrentes do uso de Inteligências Artificiais no Judiciário, verifica-se que existem discussões em diversos foros quanto à regulação dessa forma emergente de tecnologia. É essencial que o avanço da tecnologia não relegue a segundo o plano o respeito aos direitos fundamentais, devendo, em verdade, contribuir para que sejam garantidas de forma ainda mais eficiente.53
Em 2018, a Comissão Europeia pela Eficiência da Justiça (CEPEJ) elaborou um documento com diretrizes gerais e princípios a serem observados pelo Poder Judiciário quando da instalação de inteligências artificiais. A “Carta Europeia de Ética sobre o Uso da Inteligência Artificial em Sistemas Judiciais e seu ambiente” elenca 5 princípios: o respeito aos direitos fundamentais; a não discriminação, tanto entre indivíduos como entre grupos; a qualidade e a segurança, a fim de manter o funcionamento adequado do sistema jurisdicional; os princípios de transparência, imparcialidade e equidade ‘sob controle do usuário.54
O cuidado por parte do Poder Público com relação à aplicação de inteligências artificiais deve possuir prioridade, até porque a imagem do Brasil pode vir a ser maculada no cenário internacional por eventuais falhas. Isso porque a Agenda 2030 da ONU preceitua como um dos 17 Objetivos do Desenvolvimento Sustentável o fortalecimento do Poder Judiciário e de instituições. Com relação à Inteligência Artificial jurídica, merece destaque os objetivos 16.3, 16.6 e 16.7 da Agenda: 16.3 - Promover o Estado de Direito, em nível nacional e internacional, e garantir a igualdade de acesso à justiça para todos, 16.6 - Desenvolver instituições eficazes, responsáveis e transparentes em todos os níveis, 16.7 - Garantir a tomada de decisão responsiva, inclusiva, participativa e representativa em todos os níveis. 55
Seguindo a tendência europeia de controle da Inteligência Artificial, o CNJ redigiu a Resolução n° 332/2020, que versa sobre o controle do uso das IAs no âmbito do Poder Judiciário. Assim como na “Carta Europeia de Ética sobre o Uso da Inteligência Artificial em Sistemas Judiciais e seus ambientes”, a resolução preza pelos Direitos Fundamentais (Capítulo II), pela Não-Discriminação (Capítulo III), pela Publicidade e Transparência (Capítulo IV). Vale ressaltar que o Capítulo IX da resolução é inteiramente dedicado ao controle do uso da IA no Judiciário pelos usuários, estabelecendo como deve funcionar a prestação de contas nos órgãos que se utilizam da tecnologia para auxílio na tomada de decisão.
“Carta Europeia de Ética sobre o Uso da Inteligência Artificial em Sistemas Judiciais e seus ambientes”, a resolução preza pelos Direitos Fundamentais (Capítulo II), pela Não-Discriminação (Capítulo III), pela Publicidade e Transparência (Capítulo IV). Vale ressaltar que o Capítulo IX da resolução é inteiramente dedicado ao controle do uso da IA no Judiciário pelos usuários, estabelecendo como deve funcionar a prestação de contas nos órgãos que se utilizam da tecnologia para auxílio na tomada de decisão.
Quanto ao tema desse último capítulo da Resolução n° 332/2020 do CNJ, Juarez Freitas e Thomas Bellini Freitas anotam a importância do que chamam como explicabilidade, como “diretriz mandatória e ética” para a Inteligência Artificial. Trazem à tona, ainda, a importância do controle de dados e revisão de decisões automatizadas pelo usuário - agora uma possibilidade positivada pela LGPD, em seu art. 20.56
Hoje, a Inteligência Artificial chegou em um ponto onde se discute os limites quanto à sua capacidade de decidir por conta própria. Entretanto, nem sempre foi esse o caso, sobretudo no Judiciário.
Como relatado, ainda que a tecnologia das Inteligências Artificiais, desde o princípio, buscasse imitar o funcionamento do cérebro humano, a sua inserção no Poder Judiciário foi realizada (e ainda é) com parcimônia. Desde o princípio, foi identificado que seu uso não podia ser difundido sem complexas discussões éticas quanto aos efeitos que decisões artificiais teriam sobre os direitos subjetivos das partes.
Por essa razão, a tecnologia da informação foi inserida no Judiciário para auxiliar servidores em funções integralmente administrativas. Entendeu-se que a modernização dos sistemas de gestão dos tribunais teria relação direta com a melhora da eficiência da prestação jurisdicional 57
. No início, a modernização dos processos judiciais teve como objetivo facilitar a busca por documentos, o protocolo de petições, a contagem de prazos, etc. Há não muito tempo, os processos judiciais eletrônicos ainda não eram amplamente difundidos. Ainda hoje, há tribunais no Brasil que ainda fazem uso do processo físico. O processo de modernização que teve início com a implantação do PJe em 2010 teve como consequência a utilização massificada de outros sistemas de processos eletrônicos, como o Projudi, EPROC, Esaj e outros.
Para Boaventura de Sousa Santos, a modernização dos processos judiciais se deu em quatro eixos principais: no dos Recursos Humanos, no da comunicação interna dos tribunais, no da gestão de processos e no da comunicação com o público. No campo dos Recursos Humanos, o efeito seria o da redução de funcionários para administrativos e aumento da eficácia. No da comunicação interna, haveria uniformização de procedimentos processuais em tribunais usuários do mesmo software jurídico. Quanto à gestão do processo, a consequência óbvia é a da maior agilidade e eliminação de tarefas repetitivas - que passam a ser realizadas por programas e não mais por servidores. No âmbito da comunicação com o público, o processo eletrônico contribui para a democratização da justiça, na medida em que torna mais fácil às partes buscar informações sobre seus processos de forma autônoma.58
O impacto positivo da modernização do Poder Judiciário é evidente. De acordo com pesquisa realizada pelo CNJ, ao final de 2019, havia 77,1 milhões de processos em tramitação. No ano seguinte, em 2020, com o advento da pandemia de COVID-19, o temor era de que o sistema judiciário simplesmente implodisse, uma vez que não se sabia como seriam contados os prazos e como seriam realizadas as audiências, para citar apenas alguns exemplos. Entretanto, O CNJ agiu de forma relativamente célere, consideradas as circunstâncias, em relegar as audiências para a modalidade on-line e tornar os processos quase que integralmente eletrônicos - tendência essa que se mantém até hoje.
Quanto ao uso das Inteligências Artificiais propriamente ditas, sua influência na gestão de processos judiciais pode ser identificada em sete vertentes principais, de acordo com o Ministro do STJ Luis Felipe Salomão: busca de jurisprudência avançada; resolução de disputas on-line; análise preditiva de decisões; triagem de processos; agrupamento por similaridade de jurisprudência; transcrição de voz para textos com contexto; geração semiautomática de peças; dentre outras.
Para Juan Gustavo Corvalán (2017), se usada corretamente, a Inteligência Artificial teria o condão de não somente resolver problemas de gestão com maior agilidade, mas também de resolver problemas para os quais nem sequer havia solução: “Pero además, el uso de la inteligencia artificial podrá optimizar el flujo de datos y de información a disposición de las Administraciones y resolver cuestiones que antes requerían múltiples pasos, procedimientos y fases. O que, incluso, ni siquiera podían resolverse. Una inteligencia artificial bien entrenada, con acceso al flujo informativo, simplifica y facilita exponencialmente las actividades de una organización y puede obtener resultados que serían imposibles de lograr con los cerebros humanos.”59
É tentador buscar relegar à máquina a maioria dos procedimentos administrativos que acontecem dentro do Poder Judiciário. Entretanto, é importante que seja feita a distinção entre os procedimentos integralmente administrativos daqueles que influem diretamente no processo decisório. Como explicitado, o uso da inteligência artificial no Judiciário deve existir somente enquanto garante dos direitos fundamentais das partes em litígio. Além disso, justamente por muitas vezes essa distinção não existir de forma clara é que as disposições legais que prezam pela publicidade dos atos realizados com auxílio de IA são tão relevantes. Na medida em que a eficácia do procedimento, logicamente, aumenta, o requisito da explicabilidade deve ser observado, a fim de que a eficácia não seja colocada sobre outros direitos constitucionais e fundamentais.
No lado dos advogados, o uso da Inteligência Artificial ajudaria substancialmente em duas atividades: recuperação de dados e predição de decisões judiciais. Por recuperação de dados, entende-se a pesquisa jurisprudencial. De fato, essas atividades poderiam vir a ser integralmente substituídas pelas máquinas.60
A prestação da assessoria jurídica pode ser incrementada com inteligências artificiais que realizem esse tipo de atividade. Uma consulta inicial entre um advogado e seu cliente pode ser muito mais precisa, no que diz respeito à matriz de risco oferecida e as chances de sucesso de um processo, se a inteligência artificial buscar por conta própria todos os precedentes relevantes para o caso concreto e sugerir qual será a decisão do tribunal que receberá a demanda.
Nesse contexto, já existem programas de Inteligência Artificial que são capazes de elaborar petições por conta própria. Nos Estados Unidos, pode-se citar o sistema ROSS - um programa desenvolvido a partir da IA Watson, da empresa IBM, para responder questionamentos jurídicos realizados em linguagem natural. Nesse aspecto, a capacidade da inteligência artificial é tão mais avançada quanto consegue conciliar os aspectos semânticos, pragmáticos e sintáticos da linguagem natural e traduzi-las em código61
. No Brasil, observamos a IA Dra. Luzia nas Procuradorias Jurídicas de alguns estados, já capaz de elaborar determinados tipos de requerimento. Mais recentemente, foi lançada a Inteligência Artificial Chat-GPT pela empresa Open-AI. O software já está em sua versão 4.0 e responde perguntas em linguagem natural, assim como o ROSS. Entretanto, seu escopo de atuação não se restringe ao campo jurídico, respondendo com relativa exatidão uma vasta gama de questionamentos.
No relatório “Justiça em números 2022”, elaborado pelo CNJ, foi relatado que houve ajuizamento de 27 milhões de novos processos, de forma eletrônica, em 2021. No recorte histórico estudado pelo Conselho Nacional de Justiça, compreendendo o período de 2013 até 2021, foram ajuizados 182,7 milhões de novos casos.62
No mesmo ano, a despesa total com o Poder Judiciário calculada pelo CNJ totalizou o valor de R$ 103,9 bilhões.63
No caso específico do STF, verificou-se redução na entrada dos processos a partir da criação do instituto da Repercussão Geral pela Emenda Constitucional n° 45/2004. Entretanto, a partir de 2018, mais de 100 mil processos ingressaram para análise da Corte Superior - estatística não atingida desde 2007.64
Foi a partir desse cenário que a ideia para a elaboração da inteligência artificial Victor se originou, em 2017. Nesse ano, ainda que fosse perceptível o aumento de demandas que chegavam ao STF, o tribunal dispunha de uma tecnologia informática defasada em pelo menos 10 anos.65
O projeto de inteligência artificial jurídica foi denominado de “Projeto de Pesquisa e Desenvolvimento de aprendizado de máquina sobre dados judiciais das repercussões gerais no Supremo Tribunal Federal”. Foi realizado mediante convênio com a Universidade de Brasília (UnB), a partir dos trabalhos de acadêmicos dos cursos de Direito, Engenharia de Software e Ciência da Computação. 66
Dentro do STF, houve discussão sobre qual seria o setor adequado para desenvolver o projeto e supervisionar os trabalhos. No final, foi constatado que seria impossível para a Secretaria de Tecnologia da Informação do Tribunal (STI/STF) conciliar os trabalhos padrão da rotina comum do Supremo Tribunal Federal com o processo de desenvolvimento do Victor, sobretudo quando se consideram as dificuldades técnicas e a defasagem na infraestrutura tecnológica do tribunal na época. No fim, foi decidido que a STI/STF seria a supervisora do projeto, deixando sua execução aos acadêmicos dos cursos mencionados anteriormente.67
O instituto legal encontrado pelo STF - na época, sob presidência da Ministra Carmen Lúcia - para firmar parceria com a UnB, foi o do Termo de Execução Descentralizada (TED), previsto pelo Decreto n° 8.180/2013.68
Esse instrumento é utilizado para ajustar a descentralização de crédito entre órgãos e/ou entidades integrantes dos Orçamentos Fiscal e da Seguridade Social da União, para execução de ações de interesse da unidade orçamentária descentralizadora e consecução do objeto previsto no programa de trabalho, respeitada fielmente a classificação funcional programática, nos termos do Decreto.
Uma das partes mais complexas para instauração do projeto foi o contato com os agentes externos ao STF. Além do formato de contratação mencionado no parágrafo anterior, outras variáveis precisaram ser analisadas. Para Eduardo S. Toledo, fora a forma de contratação, outros cinco elementos precisaram ser analisados antes que o projeto de instauração do Victor tivesse início: definição do objeto, aceitação do projeto pelos ministros, tempo de execução, transcendência dos benefícios e absorção da tecnologia pela Administração Pública.69
A definição do objeto diz respeito à forma da tecnologia adotada e como ela seria aplicada. No caso do Victor, buscou-se conciliar a construção de uma base de dados robusta com os temas de repercussão geral com a tecnologia de machine learning. Como a função principal do Projeto Victor seria a divisão de recursos em temas de repercussão geral, a capacidade de previsão baseada programação algorítmica - característica do machine learning - seria essencial70
. Conforme Mamede Said Maia Filho e Tainá Aguiar Junquilho71
: “Após o estudo dos dados das repercussões gerais para estruturação e preparação para treinamento dos modelos de aprendizado de máquina supervisionados e não supervisionados, o projeto desenvolverá pesquisa dos possíveis algoritmos e estratégias de treinamento mais eficientes para o contexto estudado, englobando redes neurais artificiais profundas, para, em seguida, realizar a prototipação e treinamento dos algoritmos escolhidos, incluindo a sua avaliação.”
Em seguida, seria necessário obter aprovação dos Ministros do STF em si. Evidentemente, o projeto Victor não teria como prosseguir se os usuários últimos de suas funcionalidades não o considerassem adequado. O projeto deveria ter, em primeiro lugar, o aceite da então presidente da corte, Ministra Carmen Lúcia e do Vice-Presidente, Ministro Dias Toffoli. Com o aceite dos dois ministros e dos demais, o projeto pôde prosseguir.
Como relatado no início do presente tópico, a aplicação do projeto tinha caráter urgente. Por isso, seu tempo de execução - prazo entre o início do projeto e as primeiras demonstrações da IA - não poderia ser longo. Por fim, foi necessário considerar a potencialização dos resultados e como a tecnologia seria desenvolvida pela Administração Pública. De fato, o projeto Victor esteve entre os primeiros projetos de otimização da gestão do Poder Judiciário e teve direto impacto na iniciativa de instauração de tecnologias similares em tribunais de instâncias inferiores ao STF e mesmo em órgãos da Administração Pública.72
Vale ressaltar que foi discutido nos momentos essenciais do projeto em qual etapa do processo decisório uma inteligência artificial poderia ser inserida sem que houvesse usurpação das atividades de julgamento indelegáveis dos ministros.
A partir disso, as etapas delegadas ao Victor foram as de classificação de tipos de documento e de separação de recursos extraordinários e agravos em recursos extraordinários por temas de repercussão geral.73
Quanto à primeira atribuição da IA do STF, diz respeito ao fato de que os autos dos processos nas instâncias inferiores chegam ao STF de forma não padronizada: arquivos sem indicação de qual peça representam, arquivos com imagens, arquivos com elementos probatórios manuscritos, etc. Uma das funções do Victor seria a classificação automática desses documentos.
Quanto à segunda atribuição, o projeto Victor busca encontrar qual (ou quais) temas de Repercussão Geral se aplicam aos AREs e Res que sobem até o STF. Nessa etapa, se não houver uma fiscalização de servidor humano final, pode-se verificar o problema da hipernormatização artificial, como se discutirá no tópico 4.3.
O objetivo primordial do Projeto Victor é a classificação dos processos que chegam ao Supremo Tribunal Federal em temas de Repercussão Geral. O sistema de repercussões gerais tem previsão na Constituição Federal, em seu art. 102, § 3°, sendo manifestação do objetivo de guarda da norma constitucional dado pelo caput. Leia-se: “Art. 102. Compete ao Supremo Tribunal Federal, precipuamente, a guarda da Constituição, cabendo-lhe: § 3º No recurso extraordinário o recorrente deverá demonstrar a repercussão geral das questões constitucionais discutidas no caso, nos termos da lei, a fim de que o Tribunal examine a admissão do recurso, somente podendo recusá-lo pela manifestação de dois terços de seus membros”.
Em termos gerais, o sistema de Repercussão Geral é uma técnica processual emprestada de sistemas que utilizam o método decisório chamado de case-based reasoning, tipicamente utilizado em sistemas de common law. Por esse instituto jurídico, utiliza-se um caso paradigma - onde se reconhece a repercussão econômica, social, política ou jurídica da temática discutida - para se elaborar uma solução comum a casos que discutam a mesma matéria. A partir desse princípio, busca-se maior uniformidade na aplicação do Direito por parte dos Magistrados, uma vez que devem deferência não somente à lei, mas ao entendimento firmado nos tribunais superiores, sob pena de reforma de sua decisão.74
No Brasil, além do sistema de Repercussões Gerais, o Código de Processo Civil empresta da common law a necessidade de uniformização da jurisprudência. De fato, o sistema de Repercussão Geral nada mais é do que um dos meios para consecução desse objetivo75
.
No Supremo Tribunal Federal, o procedimento de estabelecimento da Repercussão Geral funciona da seguinte forma: determinado processo chega à corte superior e os ministros reconhecem que a temática discutida ultrapassa os interesses subjetivos das partes. Após esse reconhecimento, os processos que versam sobre o mesmo tema nas instâncias inferiores são suspensos 76
. Perceba-se que nessa etapa ainda não houve decisão quanto ao mérito da questão. O reconhecimento da Repercussão Geral em si tem como objetivo o sobrestamento dos recursos em outras instâncias, para que não haja conflito com relação ao Tema de Repercussão Geral decidido - esse sim a decisão final do STF sobre a matéria que deve ser aplicada pelos juízes e tribunais em todo o território nacional.
Contudo, no contexto de implementação do Projeto Victor, a inteligência artificial precisou ser treinada em um uma etapa anterior à análise quanto à Repercussão Geral. Como existem muitos sistemas de processo eletrônico no Brasil, cada um com suas particularidades quanto à digitalização das peças, separação dos movimentos processuais e divisão de arquivos, os processos que chegam ao STF não estão divididos uniformemente. Isto é, antes da implementação do Projeto Victor, as secretarias do STF realizavam um trabalho manual de separação das peças processuais mais utilizadas pelos Ministros para solução da demanda.
Conclui-se que essa etapa poderia ser realizada por uma Inteligência Artificial. Para tanto, foi necessário treinar o sistema Victor com uma vasta base de dados composta por diversas peças processuais. Nessa etapa da implementação do projeto, o treinamento foi realizado separando-se as peças em seis grupos: despachos, sentenças, acórdãos, Recursos Especiais, Agravos em Recursos Especiais e outros. Posteriormente, foi feita uma análise das peças classificadas pelo Victor por operadores humanos, a fim de identificar a acurácia das previsões realizadas pelo sistema. Concluiu-se que, nessa etapa - de separação das peças - a assertividade foi de aproximadamente 93%.77
Realizado o treinamento da IA quanto à separação e reconhecimento dos principais documentos para análise, passa-se à vinculação dos processos por temas de repercussão geral.
Quando um recurso chega ao STF, uma análise preliminar quanto à Repercussão Geral é realizada, que pode ter três resultados possíveis: recurso sem repercussão, recursos sem definição de repercussão e recursos com repercussão definida. No primeiro caso, deve o recurso ser inadmitido, cabendo à parte fazer uso de outros recursos previstos em lei (agravo em RExt, Agravo Interno, etc.) para alterar a decisão original. No segundo caso, os recursos são reunidos em grupos com temáticas similares e aguardam a definição do tribunal quanto à presença (ou não) de repercussão geral na matéria discutida. O terceiro caso - quando há reconhecimento da repercussão geral - se divide em outras duas possibilidades: em que o caso representativo da Repercussão Geral já foi julgado e em que o caso representativo ainda não o foi. Se a demanda já foi julgada, aplica-se o entendimento firmado pela Tese de Repercussão Geral. Se o caso paradigma ainda não foi julgado, aguarda-se o julgamento.78
Cabe ressaltar que não é a inteligência artificial que decide se o processo possui repercussão geral. O programa Victor somente separa os processos cuja repercussão geral já foi reconhecida previamente pelos ministros do Supremo Tribunal Federal. Essa separação pode ser realizada levando-se em conta que, na primeira etapa de implementação do projeto - de separação das principais peças do processo - a inteligência artificial foi treinada para reconhecer linguagem natural (não algorítmica).
Isso é relevante pois, em suma, se traduz na principal função do projeto: ler um tema de repercussão geral, ler as principais peças dos processos e vinculá-los quando forem correspondentes. O Tema da Repercussão Geral nada mais é do que um enunciado que resume a conclusão à qual chegaram os ministros do STF em um determinado caso de relevância social, jurídica, política ou econômica.
Poder-se-ia presumir que, pelo fato de o programa Victor não decidir o mérito do recurso que sobe à corte Superior, não há qualquer risco à legalidade e as vinculações à qual a Administração Pública está subordinada. Evidentemente, o ato de o STF, no exercício de função administrativa, decidir instalar ou não uma inteligência artificial em uma etapa preliminar do processo decisório, se configura como ato administrativo discricionário. Contudo, mesmo atos administrativos discricionários devem respeito ao substrato constitucional e principiológico do ordenamento jurídico brasileiro. É nesse momento que o questionamento central do presente trabalho se faz presente: o uso do Projeto Victor no STF apresenta um risco ao princípio da legalidade, apesar dos ganhos em eficiência?
Para responder à pergunta, primeiro é necessário analisar o que se entende por “eficiência” e “legalidade” na doutrina brasileira. Ambos são princípios da administração pública elencados no art. 37 da Constituição Federal. Como tal, não possuem prevalência um sobre o outro, em abstrato. Contudo, em situações específicas, é possível analisar as particularidades do caso analisado e concluir se um princípio acaba tendo maior peso que outro, a partir do juízo de ponderação. Cabe ressaltar que os princípios da eficiência e da legalidade possuem conteúdo normativo muito maior do que o texto encerrado na Constituição Federal induz a presumir. Por essa razão, o estudo das interpretações dadas a esses princípios hoje em dia é importante para auxiliar na resposta ao questionamento central do presente trabalho.
A legalidade administrativa pode ser entendida de quatro formas diferentes, dependendo do ordenamento jurídico. Na primeira, basta que a Administração Pública não viole nenhuma norma para que possa atuar de forma discricionária (vinculação negativa). Na segunda, a Administração Pública pode atuar somente se existir previsão constitucional ou infraconstitucional para a atividade a ser exercida. Na terceira, a Administração Pública somente detalharia a forma de implementação de atos já previstos em lei, possuindo maior discricionariedade. Na quarta e última visão, a Administração Pública possuiria sua atuação integralmente vinculada à previsão legal.79
No Brasil, a atuação da Administração Pública é muito bem detalhada. Frequentemente, existe previsão legal para a vinculação ou para a discricionariedade dos atos administrativos. Se não houve insurgência quanto à determinada previsão de ato administrativo, presume-se constitucional. Entretanto, quanto aos atos administrativos discricionários, é importante ressaltar que possuem uma limitação correspondente àquela prevista na Constituição Federal e na legislação. Isto é, ainda que no Brasil não mais se admita a interpretação do princípio da legalidade em sua forma estrita, ainda existe uma limitação decorrente das normas positivadas e, principalmente, dos direitos fundamentais.80
O princípio da eficiência, em uma perspectiva geral, se traduz em um mandato de otimização, quantitativa e qualitativa, da atuação da administração pública. Em teoria, prevê a garantia de um resultado maior, com uma menor quantidade de erros e com menor custo.81
Nesse sentido, a ideia de eficiência tem como pressuposto a ideia de desburocratização, já que, teoricamente, poderia garantir resultados mais rápidos e garantir mais satisfação aos usuários de serviços públicos.82
Emerson Gabardo divide o princípio da eficiência em quatro atributos: racionalização, produtividade, economicidade e celeridade. A racionalização, na perspectiva do autor, torna determinado ato administrativo eficiente na medida em que reduz possíveis erros. A produtividade pode ser entendida como a relação entre o produto final e os meios de produção; a soma entre eficiência propriamente dita e eficácia ou como rendimento. Por economicidade, o autor entende que é a aquisição de riqueza em menor tempo possível, com o menor gasto de energia. O último atributo da eficiência, nessa acepção é o da celeridade, que, aliada aos outros elementos do conceito de eficiência, busca a garantia do resultado o mais rápido possível.83
Em uma perspectiva prática, o princípio da eficiência pode ser encerrado em quatro premissas básicas:
“...é possível afirmar que o conteúdo jurídico do princípio da eficiência administrativa pode ser traduzido como o dever que a Constituição Federal impõe à Administração Pública de : (i) exercer o poder administrativo que é conferido legalmente com máxima velocidade, rapidez, baixo custo e produtividade; (ii) atuar de forma a especificar fielmente a finalidade pública que está na base das normas jurídicas a que está sujeito; (iii) utilizar os meios mais adequados para a melhor realização dos objetivos fixados aos comandos que lhe são dirigidos pelo ordenamento jurídico; e (iv) sempre de acordo com os direitos fundamentais e com os demais princípios e normas que regem a atividade administrativa.” 84
Essa perspectiva aparenta ser a mais adequada, uma vez que possui, em sua caracterização, uma análise quanto à finalidade de uma determinada conduta dita eficiente, ao mesmo tempo que que a insere dentro do ordenamento jurídico brasileiro, na medida em que prevê que qualquer ato administrativo eficiente deve respeito aos direitos fundamentais e às normas da administração pública.
Apresentados os conteúdos normativos do princípio da legalidade e do princípio da eficiência, pode-se passar a discutir a pergunta elencada no início do tópico.
Antes de mais nada, é possível dividir a utilização do programa Victor em dois momentos distintos que demanda análise separada: a instauração da Inteligência Artificial e sua utilização propriamente dita.
Quanto à instauração do projeto, não se verifica ofensa ao princípio da legalidade. Não há qualquer previsão legal que proíba um tribunal de delegar uma atividade administrativa (em abstrato) de separação de recursos à uma máquina projetada especificamente para esse fim. Em verdade, a instauração de inteligências artificiais por tribunais brasileiros é uma mudança bem-vinda e, em verdade, inevitável. Além disso - somente nesse momento de instauração da IA nos sistemas do tribunal - percebe-se respeito ao princípio da eficiência. Parte do pressuposto de que o Poder Judiciário tem dificuldade em processar em tempo adequado todas as demandas e que é necessário acelerar o processo decisório e garantir a duração razoável do processo. Quanto ao Projeto Victor, a possibilidade de sua aplicação para auxiliar o processo decisório era ainda mais tentadora do que outros sistemas de Inteligência Artificial: conseguiria realizar a atividade de separação de recursos por Tema de Repercussão Geral em 5 segundos, atividade essa realizada em 44 minutos por servidores humanos.85
O conflito entre princípio da eficiência e princípio da legalidade se torna mais evidente quando se analisa a utilização propriamente dita do programa Victor. Como relatado nos tópicos anteriores, o fato de o programa atuar somente na compilação de recursos por temas de Repercussão Geral induz a pensar que é impossível que haja qualquer mácula na decisão final dos ministros, uma vez que são eles próprios - e não a máquina - que decidirão pelo provimento ou não do recurso.
Entretanto, mesmo nessa etapa intermediária da decisão - separação de recursos - pode-se detectar alguns problemas possíveis: consequências da hipernormatização artificial e dos vieses e impedimentos ao acesso ao Poder Judiciário.
A hipernormatização, como demonstrado em tópico anterior, é o resumo inadequado do conteúdo de uma decisão jurídica em uma tese simplificada. Esse problema é particularmente relevante quando se discute o sistema de Repercussões Gerais adotado pelo STF. Aqui, a hipernormatização se apresenta na medida em que um Recurso Extraordinário pode ser inadmitido/ter seu seguimento negado se os elementos do caso concreto não estiverem previstos em determinado Tema de Repercussão Geral, mesmo que o inteiro teor da decisão que originou o tema preveja a hipótese aventada nesse Recurso Extraordinário exemplificativo.
Como explicado ao longo do texto, muitas vezes, a programação da inteligência artificial é maculada pela presença de vieses em sua programação. Isto é, formas de atuação da IA que não se coadunam com a finalidade originalmente prevista. É o caso da IA utilizada por juízes criminais que tem como principal base de dados estatísticas de prisões efetuadas por policiais racistas.86
Para o caso do Projeto Victor, a hipernormatização artificial é um viés implícito na máquina.
Isso porque se trata de um atributo não previsto, que pode ser replicado na atuação da máquina e que tem origem em uma base de dados enviesada em si própria. 87
Como o Projeto Victor atua em casos em que a premissa estabelecida na tese de Repercussão Geral é diferente daquilo que foi estabelecido pela íntegra das decisões dos ministros no recurso que originou a tese? Citou-se o caso da Tese fixada no RE 494.601/RS, onde se considerou o sacrifício de animais em rituais de religiões da matriz africana como sendo constitucional. Deve-se relembrar que o STF considerou como constitucional o sacrifício de animal em ritual de religião africana somente se o animal não sofrer e se ele for consumido após a cerimônia. Se um recurso que não cumpre esses dois requisitos chegar ao STF, o programa Victor irá classificá-lo na Tese fixada no RE 494.601/RS? Se sim, o Projeto Victor deixaria de acusar a inconstitucionalidade de um recurso, já que a premissa da Tese é incompleta.
Outra hipótese - mais grave - é aquela na qual o programa Victor deixa de classificar o Recurso Extraordinário em um Tema de Repercussão Geral. Para fins argumentativos, suponha-se que tenha sido concedida admissibilidade a um Recurso Extraordinário que discuta o seguinte: a) a constitucionalidade do sacrifício de um animal em um ritual de religião africana, com base na Tese do RE 494.601/RS e b) a inconstitucionalidade da correção monetária da condenação devida ao recorrente pela TR. Supondo que tenha sido concedida admissibilidade a esse recurso, o programa Victor seria capaz de detectar que existe um Tema de Repercussão Geral que não foi citado pela decisão de admissibilidade do recurso? No item b) da hipótese criada, discute-se a previsão do Tema 810 do STF.88
Se esse tema foi discutido ao longo dessa possível ação, sem em momento algum ter sido mencionado, o programa Victor teria capacidade de reconhecer a aplicabilidade do Tema 810?
Se a resposta for não, verifica-se, de fato, ofensa ao princípio da legalidade. Se, por conta do trabalho do programa Victor, o Recurso Extraordinário for classificado somente quanto à Tese do RE 494.601/RS, não é de se afastar a possibilidade de que a incidência do Tema 810/STF sequer fosse apreciada, uma vez que, quando o ministro se deparasse com o Recurso, não haveria menção a esse precedente. Se esse tipo de acontecimento for possível, a atuação do Projeto Victor ofende a legalidade na medida em que contribui para excluir da apreciação do judiciário lesão ou ameaça a direito (art. 5°, XXXV, Constituição Federal).
Além disso, é comum que um precedente firmado em sede de repercussão geral passe a ter sua aplicação alterada com o passar do tempo sem que o texto original sofra mudanças.89
Em casos como esse, recursos que se coadunam com a nova interpretação, mas não com o texto original, ainda que tenham sido admitidos pelos tribunais de instâncias inferiores, poderia ter seu trâmite obstado na etapa de análise pelo programa Victor, uma vez que ele deixaria de classificá-lo no tema de repercussão geral correspondente. Em sentido oposto, o programa poderia classificar um recurso extraordinário - cujos fatos não implicariam na incidência do precedente de repercussão geral - em um Tema, podendo, eventualmente, causar prejuízos à parte adversa. Em situações como essas, é importante pontuar que o jurisdicionado tem direito a uma decisão motivada por parte do órgão decisor, explicando com detalhes o porquê de o recurso ser regido (ou não) por determinado tema de Repercussão Geral90
. Além disso, nesse caso, assim como nos demais, é importante que o jurisdicionado tenha acesso ao procedimento de separação efetuado pelo programa Victor.
Por mais detalhado e minucioso que seja o processo de divisão de recursos realizado pelo programa Victor, é imprescindível que haja um controle humano de seu trabalho. 91
Afinal, ainda que à primeira vista, a divisão do recurso em tema de repercussão geral aparente ser um trabalho essencialmente administrativo, o mérito do recurso pode ser colocado em perigo caso o programa: a) elenque o recurso em um tema com o qual não tem relação ou b) não elenque o recurso em um tema com qual tem relação. Mesmo que seja ato majoritariamente administrativo, essa divisão deve ser validada por um juiz humano - a Constituição garante ao jurisdicionado o direito público subjetivo ao acesso a juízes.92
Desde quando começou a ser estudada como matéria acadêmica nos anos 1950, percebeu-se o potencial disruptivo das inteligências artificiais. Desde aquele tempo, buscava-se aproximar, o máximo possível, a atuação da máquina ao funcionamento do cérebro humano. Nessa época, entretanto, não se dispunha da tecnologia para que essa aproximação acontecesse.
Hoje em dia, a tecnologia existe e vem sendo usada de forma massificada. Tecnologias como o Chat-GPT demonstram que o sonho dos estudiosos originais das Inteligências Artificiais não era um absurdo. Na mesma medida que as atuais inteligências artificiais causam espanto e interesse, surge a necessidade de regulação dessa nova tecnologia. Em 14 de junho de 2023, a União Europeia aprovou o a proposição para o texto E.U. AI Act. O documento - ainda pendente de redação e aprovação final - busca garantir que o desenvolvimento de tecnologias de inteligência artificial estejam sempre evoluindo de acordo com a legislação dos países do continente europeu, com particular foco à garantia dos direitos fundamentais.93
No Brasil, o controle das inteligências artificiais vem sendo trabalhado com frequência, ainda que não com a mesma intensidade que na União Europeia. A Resolução n° 332/2020 do CNJ foi um marco nessa regulação. Essa regulação teve como principal expoente o advento da LGPD. A LGPD surge em um momento em que as inteligências artificiais passam a ter seu uso massificado em empresas do setor privado e até mesmo no Poder Público, como é o caso da utilização do processo eletrônico e dos softwares de IA pelo Poder Judiciário - cujo maior exemplo é o software Victor, utilizado pelo STF.
A solução para a atuação do Victor pode ser discutida de um escopo mais geral para um mais específico. Como relatado, um dos problemas que podem afetar o funcionamento e a eficiência do programa Victor é o da hipernormatização artificial. Esse problema decorre da simplificação exagerada da decisão de determinado recurso no STF em uma tese curta - um Tema de Repercussão Geral. É compreensível que esse sistema decisório busque resumir o máximo possível a decisão dos magistrados. Afinal, no controle difuso de constitucionalidade, o Tema de Repercussão Geral passa pelas mãos de um Magistrado que (supõe-se) conhece a decisão e seus termos na íntegra.
Contudo, o resumo da decisão no Tema de Repercussão Geral não é suficiente para a máquina. Portanto, para evitar distorções, o ideal seria que os Temas de Repercussão Geral encerrassem todos os argumentos utilizados pelos ministros na tomada de decisão original, mesmo que o enunciado final seja uma longa redação. Prezando pelo excesso, o programa Victor conseguiria identificar, em sua integralidade, se o processo corresponde a determinado Tema de Repercussão Geral, além de que seria muito mais intuitivo para informar advogados e juízes de outras instâncias.
Mais especificamente, não se pode esquecer a Resolução n° 332/20, a LGPD e a Carta Europeia de Ética sobre o uso da Inteligência Artificial em Sistemas Judiciais e seu Ambiente vinculam a Administração Pública, quando da instauração de sistemas de inteligência artificial, a respeitar a explicabilidade e a transparência. É essencial que o jurisdicionado, no caso do programa Victor, tenha acesso aos efeitos que o software teve na resolução de sua demanda. Morais (2022) sugere que deveria haver, no site do STF, informações mais claras e atualizadas sobre como o tribunal utiliza a inteligência artificial. Sugere ainda que seja informado às partes que o software Victor está sendo utilizado e como a decisão final foi afetada por ele.94
Adicionalmente, sugere-se que na página do processo eletrônico, a atuação do programa Victor esteja explícita na movimentação do processo, da mesma forma que a juntada de uma petição por um advogado ou uma certidão pelo serventuário do tribunal o é. Assim, caso o advogado identificasse, nesse movimento, que o programa Victor não classificou um recurso por tema de repercussão geral que julga orientar a demanda, seria possível peticionar nos autos, apresentando fundamentação - com o respaldo da movimentação referente ao ato do programa Victor - do porquê o processo deve ser analisado à luz desse ou daquele Tema.
O Projeto Victor é bem-vindo na medida em que acelera o procedimento de julgamento de recursos no STF. Trata-se de uma modernização inevitável que acontece na esteira da digitalização do processo judicial.95
Hoje, a maior parte das cortes brasileiras já é capaz de atuar de forma exclusivamente digital e isso inclui audiências por videoconferência. Contudo, a problemática da hipernormatização artificial, que é um problema inerente ao próprio sistema de Repercussão Geral e que acaba afetando a inteligência artificial Victor, impõe a necessidade de um controle da decisão artificial tanto pelos servidores e pelos ministros do STF, quanto pelo jurisdicionado, sob pena de afetar o princípio do acesso à justiça e, por consequência lógica, o princípio da legalidade ao qual a Administração Pública está subordinada.","['ARANÃO, Adriano; BERNARDI, Renato. O exercício da discricionariedade administrativa no contexto do estado social e democrático de direito: limites e possibilidades a partir da constituição federal de 1988. Revista Brasileira De Filosofia Do Direito, Brasília, vol. 3, n. 1, p. 133-152, jan./jun., 2017.', 'ARAÚJO, Pedro Henrique Luz de et al. VICTOR: a Dataset for Brazilian Legal Documents Classification. In: Twelfth International Conference On Language Resources and Evaluation, 12. 2020, Marselha. Proceedings of the Twelfth Language Resources and Evaluation Conference, Marselha: ELRA, 2020. p. 1449-1458.', 'ARAÚJO, Valter Shuenquener de; ZULLO, Bruno Almeida; TORRES, Maurílio. Big Data, algoritmos e inteligência artificial na Administração Pública: reflexões para a sua utilização em um ambiente democrático. A&C - Revista de Direito Administrativo & Constitucional, Belo Horizonte, ano 20, n. 80, p. 241-261, abr./jun. 2020.', 'BARBOSA, Xênia de Castro; BEZERRA, Ruth Ferreira. Breve introdução à história da Inteligência Artificial. Revista de História e Humanidades Jamaxi, Rio Branco, vol. 4, n. 2, p. 90-87, ago./fev. 2021.', 'BELLOCCHIO, Lucía; SANTIAGO, Alfonso. Estado digital de Derecho. A&C - Revista de Direito Administrativo & Constitucional, Belo Horizonte, ano 20, n. 80, p. 87- 102, abr./jun. 2020.', 'BOYD, Danah; CRAWFORD, Kate. Six Provocations for Big Data. In: A Decade in Internet Time: Symposium on the Dynamics of the Internet and Society, [s.n.], 2011, Oxford. Anais do Simpósio sobre a Dinâmica da Internet e da Sociedade. Oxford: Universidade de Oxford, 2011. p. 1-17.', 'BRASIL. Conselho Nacional de Justiça. Justiça em Números 2022. Brasília, DF, 2022.', 'BRASIL. Lei n° 13.105, de 16 de março de 2015. Código de Processo Civil. Diário Oficial da União, Brasília, DF, 16 mar. 2015.', 'BRASIL. Supremo Tribunal Federal. Administrativo. Tema 810. Validade da correção monetária e dos juros moratórios incidentes sobre as condenações impostas à Fazenda Pública, conforme previstos no art. 1º-F da Lei 9.494/1997, com a redação dada pela Lei 11.960/2009. Brasília, DF: Supremo Tribunal Federal, 2017.', 'BRAVO, Álvaro Avelino Sánchez. Marco Europeo para una inteligencia artificial basada en las personas. International Journal of Digital Law, Curitiba, v. 1, n. 1, p. 65-77, jan./abr. 2020.', 'CAMBI, Eduardo; ALVES, Elidia Aparecida de Andrade; ALVES, Fernando de Brito. Interfaces Artificiais e interpretação judicial: o problema do uso da inteligência artificial e da metodologia fuzzy na aplicação do direito. Revista dos Tribunais, São Paulo, vol. 108, n. 1010, p. 245-273, dez. 2019.', 'CAMPOLO, Alex et al. AI NOW 2017 Report. Nova Iorque: AI Now Institute - New York University. 2017.', 'CHOI, Jonathan H. et al. ChatGPT Goes to Law School. Journal of Legal Education, Mineápolis, 2023. No prelo.', 'CORREIA, Pedro Miguel Alves Ribeiro; SILVA, Edmar Mendes da; BILHIM, João. O princípio da legalidade sobre a perspectiva da administração pública: uma análise comparativa da doutrina e jurisprudência portuguesa e brasileira. Lex Humana, Petrópolis, vol. 8, n. 1, p. 98-117, jan./jun. 2016.', 'CORVALÁN, Juan Gustavo. Administración Pública digital e inteligente: transformaciones en la era de la inteligencia artificial. Revista de Direito Econômico e Socioambiental, Curitiba, vol. 8, n. 2, p. 26-66, mai./ago. 2017.', 'CORVALÁN, Juan Gustavo. Inteligencia Artificial GPT-3, Pretoria y Oráculos Algorítmicos en el Derecho. International Journal of Digital Law, Curitiba, v. 1, n. 1, p. 11-52 jan./abr. 2020.', 'COSTA, Ilton Garcia da; SANTOS, Ana Flavia Coelho dos. O Princípio Da Eficiência e a (i)legitimidade do Controle Jurisdicional das Políticas Públicas. Prisma Jurídico, São Paulo, vol. 20, n. 2, p. 311-29, jul./dez. 2021.', 'DA SILVA, Nilton Correia. Notas iniciais sobre a evolução dos algoritmos do Victor: o primeiro projeto de inteligência artificial em supremas cortes do mundo. In: FERNANDES, Ricardo Vieira de Carvalho; DE CARVALHO, Angelo Gamba Prata (Coord.). Tecnologia Jurídica e Direito Digital: II Congresso Internacional de Direito, Governo e Tecnologia. Belo Horizonte: Fórum, 2018. p. 89-94.', 'DANTAS, Ivo; ALENCASTRO, Emiliane; URTIGA, Rafael Beltrão. Inteligência Artificial aplicada ao gerenciamento de precedentes na corte constitucional brasileira. Revista de Direito e as Novas Tecnologias, São Paulo, vol. 11, n.4, p. 1-12, abr./jun. 2021.', 'DAUN, Rafaela Rabelo, PAIÃO, Olivie Samuel. O uso da inteligência artificial no direito: a aplicação nos precedentes judiciais e na uniformização da jurisprudência. In: RIGOLDI, Vivianne; NASCIMENTO, Arthur Ramos do; BONAVIDES, Samia Saad Gallotti; DOS SANTOS, Amanda Querino (Org.). Direito Constitucional Contemporâneo I, Jacarezinho: UENP, 2019. p. 159-173.', 'DOMINGUES, Tatiane. Implementação da inteligência artificial no poder judiciário brasileiro: benefícios e malefícios. São Paulo, 2021. 38. f. Monografia (Especialização) - Monografias Latu Sensu (Especialização e MBA), Pontifícia Universidade Católica de São Paulo.', 'EISENMANN, Charles. Anthologie Du Droit : Tome I. Paris: Librairie Générale de Droit et Jurisprudence, 1982. (Coleção Anthologie du Droit).', 'FIGUEIREDO, Carla Regina Bortolaz de; CABRAL, Flávio Garcia. Inteligência artificial: machine learning na Administração Pública. International Journal of Digital Law, Curitiba, v. 1, n. 1, p. 79-96, jan./abr. 2020.', 'FIGUEIREDO, Carla Regina Bortolaz de; CABRAL, Flávio Garcia. Machine Learning na Administração Pública. International Journal of Digital Law - IJDL, Belo Horizonte, vol. 1, n. 1, p. 79-95, jan./abr. 2020.', 'FILHO, Mamede Said Maia Filho; JUNQUILHO, Tainá Aguiar. Projeto Victor: Perspectivas de aplicação da inteligência artificial ao Direito. Revista de Direitos e Garantias Fundamentais, Vitória, vol. 19, n. 3, p. 219-238, set./dez. 2018.', 'FREITAS, Juarez; FREITAS, Thomas Bellini. Direito e inteligência artificial: em defesa do humano. 1. ed. Belo Horizonte: Fórum, 2020.', 'GABARDO, Emerson. Princípio da eficiência. In: NUNES JUNIOR, Vidal Serrano; ZOCKUN, Maurício; ZOCKUN, Carolina Zancaner; FREIRE, André Luiz (coord. de tomo). Tomo: Direito Administrativo e Constitucional. In: CAMPILONGO, Celso Fernandes; GONZAGA, Alvaro de Azevedo; FREIRE, André Luiz (coords.). Enciclopédia jurídica da PUC-SP. 1. ed. São Paulo: Pontifícia Universidade Católica de São Paulo, 2017. p. 1-23.', 'GILLET, Sérgio Augusto da Costa; PORTELA, Vinícius José Rockenbach. Breves conexões entre a motivação das decisões judiciais e o campo da inteligência artificial. Cadernos de Direito, Piracicaba, vol. 18, n. 34, p. 153-171, jan./jun. 2018.', 'GOMES, Helton Simões. Como as robôs Alice, Sofia e Monica ajudam o TCU a caçar irregularidades em licitações. G1, 18 mar. 2018. Disponível em: https://g1.globo.com/economia/tecnologia/noticia/como-as-robos-alice-sofia-e-monica-ajudam-o-tcu-a-cacar-irregularidades-em-licitacoes.ghtml\n» https://g1.globo.com/economia/tecnologia/noticia/como-as-robos-alice-sofia-e-monica-ajudam-o-tcu-a-cacar-irregularidades-em-licitacoes.ghtml', 'HACHEM, Daniel Wunder; GABARDO, Emerson. El principio constitucional de eficiencia administrativa: contenido normativo y consecuencias jurídicas de su violación. Cuestiones Constitucionales. Revista Mexicana de Derecho Constitucional, Ciudad de Mexico, v. 39, p. 131-167, 2018.', 'JUBOLINI, Márcio. ChatGPT é vilão? Veja a íntegra da carta em que Musk, Wozniak e mais de 1 mil pedem pausa nas pesquisas de IA. Money Times, 29 mar. 2023. Disponível em: https://www.moneytimes.com.br/chatgpt-e-vilao-veja-a-integra-da-carta-em-que-musk-wozniak-e-mais-de-1-mil-pedem-pausa-nas-pesquisas-de-ia/\n» https://www.moneytimes.com.br/chatgpt-e-vilao-veja-a-integra-da-carta-em-que-musk-wozniak-e-mais-de-1-mil-pedem-pausa-nas-pesquisas-de-ia/', 'LEONARDO, César Augusto Luiz; ESTEVÃO, Roberto da Freiria. Inteligência Artificial, motivação das decisões, hermenêutica e interpretação: alguns questionamentos a respeito da inteligência artificial aplicada ao direito. Revista Em Tempo, [s.l.] vol. 20, n. 1, p. 1-28. nov. 2020.', 'LIMBERGER, Têmis; KOSSMAN, Edson Luís. O princípio constitucional da eficiência ante o Estado (in)suficiente. Revista de Direito Administrativo, Rio de Janeiro, vol. 273, p. 287-311, set./dez. 2016.', 'LUDERMIR, Teresa Bernarda. Inteligência Artificial e Aprendizado de Máquina: estado atual e tendências. Estudos Avançados, São Paulo, vol. 35, n. 101, p. 85-94, jan./abr. 2021.', 'MAGALHÃES, Renato Vasconcelos. Inteligência Artificial e Direito - Uma breve introdução histórica. Revista Direito e Liberdade. Mossoró, vol. 1, n. 2, p. 355-370, jul./dez. 2005.', 'MENDES, Alexandre José. O aprimoramento da qualidade da decisão judicial apoiado em modelos de inteligência artificial e sua contribuição para a consolidação do sistema de precedentes brasileiro. Curitiba, 2021. 294 f. Tese (Doutorado) - Programa de Pós-Graduação em Direito, Pontifícia Universidade Católica do Paraná.', 'MORAIS DA ROSA, Alexandre. A questão digital. Revista de Direito da Faculdade Guanambi, Guanambi, vol. 6, n. 02, jul./dez. 2019. p. 1-18.', 'MORAIS, Fausto Santos de. O Uso da Inteligência Artificial na Repercussão Geral: Desafios Teóricos e Éticos. Revista Direito Público, Brasília, vol. 18, n. 100, p. 306-326, out./dez., 2021.', 'NAÇÕES UNIDAS BRASIL. Site da Organização das Nações Unidas, 2023. Paz, Justiça e Instituições Eficazes. Disponível em: https://brasil.un.org/pt-br/sdgs/16\n» https://brasil.un.org/pt-br/sdgs/16', 'NILSON, Nills John; The quest for Artificial Intelligence: A history of ideas and achievements. Cambridge: Cambridge University Press. 2009.', 'NUNES, Thâmylla da Cruz; GOMES, Luísa Caroline. Decisões Judiciais Conflitantes e o Impacto Da Inteligência Artificial na Uniformização Da Jurisprudência. Revista de Direito e Atualidades - Debates Jurídicos, [S.l], vol.1, n. 3, p. 86-104, jan. 2022.', 'PAIÃO, Olivie Samuel. Precedentes “abrasileirados” e a Inteligência Artificial: A busca pela ratio decidendi da Súmula Vinculante. Marília, 2021. 131 f. Dissertação (Mestrado) - Programa de Pós-Graduação Strictu Sensu, Centro Universitário Eurípides de Marília (UNIVEM).', 'PESSOA, Flávia Moreira Guimarães; GUIMARÃES, Alessandro de Araújo. Novos Paradigmas do Acesso à Justiça com o uso de Inteligência Artificial. In: ARAÚJO, Valter Shuenquener de; GOMES, Marcus Livio (Coord.); CANEN, Doris (Org.). Inteligência Artificial e Aplicabilidade Prática no Direito. [s.l], CNJ, 2022. p. 149-164.', 'PUSCHEL, André Felipe Silva; RODRIGUES, Roberto Tessis; VALLE, Vivian Cristina Lima López. O dilema ético da decisão algorítmica na administração pública. A&C - Revista de Direito Administrativo & Constitucional, Belo Horizonte, ano 22, n. 90, p. 207-226, out./dez. 2022.', 'ROQUE, André Vasconcelos; DOS SANTOS, Lucas Braz Rodrigues. Inteligência Artificial na tomada de decisões judiciais: três premissas básicas. Revista Eletrônica de Direito Processual - REDP. Rio de Janeiro, vol. 22, n. 1, p. 58-78, jan./abr. 2021.', 'SALOMÃO, Luís Felipe et al. Tecnologia aplicada à gestão dos conflitos no âmbito do poder judiciário brasileiro. [s.l.], FGV Conhecimento, 2020. 75 p.', 'SANTOS, Boaventura de Sousa. Os tribunais e as novas tecnologias de comunicação e de informação. Dossiê Sociedade e Direito, Porto Alegre, vol. 7, n. 13, p. 82-108, jan./jun. 2005.', 'SCHIEFLER, Eduardo André Carvalho; CRISTÓVAM, José Sérgio da Silva; PEIXOTO, Fabiano Hartmann. A inteligência artificial aplicada à criação de uma central de jurisprudência administrativa: o uso das novas tecnologias no âmbito da gestão de informações sobre precedentes em matéria administrativa. Revista do Direito, Santa Cruz do Sul, vol. 3, n. 50, p. 18-34, jan./abr. 2020.', 'SOARES, Marcelo Negri; MEDINA, Valéria Julião Silva. A Inteligência Artificial como instrumento de acesso à justiça e seus impactos no direito da personalidade do jurisdicionado. Revista de Direito Brasileira, Florianópolis, vol. 26, n. 10, p. 277-290, mai./ago. 2020.', 'SOUZA, Ewerton Pacheco de et al.. Aplicações do Deep Learning para diagnóstico de doenças e identificação de insetos vetores. Saúde em Debate, vol. 43, n. especial 2, p. 147-154, nov. 2019.', 'SOUZA, Talitha Pedras Figueiredo Campos de Carvalho; FREITAS, Sérgio Henrique Zandona; RIBEIRO, Adriano da Silva. A Inteligência Artificial no Poder Judiciário Brasileiro e a Gestão de Conflitos. Revista de Direito da Universidade FUMEC - Meritum, [s.l], vol. 17, n. 3, p. 167-182, set./dez. 2022.', 'STRINGHINI, Antonella. Asistencia virtual automatizada e inclusiva para optimizar la relación de la ciudadanía con la Administración Pública. International Journal of Digital Law, Curitiba, v. 1, n. 1, p. 117-128, jan./abr. 2020.', 'SURDEN, Harry. Values Embedded in Legal Artificial Intelligence. University of Colorado Law Legal Research Paper, [s.l.], v. 17, n. 17, p. 1-6, mar. 2017.', 'TOLEDO, Eduardo. Projetos de inovação tecnológica na Administração Pública. In: FERNANDES, Ricardo Vieira de Carvalho; DE CARVALHO, Angelo Gamba Prata (Coord.). Tecnologia Jurídica e Direito Digital: II Congresso Internacional de Direito, Governo e Tecnologia. Belo Horizonte: Fórum, 2018. p. 83-87.', 'TORFI, Amirsina et al. Natural language processing advancements by deep learning: A survey. v. 4. p. 1-23, 2020.', 'TUCCI, José Rogério. Recente regramento da inteligência artificial na União Europeia. Conjur, 23 jun. 2023. Disponível em: https://www.conjur.com.br/2023-jun-23/paradoxo-corte-recente-regramento-inteligencia-artificial-uniao-europeia\n» https://www.conjur.com.br/2023-jun-23/paradoxo-corte-recente-regramento-inteligencia-artificial-uniao-europeia', 'VALENTINI, Romulo Soares. Julgamento por computadores? As novas possibilidades da juscibernética no século XXI e suas implicações para o futuro do direito e do trabalho dos juristas. Belo Horizonte, 2017. 152 f. Tese (Doutorado em direito) - Faculdade de Direito, Universidade Federal de Minas Gerais. Belo Horizonte.', 'VALLE, Vanice Lírio do. Inteligência artificial incorporada à Administração Pública: mitos e desafios teóricos. A&C - Revista de Direito Administrativo & Constitucional, Belo Horizonte, ano 20, n. 81, p. 179-200, jul./set. 2020.', 'VALLE, Vivian Cristina Lima López; GALLO, William Ivan. Inteligência artificial e capacidades regulatórias do Estado no ambiente da administração pública digital. A&C - Revista de Direito Administrativo & Constitucional, Belo Horizonte, n. 82, p. 67-86, out./ dez. 2020.', 'VIANA, Ana Cristina Aguilar. Transformação digital na administração pública: do governo eletrônico ao governo digital. Revista Eurolatinoamericana de Derecho Administrativo, Santa Fe, vol. 8, n. 1, p. 115-136, ene./jun. 2021.']","['Publicação nesta coleção\n19 Jan 2024', 'Data do Fascículo\n2023']","[' VIVIAN CRISTINA LIMA LOPEZ VALLE ', ' JOSEP RAMON FUENTES I GASÓ ', ' ATTÍLIO MARTINS AJUS ']","[' Pontifícia Universidade Católica do Paraná (Curitiba-PR, Brasil) vivian.lima@pucpr.br', ' Universitat Rovira i Virgili (Tarragona, España) josepramon.fuentes@urv.cat', ' Pontifícia Universidade Católica do Paraná (Curitiba-PR, Brasil) attajus@hotmail.com']",http://www.scielo.br/scielo.php?script=sci_arttext&pid=S2359-56392023000200208&lang=pt,2024-11-21 09:59:40.795065,Scielo.org
INTELIGÊNCIA ARTIFICIAL E ÉTICA: UM DIÁLOGO COM LIMA VAZ,"Os feitos tecnológicos deste início de século levaram a humanidade a mitificar os processos maquínicos de alta performance funcional, a ponto de considerar programas computacionais como entidades inteligentes, as quais têm ampla aplicação em todos os setores da sociedade, como execução de atividades antes reservadas exclusivamente a humanos, na medida em que as realizam de forma infinitamente mais veloz, precisa e eficiente. A Ciência da Computação, associada à Robótica, tem obtido resultados estarrecedores na projeção (design) incorporada de máquinas muito similares aos humanos (androides e ginoides), destinados a executar tarefas ainda mais ambiciosas, como a de se relacionar afetivamente com humanos. Entre esses feitos, o que chama especial atenção é a possível criação de máquinas moralmente mais elaboradas que os próprios humanos. Essa ambição toca diretamente os estatutos da Ética filosófica, desde a sua fundação socrática originária como ciência do ethos e, entre os filósofos que mais se dedicaram a refletir sobre os desafios e dilemas éticos do século XX, figura Henrique Cláudio de Lima Vaz, brasileiro de produção acadêmica e envergadura intelectual invulgares. Deixando um legado monumental à filosofia brasileira, Lima Vaz ocupou-se de diversificadas temáticas do nosso tempo, e suas reflexões seguem tão atuais quanto desafiadoras, atraindo intelectos, que se pretendam rigorosos, a revisitar sua vasta obra e buscar nela inspiração aquilatada para enfrentar questões urgentes dessa nova era que se anuncia. Uma dessas questões é a relação aqui apresentada entre os feitos da Inteligência Artificial e a referência vaziana ao processo mutacional ora vivido. Este artigo parte, portanto, da obra de Lima Vaz para apresentar alguns questionamentos éticos sobre as experiências inusitadas vividas hoje no horizonte de uma cultura altamente tecnicizada, as quais sujeitam o humano ao império de uma suposta superioridade maquínica, o que acaba por impactar nosso universo simbólico, colocando sob suspeita alguns atributos intocáveis da essência espiritual que nos constitui, como a noção de consciência, abertura à transcendência irredutível aos feitos mais eloquentes de qualquer evolução técnica.","Com uma trajetória que marcou a história da Filosofia brasileira, sendo o precursor decisivo na consolidação do hegelianismo em nossa tradição filosófica, o pensamento de Henrique Cláudio de Lima Vaz é fonte obrigatória para todo aquele que se lança ao desafio de pensar filosoficamente o nosso tempo, eis que ele nos oferece uma obra vastíssima e muito atual, que vai desde as suas primeiras discussões sobre Ontologia e História, passando pelo seu tratado de Antropologia Filosófica, pelos Escritos de Filosofia sobre Ética, Cultura, Política, até sua última publicação em vida sobre Experiência Mística e Filosofia na Tradição Ocidental. Sem mencionar a quantidade expressiva de artigos por ele publicados sobre as mais diversas temáticas, inclusive sobre a conjuntura política do país em momentos bastante refratários a perfis intelectuais como o dele, e, ainda, a não menos extensa produção bibliográfica, nas diversas modalidades (dissertações, teses, livros, resenhas e artigos – os quais são recorrentemente publicados sob inspiração do seu vigoroso pensamento).
Quem teve o privilégio de ser aluno de Lima Vaz, seja nos famosos seminários sobre Hegel, ofertados regularmente entre as décadas de 1970 e 1980 na Faculdade de Filosofia e Ciências Humanas da Universidade Federal de Minas Gerais – FAFICH/UFMG (cujo conteúdo foi reunido em duas extensas obras pela Editora Loyola em 2020), seja frequentando seus cursos de Ética no antigo Instituto Santo Inácio de Loyola – ISI (hoje Faculdade Jesuíta de Belo Horizonte) – na década de 1990 e início dos anos 2000, sabe da potência com a qual seu pensamento nos arrebata rumo aos mais elevados níveis de reflexão metafísica, em face do vigor com o qual disseca conceitos complexos da história da Filosofia, além de municiar o pesquisador de fontes pouco vistas na literatura filosófica brasileira, sendo suas publicações caracterizadas por um rigor conceptual e uma erudição literária peculiarmente diferenciadas na história das pesquisas filosóficas na América Latina.
É nesse pórtico da história da Filosofia brasileira que orgulha as Minas Gerais (Lima Vaz é mineiro, nascido em Outro Preto, e o centenário de seu nascimento foi festejado por várias instituições acadêmicas no ano de 2021) que buscamos inspiração para discutir o dilema lançado neste ensaio, a encruzilhada milenar na qual nos situamos hoje, a qual aponta para dois caminhos incertos: o que nos sugestiona a um hedonismo sem medidas pela fruição irrefletida e bulímica de bens tecnológicos à disposição; o que nos exorta a uma profunda e responsável reflexão sobre os rumos da nossa civilização, a qual, pelo progresso das tecnociências, vem sofrendo uma mutação (conforme sugere Lima Vaz) nas nossas formas de vida, jamais experimentada antes, nem com o advento da máquina a vapor, nem com o da eletricidade. O diferencial da conquista tecnológica que forja novas experiências do humano com objetos técnicos (expressão adotada por Gilbert Simondon) neste início de século, tal como desenvolvido na tese de titularidade defendida pela autora deste artigo junto à FDUFMG, sob o título “Inteligência Artificial no horizonte da Filosofia da Tecnologia: técnica, ética e direito na era cybernética”, implica numa nova forma antropoformizante da tradicional relação homem-máquina. Essa relação, tal como experimentada neste início de século, destoa das anteriores qualitativamente, haja vista que arquitetamos, enfim, a máquina “de pensar”: o computador. Há neste século uma tendência sensivelmente maior de antropoformizar máquinas computacionais de alta performance precisamente por imitarem, não atividades do corpo humano (como o objeto técnico escavadeira, que imita o movimento do antebraço e do punho para remover terra com maior precisão e eficiência que as mãos humanas, p. ex.), mas as faculdades da inteligência humana, transgredindo nossa tradição filosófica com o esvaecimento de um dos pilares da civilização ocidental, que manteve a unidade espiritual da nossa trajetória civilizatória até aqui: a noção de natureza humana. Essas questões são trazidas à discussão na Ética de Lima Vaz (ética vaziana), um autêntico tratado de Ética filosófica disposto em duas obras de maturidade do filósofo, as quais apresentam, segundo suas próprias palavras, o programa de uma Metafísica do Bem. São elas: Escritos de Filosofia IV: Introdução à Ética Filosófica 1 e Escritos de Filosofia V: Introdução à Ética Filosófica 2, publicadas respectivamente em 1999 e 2000.
A redação das duas obras foi guiada, conforme explica Lima Vaz, pela intenção de “tentar uma reflexão histórico-sistemática sobre os temas e problemas fundamentais da Ética filosófica” (Lima Vaz, 1999, p. 9). No prefácio da primeira e na conclusão da segunda, em passagens que dialogam entre si, Lima Vaz registra sua maior preocupação à época, a ponto de iniciar e concluir seu tratado de Ética com ela: o fenômeno da mutação civilizacional em curso na nossa civilização. Nessas passagens, ele traça um cenário prospectivo segundo o qual os feitos das tecnociências atingiriam um nível de mudança sem precedentes na história da civilização humana, pelos impactos disruptivos em nossa forma de existência, o que não seria mais uma entre tantas mudanças experimentadas desde que o homo sapiens emerge como criatura única no universo, razão por que Lima Vaz a considera uma mutação sem precedentes civilizacionais.
O propósito deste texto é, guiando-se pelo pensamento vaziano, trazer um recorte relevante entre as possíveis leituras desse fenômeno mutacional: o problema da atribuição de qualificativos até então exclusivamente humanos a máquinas de funcionalidade superpotente, as quais passam a ser reconhecidas, em virtude dessa performance meramente técnica, como entidades inteligentes ou agentes artificiais autônomos (inclusive morais, como veremos). Provavelmente, em toda a trajetória da experiência técnica humana, ou da tecnicidade – como prefere Gilbert Simondon (1989) – jamais houve um desafio dessa magnitude, cujo enfrentamento conclama os estatutos tradicionais da Ética filosófica e, igualmente, as propostas da Ética aplicada e da Metaética.
Essa exímia manifestação da tecnicidade (Technischkeit) na trajetória humana exige, portanto, o diálogo com a sua intrínseca eticidade (Sittlichkeit – Hegel), razão por que partimos da Ética vaziana para pensar esse fenômeno a partir de suas significativas contribuições filosóficas sobre a praxis humana, desde a empreitada socrática de fundação de uma ciência do ethos, tal como referenciado por Lima Vaz. Causa especial estranhamento intelectual e temor moral os feitos tecnológicos no campo da projeção (design) de máquinas ditas inteligentes, o que vem sendo explorado à exaustão pelos mass media e seduzindo consumidores em todos os loci da World Wide Web, muito especialmente por se conjecturar a superação intelectiva e emotiva das competências cognitivas humanas por robôs em formato incorporado humanoide (tarefa da Robótica). Um feito exemplar, nesse sentido, é a venda de assistentes artificiais pessoais para atuarem como babás, cuidadores, mediadores empresariais e companhias íntimas, e.g., a ginoide (fembot) Olivia, o robô sexual de luxo mais avançado da linha RealDoll, que foi oferecida ao mercado em 2021 pela empresa americana Abyss Creations. Criadas a partir de um software de Inteligência Artificial (chamado X-Mode) que imita a vida em corpos inanimados de produtos incorporados em silicone superflexível, várias ginoides podem ser adquiridas em formatos customizáveis, por algo em torno de 30 mil reais, no site realdoll. com. Incrivelmente reais, chegam a chocar pelo nível de perfeição estética que encarnam (incorporam, na verdade), como nenhum humano encarnaria, o que nos leva a refletir sobre a banalização do corpo e das relações de afetividade humanas.
Mas a empreitada mais ambiciosa da área de Inteligência Artificial é, no entanto, a arquitetação de Agentes Morais dotados de consciência artificial. Uma afirmação dessa natureza (sobre a possibilidade de criação artificial de consciência) parece não merecer atenção de uma Ética filosófica comprometida com rigores conceptuais, supondo-se que não há qualquer dúvida sobre a impossibilidade de se reproduzir a consciência, haja vista a transcendência da natureza humana. Mas esta categoria, a natureza humana, nunca fora tão banalizada (e até atacada) como nas últimas décadas, especialmente pelos feitos nas áreas da Neurociência e a associação dela aos progressos da Cybernética a partir da década de 1960 pelas descobertas do matemático Norbert Wiener, o que trouxe uma leitura computacional diferenciada na programação de artefatos maquínicos, possibilitando a fundação da escola conexionista da Inteligência Artificial – IA (Boden, 2020, pp. 33-34), um avanço sem precedentes na história da tecnologia, como será visto.
Quando pensamos nessa aparente teratologia conceptual, qual seja, a de que máquinas possam ser consideradas seres conscientes, remetemo-nos à advertência, já anunciada acima, sobre os processos que integram esse momento de cisão tão radical em nossa história, a qual Lima Vaz considera verdadeira mutação. É no interior do sistema ético vaziano que buscaremos pistas valiosas para propormos algumas reflexões sobre as questões relativas aos desdobramentos da relação entre a produção tecnológica atual (e seus feitos) e a praxis ética que deve permeá-la enquanto atividade humana que é e, como tal, espiritualmente intocável, seja enquanto atividade poiética, seja enquanto atividade finalística, nas relações estabelecidas com os objetos que produz, particularmente os atuais artefatos inteligentes.
Há mais de duas décadas, nas publicações referidas de 1999 e 2000, Henrique Cláudio de Lima Vaz apontou o maior desafio a ser enfrentado pela civilização ocidental, ao cumprir seu terceiro milênio de história, “se concordarmos em datar o início de nossa civilização no século X a.C., com a formação do reino davídico e os começos da tradição literária bíblica de um lado, e de outro, com os primeiros passos da Grécia arcaica” (Lima Vaz, 1999, p. 7): uma monumental produção de bens culturais que liberta cada vez mais o humano de inóspitos condicionamentos naturais, ao mesmo tempo em que há um lastimável declínio dos valores espirituais que definem essa mesma humanidade. No prefácio dos Escritos de Filosofia IV e na conclusão dos Escritos de Filosofia V, como já mencionado, em passagens que dialogam entre si, Lima Vaz assevera que o desafio da nossa era é superar um paradoxo civilizacional sem precedentes, qual seja, ao mesmo tempo que agregamos à nossa existência “uma formidável e crescente produção de bens materiais e simbólicos que ocupam o espaço humano, atestando a passagem sempre mais rápida do mundo da natureza para o mundo da cultura”, assistimos, contraditoriamente, a um “progressivo esmaecer em seu horizonte simbólico das constelações de valores espirituais que orientaram até o presente sua marcha através dos azares do tempo” (Cf. Lima Vaz, 1999, p. 7), “violando uma lei fundamental do processo de criação cultural: a ordenação normativa de nossa atividade criadora em termos de bens e fins” que nos (auto)realizam (Lima Vaz, 1999, p. 8).
Como dito por ele em certa ocasião, nossa trajetória nos levou a uma sociedade rica em meios e pobre em fins, arrebatando-nos rumo a um “relativismo universal e um hedonismo sem limites”. Sintomaticamente os estudos sobre Ética são os que mais crescem na literatura Filosófica e das Ciências Humanas, o que se estende desde a Metaética e a Ética fundamental até a Ética aplicada, e tal ocorre por “uma das mais inequívocas e significativas reações a uma crise espiritual sem precedentes” em nossa civilização (Cf. Lima Vaz, 1999, p. 7). Tais produções parecem representar “o sobressalto de nossa natureza espiritual em face de ameaças que parecem pôr em risco a própria sobrevivência das razões de viver e dos valores de vida lentamente e penosamente descobertos e afirmados ao longo desses milênios de nossa história” (Cf. Lima Vaz, 1999, p. 8). A produção bibliográfica em torno de temas éticos, a polissemia do substantivo Ética e do adjetivo ético em todos os campos da linguagem contemporânea, indo das áreas da Filosofia até os meios de comunicação em massa, cunhou a expressão “século da Ética” para designar o século XXI. A expressão aponta:
de um lado, o vertiginoso crescimento das tecnociências, em particular da biotecnologia, e, de outro, a não menos rápida e abrangente dissolução do tecido social tradicional, o qual vem sendo substituído por novas e inéditas formas de convivência humana e de organização da sociedade. Os dois fenômenos estão entrelaçados e a descrevê-los e avaliá-los já se dedica uma vasta literatura, de resto muito desigual. (Lima Vaz, 2000, p. 240)
Também chamado “século da Biologia”, nele se descortina uma marca dessa nova era: um processo de mutação (palavra tomada por empréstimo da Biologia propositalmente por Lima Vaz) muito mais profundo que qualquer mudança vivida pela humanidade até aqui, assinalando o surgimento de uma nova civilização humana (Cf. Lima Vaz, 2000, p. 240). Nesse contexto inusitado e insólito, o filósofo nos traz algumas questões:
Que sentido terá a vida humana nessa nova civilização? Que valores a guiarão? Que fins o ser humano poderá entrever para o seu caminho histórico? Essas são interrogações de natureza ética que solicitam com urgência alguma forma de resposta no acelerado processo que nos arrasta em direção a terras ignotas de cultura e civilização. (Cf. Lima Vaz, 2000, p. 240)
Ele identifica três tipos de resposta a tais questões e a outras que a estas se conectam (Lima Vaz, 2000, p. 241):
i) a primeira, que considera estas interrogações um “resíduo anacrônico da civilização que termina”, retirando “validez ao problema ético” e confiando “a conduta da vida humana a técnicas controláveis de comportamento e previsão” (intenção do niilismo ético – se é que este tem alguma intenção);
ii) a segunda, que sustenta a corrente mais poderosa do pensamento ético contemporâneo, que tenta “renovar, no contexto dos problemas atuais, as grandes concepções éticas da modernidade”, todas elas fundadas na metafísica da subjetividade, supondo que “os problemas humanos se equacionam e resolvem na imanência da história”;
iii) a terceira, à qual Lima Vaz se filia, que remonta às origens da Ética e ao paradigma platônico-aristotélico que conduziu a Ética clássica, redescobrindo nele “o princípio capaz de inspirar respostas adequadas aos problemas éticos futuros que já começam a ser nossos problemas atuais”
Ele inclui nesta terceira linha de possibilidades a sua Ética filosófica, a qual tem por fundamento primeiro a pressuposição de que o ser humano é constituído por uma instância racional trans-histórica e que é, ao mesmo tempo, instância normativa do agir humano na história. Essa instância é o Bem transcendente.
Essa instância permanece como invariante conceptual na variação dos tempos e lugares. Vivida e pensada em diferentes formas históricas, ela assegura a identidade da vida ética como constitutiva da vida propriamente humana onde quer que se manifeste, e deve ser considerada a razão última de possibilidade de formação do ethos das comunidades históricas particulares e da ideia do ethos de uma comunidade política universal, se essa um dia vier a realizar-se. (Cf. Lima Vaz, 2000, p. 241)
Tendo assumido esse esteio da tradição grega e não admitindo o esvaziamento semântico kantiano da noção de virtude (areté), Lima Vaz parece ser mais um filósofo contemporâneo a reabilitar a Ética das virtudes, tal como Max Scheler e Alasdair MacIntyre, citados por Manoel dos Reis Morais como sendo filósofos paradigmáticos nessa nova empreitada de reabilitação contemporânea dos postulados platônico-aristotélicos para pensar problemas do tempo presente (Morais, 2018, p. 155). Nesse sentido, importa destacar a originalidade do sistema ético vaziano: trata-se de uma autêntica proposta pedagógica (paideia), uma heurística do Bem transcendente como normatividade que se cumpre historicamente, aqui tomada como itinerário para refletirmos sobre alguns dilemas existenciais desse milênio, marcado por uma hiperprodução técnica sem similar antes de meados do século passado. A Ética vaziana é, segundo nosso sentir, um programa filosófico que visa a uma profunda compreensão da própria existência do mundo e da nossa situação nele, já que ele só tem existência se significado pelo humano em todos os sentidos que o Ser possa se revelar. Eis a razão pela qual arriscaríamos afirmar que o sistema ético de Lima Vaz, sua obra de maturidade, ao contrário dos Escritos de Filosofia anteriores, completa tematicamente e conclusiva conceptualmente, é uma verdadeira Ontologia, reflexo da sua eleição do Bem transcendente como a essência do Ser que para todos os outros seres traz significado, isto é, o ser humano. É dessa obra que partimos para pensar em que medida nos desumanizamos e em que medida a evolução técnica contribuiu para esse processo. O pensamento ético de Henrique Cláudio de Lima Vaz é um farol inequívoco a guiar nossas reflexões sobre alguns fenômenos existenciais que aqui serão apresentados e que denotam uma mutação nos rumos da humanidade, tal como ele prenunciou há mais de duas décadas.
A empreitada mais ambiciosa no campo da inteligência artificial atualmente é o agenciamento maquínico (Deleuze, Guattari) de entidades artificiais com competência moral. Numa breve definição, adequada aos propósitos deste pequeno ensaio, Inteligência Artificial é um campo de estudo da Computação Cognitiva, que tem por subcampo o chamado Aprendizado de Máquina ou Aprendizagem Mecânica (machine learning). Só de nos referirmos a esse catálogo terminológico, percebemos uma mudança de sentidos no que se entende por inteligência e liberdade humanas. Este é um dos fenômenos mais impressionantes do processo mutacional que vivemos hoje, tal como apontado por Lima Vaz, qual seja, uma mítica antropoformizante que ronda essas atividades computacionais, em torno da qual se sugere convictamente a atribuição de características humanas ao que não passa de programas computacionais com altíssima capacidade de acumulação e cruzamento de dados dispostos no formato algoritmo, quer dizer, de receitas executáveis para atingir objetivos. O próprio conceito de algoritmo, que nada mais é que um cálculo preciso com variantes delimitadas, vem sendo tomado por essa aura antropoformizante, de modo que passamos a nos referir a esses processos de cálculos, “os” algoritmos, como verdadeiras entidades à espreita para controlar nossas vidas no imenso e complexo sistema Big data.
Evidentemente que “a entidade” por trás dos cálculos é o próprio humano, sendo essa antropoformização maquínica mais uma forma de alienação humana da sua própria essência, portanto, das responsabilidades sobre suas ações, mas em um novo formato plasmado pelos processos tecnológicos hiperpotentes, vale dizer, pela transferência a um suporte concreto. O mito não é uma divindade, um espectro intangível, mas uma máquina (virtual): não é um Deus à imagem e semelhança, mas uma inteligência maquínica decalcada. Cantwell Smith não mede adjetivos para apontar os equívocos que estão entranhados no senso comum sobre os feitos da computação, mostrando, inclusive, as falhas cometidas por programadores, precisamente porque até eles compartilham das crenças fantasiosas sobre o que esses processos computacionais são (Smith, 2019, pp. 40-42). Essa mitificação quanto ao poder real dos feitos computacionais chega a ponto de levar alguns cientistas a conjecturarem a possibilidade de construir uma Inteligência Artificial Geral (AGI, na sigla em inglês) que poderia evoluir para uma Inteligência Artificial Sobre-humana (ASI, em inglês), máquina que conseguiria emular nosso cérebro e nossa mente, superando os humanos (Boden, 2020, pp. 38, 199). Mas essas hipóteses são quimeras, já que desenvolver uma AGI ainda está longe do que o atual estágio das pesquisas computacionais consegue vislumbrar em curto e médio prazos.
Deixando de lado a mítica reinante nessa era de mutações, registramos que os cientistas da computação denominam inteligência artificial a área em que se desenvolvem processos longos, detalhados e enfadonhos de acumulação de dados, que são levados a cabo por centenas de programadores, que há décadas vêm estabelecendo por meio de programas (que ficam memorizados na estrutura computacional) milhares de padrões de passo a passo (algoritmos) com o propósito de obter resultados similares à cognição humana. Esta é caracterizada principalmente pela memória, pelo entendimento e pelo raciocínio, que, no caso, são simulados pelo cruzamento de dados adicionados a computadores potentes, imitando, com velocidade imbatível, os processos de cognição humana.
Complementarmente à noção de inteligência artificial, temos a aprendizagem mecânica ou o aprendizado de máquina, assim denominados os processos computacionais que otimizam a aquisição de informação, exponenciando a execução das tarefas programadas com mais eficiência, refinando habilidades cada vez que se repetem essas tarefas, numa sucessiva e crescente aquisição de melhores padrões computacionais sem intervenção imediata dos programadores humanos (nesse sentido é que a aquisição é considerada “aprendizado”). São, na verdade, programas que atuam sobre programas, como esclarecem Rich e Knight, são “mudanças adaptáveis no sistema, no sentido de que permitem que o sistema, da próxima vez, faça a mesma tarefa ou tarefas tiradas do mesmo grupo com mais eficiência e eficácia” (Rich, Knight, 1993, p. 514).
Se uma máquina está municiada de memória e de padrões que operacionalizam os dados dessa memória, similarmente ao que ocorre com a memória e o raciocínio humanos (conectando dados e produzindo resultados), diz-se que temos aí uma forma de inteligência, a artificial, e as técnicas desenvolvidas por esse campo da computação decorrem da própria limitação computacional. Como anota Whitby, “em um nível mais básico, o computador é um pateta completamente obediente. Tecnicamente dizemos que ele executa um algoritmo – um padrão de passos simples”, segundo o qual os “cálculos matemáticos podem ser quebrados em passos simples que podem ser executados pelo nosso pateta completamente obediente. De fato, quase todos os cálculos matemáticos podem ser expressos em algoritmos”, de modo que o grande desafio da área de pesquisa Inteligência Artificial é “encontrar as peças que faltam entre um interessante problema real – do tipo daqueles com os quais você tem que lidar – e um algoritmo, ou conjunto de comandos simples que o computador pode executar” (Whitby, 2004, p. 38). E por que esse sistema funciona tão bem, resolvendo a variedade de demandas da nossa vida, desde a redação deste texto até o guia preciso do GPS quando não fazemos ideia de como chegar a um destino qualquer? Whitby responde-nos: “Um dos motivos principais por que tudo isso funciona tão bem é que a eletrônica é muito rápida e todo o processo demora uma fração de segundo”, isto é, “a estupidez tediosa da maneira como os computadores digitais operam é compensada pela sua tremenda velocidade” (Whitby, 2004, pp. 59, 60).
As técnicas dessa área computacional, a qual fora inicialmente nomeada “simulação computacional”, passam a ser chamadas de inteligência artificial, por conseguirem, segundo o processo simplificadamente traçado por Whitby, alcançar resultado similar ao da inteligência humana, com um propósito muito bem definido: a produção de resultados a partir da conexão entre ideias (expressas em dados, no caso) que simula a produção de “conhecimento” novo típica dos humanos, libertando-nos de centenas de tarefas que passam a ser delegadas a máquinas (Ziviani, 1986), vez que estas, com maior velocidade e precisão, atingem os mesmos resultados que as atividades conectivas do sistema neural do cérebro humano conseguem a duras penas. É nesse sentido que se diz que a máquina produz conhecimento, logo, é inteligente. Mas tratase mesmo de uma imitação artificial do funcionamento do processo cognitivo humano, nada mais. Em outras palavras, são tarefas engendradas
por milhares de algoritmos estruturados como fórmulas cada vez mais refinadas que possibilitam a aprendizagem de máquina (AM), que, pelo grau de refinamento preditivo, são classificadas como machine learning e deep learning. Estas inteligências artificiais adquirem conhecimento extraindo padrões a partir de dados não trabalhados (Ziviani, 2017
), isto é, são programas de computador capazes de aprender a executar tarefas a partir de sua própria experiência (Faceli et al., 2011). Trata-se de sistemas de aprendizagem algorítmica capazes de se adaptar a novas situações problemáticas de forma independente, seguindo escrevendo seus próprios programas (Hoffmann-Riem, 2021, p. 15). (Brochado, 2021, p. 152)
John MacCarthy, quem cunhou a expressão Inteligência Artificial em 1956, um dos mais importantes fundadores da área, parte de um conceito funcional de livre arbítrio humano para propor que nossa inteligência possa ser decalcável em máquina. Para ele, se humanos decidem o que fazer avaliando resultados das diversas ações sobre o que eles podem fazer e já fizeram, esse processo em alternativas pode ser reproduzido em máquina, ainda que seja de forma determinística. Em suas palavras,
O problema do “livre-arbítrio” assume uma forma aguda, mas concreta. Nomeadamente, em raciocínio de senso comum, uma pessoa frequentemente decide o que fazer avaliando os resultados das diferentes ações que ela possa praticar. Um programa inteligente deve usar este mesmo processo, mas usando um senso formal exato de lata, devendo ser capaz de mostrar que tem estas alternativas sem negar que é uma máquina determinista. (McCarthy, 1969, p. 6
, tradução livre)
A primeira petição de princípio ao se nomearem esses processos de simulação computacional como seres inteligentes é a confusão elementar, aqui revelada por McCarthy, entre cérebro e mente, energia e informação. Descrever os processos cerebrais não nos autoriza a deduzir que eles causam as atividades mentais, tal como compreender a energia funcional no cérebro não explica o surgimento da informação na mente. Como pondera Dreyfus,
Os filósofos têm pensado no homem como uma mente contemplativa que recebe passivamente dados sobre o mundo e depois ordena seus elementos. A física tornou esta concepção plausível, fazendo-nos ver o cérebro como um objeto físico. O cérebro recebe passivamente a energia do mundo físico e a processa de acordo com seu estado atual, que depende da energia recebida no passado. Se aceitarmos esta visão passiva da mente e não fizermos distinção entre o nível de processamento físico e o de processamento de informações, parece bastante claro que a mente, assim como o computador, nada mais faz do que receber bits de dados bem definidos. [...] Como era de se esperar, os cientistas da computação, mais uma vez apoiados nisto pela tradição filosófica e pelo sucesso da física, raramente abordaram este problema. (Dreyfus, 1988, pp. 334-335, tradução livre)
O chamado aprendizado de máquina é, ao termo e ao cabo, um programa de algoritmos que criam algoritmos para, segundo o sistema de feedback, preencher lacunas informacionais visando a atingir, a partir dos próprios algoritmos existentes (sem intervenção humana imediata, portanto), o desempenho ótimo da máquina. A partir desse sistema de aprendizado, é possível pensar em ensinamento de conteúdo moral a máquinas que, assim, passam a se relacionar com humanos com comportamento intelectivo e moral, vale dizer: tal como a máquina imita o conhecimento humano, seria possível que ela imitasse a moralidade humana também.
Para unir esse desafio aos princípios da Ética filosófica, a chamada Ética Computacional vem tentando uma espécie de resgate do aristotelismo, buscando na Ética das virtudes o caminho para criar máquinas inteligentes como agentes morais artificiais, os quais, inclusive, poderão ensinar e ser modelo comportamental para os humanos, enquanto seres “virtuosos” infalíveis que essas máquinas serão. Como se vê, o sistema platônico-aristotélico, sugerido por Lima Vaz como caminho para enfrentarmos a mutação que estamos testemunhando, coincidentemente tem sido fonte de inspiração para direcionar as ambições técnico-científicas rumo à arquitetação de um projeto que transcende à Inteligência Artificial enquanto experimento com objetivos meramente eficaciais e econômicos. Esses agentes morais artificiais teriam por tarefa suprema ensinar boas práticas aos humanos, vale dizer, seriam a expressão máxima de uma tecnopaideia que reabilita, por meio de máquinas, a Ética clássica da virtude-ciência.
Nessa nova leitura maquinizada da Ética, adota-se o rigorismo eficacial da Inteligência Artificial para atingir precisão ótima na prática de ações virtuosas. Não estamos aqui a defender que máquinas adquirem consciência, o que seria uma teratologia filosófica. O que se considera aprendizado é apenas um sistema de acúmulo de dados sem autojulgamento sobre cada dado apreendido, razão por que Cantwell Smith refuta a tese da inteligência artificial como inteligência genuína, haja vista que ela não emite juízo sobre as informações que recebe, não só quanto às fontes de recepção, como também quanto à forma como os dados são integrados em diversas perspectivas de modo responsável em face do mundo a eles subjacente.
Para Smith, se qualquer sistema de captação de dados ainda não foi capaz de exercer julgamentos sobre o que “apreende”, evidentemente que a responsabilidade de captação e de integração legítima dessa datificação será sempre e exclusivamente de humanos. A combinação estatística de dados reunidos (necessariamente por humanos), ao contrário do que sugere o modismo atual, milita contra a noção do que entendemos por inteligência, já que essa tarefa mecânica meramente receptiva está longe do que se entende por atividade humana inteligente. Em suas próprias palavras,
A inteligência genuína exige que se faça um juízo experiente, sempre que a informação é combinada de diferentes fontes e circunstâncias, sobre como os vários dados registrados no mundo podem ser avaliados de forma sólida e o que é necessário para integrar suas diferentes perspectivas de uma forma que seja responsável perante o mesmo mundo subjacente. [...] Se um sistema não é capaz de julgar, então somos nós os responsáveis pelas diferentes perspectivas e preconceitos de todas as suas fontes de registro, bem como pela legitimidade de todas as suas instâncias de integração de dados [...] Ao contrário da moda atual, a mera capacidade de combinar estatisticamente dados reunidos de diversas fontes sem exercer julgamento a cada passo pode na verdade militar contra, e não a favor, de qualquer coisa que deveríamos querer chamar de inteligência. (Smith, 2019, p. 90, tradução livre)
Nada obstante, ao contrário dos humanos, um robô que seja programado para praticar condutas para o bem não romperia, sob qualquer hipótese, o padrão moral programado, o que equivale a uma programação da inteligência moral universal e incorruptível, quer dizer, uma reabilitação artificializada universal-concreta (efetiva) da razão prática, o que hoje é possibilitado pelas tecnologias de entes inteligentes. Pela relação humana com estes, afigura-nos como factível o melhoramento da performance moral humana, inspirada em máquinas incorruptíveis. Tais práticas seriam pedagógicas, e.g., na atuação de assistentes pessoais artificiais, como robôs corporativos direcionados à mediação em compliance empresarial, como robôs-babás programados para também ensinar princípios morais fundamentais a crianças em fase de formação, como cuidadores artificiais capazes de interagir dialogicamente com idosos solitários (este último tem sido um dos principais focos das pesquisas em IA hoje no Japão, cuja população idosa é expressiva e crescente).
A expectativa sobre a construção de agentes morais artificias é grande e não se sabe o limite entre a promessa e a fantasia, tornando-se banais os mitos em torno da Inteligência Artificial, especialmente pelas práticas de vaporware, bastante comuns entre as equipes de desenvolvedores de hardware e software, o que consiste em anunciar o lançamento de novos produtos ainda em fase de design, sem previsão concreta da data de produção conclusiva, com o intuito (muito comum na área também) de agitar a mídia e atrair consumidores em potencial para a “última” tecnologia inventada. Essa prática tem sido bastante recorrente para atrair bilhões de investimentos, seja por instituições de pesquisa, seja por entidades governamentais, seja por predileção excêntrica de bilionários, como Elon Musk, que apostam na tecnologia como caminho para a vida mais longeva e confortável que a humanidade ainda está por experimentar.
Fato é que a crença no aprendizado maquínico virtuoso é igualmente paradoxal, como tantos outros paradoxos que marcam este início de século. Ao mesmo tempo que se criou um mito antropoformizante em torno de entidades inteligentes que nada mais são que programas computacionais, talvez seja essa mesma mitificação que nos empurre rumo à ascensão a patamares morais mais elevados. Essa crença na superioridade maquínica pode ser o bodoque que vai nos catapultar, segundo o mesmo sugestionamento hoje experimentado quanto às proezas da inteligência artificial, a práticas virtuosas por imitação de robôs elevados moralmente, admirável inspiração (pedagógica) para nos tornarmos humanos melhores.
A criação de agentes artificiais morais, como vimos, já é realidade e, até o momento, é a conquista tecnológica mais desafiadora no campo das discussões éticas, pois que temos, nesse caso, a mutação mais paradoxal que viveremos: máquinas corrigindo os desacertos de caráter do ser humano. Como expecta Paulo Antônio Silveira,
A conclusão a que diversos cientistas de programação chegaram é que um modelo de agência artificial fundado em machine learning, combinado com a ética da virtude, é um caminho natural, coeso, coerente, integrado e “bem costurado” (seamless). Assim, existe uma resposta coerente, consistente e bem fundamentada que indica que não é provada a impossibilidade de um agente moral artificial autêntico. (Silveira, 2021, p. 186)
Ocorre que essa empreitada jamais pode ser encarada como produção de um artefato, design técnico. Essas e tantas outras questões de ordem prática não podem ficar à mercê de uma Ética de situação pensada somente por atores envolvidos nos processos de criação tecnológica, os próprios cientistas da computação e programadores, simplesmente porque os objetivos técnicos desses protagonistas das tecnociências podem se afastar em muito do sentido ético sobre o qual a ciência deve edificar suas conquistas.
Nesse ponto é que entendemos que o Direito deva assumir protagonismo regulatório em diálogo com o estatuto filosófico da Ética, a Ética Geral, e não com supostas Éticas parciais pensadas situacionalmente por atores envolvidos nos processos de criação tecnológica e inovação. Sem essa interlocução, que nos parece evidente, não encontraremos possibilidades normativas efetivas para diminuir os impactos negativos que os processos tecnológicos produzem.
Parece que até o momento, no direito vigente, em que pesem as conquistas regulatórias no Canadá, na Alemanha e, especialmente, no pioneirismo da União Europeia, o que temos de fato é uma regulação fragmentária, incipiente e demasiadamente principiológica, o que denota a indisfarçável impotência do Direito em lidar com esses complexos fenômenos de verdadeira mutação civilizacional; razão pela qual este texto também defende o comprometimento que a Filosofia do Direito atual deve assumir na tarefa de refletir sobre questões de ordem técnica (não só das tecnicalidades jurídicas, mas da tecnicidade na experiência humana) que impactam na própria aplicação do direito positivo, como a experiência hoje trivializada no emprego de robôs virtuais para a tomada de decisões nos processos judiciais.
Não é demais mencionar o quanto pode ser desestabilizador para a simbologia social em torno do papel e da relevância do Direito o excesso de casos decididos por máquinas, a pôr em xeque a própria necessidade do Poder Judiciário enquanto instituição de poder, se se entender que este nada mais é que um compêndio de programas computacionais. Politicamente falando, as práticas de decisão maquínica podem vir a
estafar as bases institucionais do Judiciário em pouco tempo, sem qualquer tom escatológico, pelo malogro nos escopos do próprio Poder Judiciário, o qual cumpre a missão de receber demandas e decidi-las com competência e sensibilidade (não à toa sentença vem de sentire), no que reside simbolicamente sua legitimidade, respeitabilidade, sua posição de poder. Pessoas seguirão buscando por autoridades para resolver com sensibilidade humana seus dramas pessoais quando sabedoras serão de que robôs estão à frente dos processos? Parece que será algo similar ao que os chatbots provocam em nós hoje: busca por empatia ao tentarmos chegar num humano que nos atenda e resolva nossas questões humanamente. (Brochado, 2021, p. 154)
Eis mais um desafio a ser enfrentado pelo Direito em diálogo com os princípios da Ética filosófica. Na busca pela união do papel formalizador do Direito e da tarefa conteudística da Ética, emerge como ponto de equilíbrio a categoria da pessoa moral, que é a própria singularidade no movimento dialético da relação estabelecida entre os indivíduos e seu ethos
através das mediações sociais que se tecem no campo das esferas particulares da sociedade, cada qual particularizando, por sua vez, o horizonte universal do ethos, [sendo] justamente o movimento dialético que retorna do particular ao universal, fazendo do indivíduo empírico um universal concreto [...], [um] singular na terminologia dialética ou uma pessoa moral na terminologia da Ética. (Lima Vaz, 1993, pp. 25-26)
A noção de pessoa moral é angular na Ética vaziana, visto que é ela que permite uma ontologia do sujeito em diálogo entre Antropologia e Ética filosóficas. Nesse sentido, a distinção que Vaz propõe entre as categorias da Pessoa e da Pessoa Moral, na Antropologia e na Ética, respectivamente:
a expressão pessoa moral é, sob certo aspecto, redundante, pois a pessoa humana é, por essência, um ser moral enquanto princípio dos atos que são propriamente atos humanos. [...] [A] pessoa é constitutivamente ética e o predicado da eticidade se estende a todas as suas manifestações: psicológica, social, política, jurídica, profissional e outras. A distinção entre pessoa e pessoa moral diz respeito apenas à distinção entre os objetos formais de duas disciplinas no corpo dos saberes filosóficos, a Antropologia filosófica e a Ética. (Lima Vaz, 2000, pp. 237-238)
O direito é a normatividade do ethos que dota de objetividade a categoria universal concreta da pessoa moral na forma de sujeitos de direito, cujo horizonte normativo é a universalidade empírica (concreta, portanto) da normatividade jurídica. É o direito enquanto norma e praxis (e enquanto ciência que os toma por objeto) que garante a preservação das subjetividades ao reconhecer a categoria da pessoa moral (da Ética) como categoria axiforme dos direitos e garantias fundamentais, a pessoa, capaz efetivamente de postular seus direitos (ius suum), razão pela qual a pessoa é um sujeito (universal-concreto) de direitos (Brochado, 2021, pp. 252-253). Nesse sentido é que a dialética da experiência ética ascende em dignidade efetiva à dialética da experiência jurídica, cujo movimento se desdobra como
a universalidade abstrata da lei e a universalidade também abstrata do conflito de interesses [que] fazem nascer a universalidade concreta do sujeito de direito e realiza a um só tempo, como sujeito universal, a singularidade universal da sociedade, isto é, o sujeito de direito (Salgado apud Brochado, 2021, p. 254).
O sujeito de direitos (pessoa juridicamente considerada) está autorizado a exigir a fruição de bens e valores na forma do exercício de direitos que integram a sua dignidade, condição exclusiva da pessoa moral.
Sendo a pessoa (juridicamente considerada) o centro unificador (categoria axiforme) de todos os direitos, importa assumir que não seria possível ao direito reconhecer capacidades e responsabilidades senão a seres que possam ser definidos como tais. A base de uma Filosofia do Direito propriamente dita é uma metafísica do sujeito tal como legada pela modernidade, a qual supõe a condição intocável e superior da pessoa em sua dignidade. O suposto da liberdade é o sustentáculo do Direito, de modo que não há que se falar em direitos e obrigações de seres que não consolidam as características da pessoa e com ela o seu valor central: a dignidade humana. Esta só pode ser atribuída à natureza humana, atribuição esta, conforme a síntese precisa ofertada por Karine Salgado, ilimitada e inquantificável, visto ser “um valor cuja medida é inexprimível” (Salgado, 2009, p. 21). A liberdade, o fundamento da dignidade, é o “elemento diferenciador do homem que o coloca acima das determinações naturais, pois que racional, e lhe permite a construção de sua própria obra, a determinação de como as coisas devem ser, a cultura” (Salgado, 2009, p. 16).
Eis por que falar-se em inteligência artificial e autonomia de máquinas (como carros autônomos que hoje já circulam por aí) gera um impasse jurídico difícil de contornar: impossível responsabilizar seres que não são capazes de juízo de reprovação sobre a própria conduta – o que não é possível, evidentemente, em máquinas (Brochado, 2021, p. 161). Sobre esse suposto, algumas teses emergem na seara jurídica para imputar consequências, nos quadros do ordenamento jurídico vigente, aos resultados provocados na realidade pela atuação de entidades maquínicas que imitam a inteligência humana. Uma possibilidade é a comparação delas à categoria da pessoa jurídica, a qual não é definida, evidentemente, por uma natureza intrínseca, mas por uma finalidade, quer dizer, em virtude de uma função societária. Nesse sentido, a atribuição de responsabilidade a essas entidades pode ser análoga ao que há séculos se pratica na área jurídica no tratamento da pessoa jurídica, inclusive com a possibilidade de responsabilização solidária dos humanos quando adquirem esse tipo de artefatos inteligentes.
Cogita-se, ainda, da possibilidade de regulação em que os humanos devam permanecer sempre responsáveis por suas máquinas “inteligentes” e o “modelo de responsabilização deve, sempre que possível, envolver um processo de certificação de boas práticas, a ser ofertado pelos entes envolvidos (academia, indústria e governo” (Peixoto, 2020, p. 157). Hoje já se anuncia um plexo de direitos destinados a robôs, direitos robóticos, uma tentativa de analogia com os direitos da personalidade, que se apresentam em três classes: físicos (direito à vida, à integridade física, à imagem, ao cadáver etc.), psíquicos (direito à liberdade, à intimidade, à privacidade etc.), morais (direito à identidade, à honra, à criação intelectual etc.) (Bittar, 2015, pp. 37-38). Ficou famoso o caso de reconhecimento de direitos a Sophia, “uma robô humanoide a quem o governo da Arábia Saudita concedeu nacionalidade, e que gerou protestos de organizações de proteção de direitos humanos contra discriminação de tratamento dispensado para mulheres naquele país” (Polido, 2020, p. 237).
Direitos robóticos ainda estão num segundo plano diante das exigências regulatórias mais urgentes, como a responsabilidade de carros “autônomos”, que hoje são realidade, e, independentemente da estratégia jurídica a ser adotada futuramente para o controle e responsabilização (compartilhada ou não) de entidades maquínicas inteligentes, parece bastante plausível, na ausência de uma categorização jurídica mais atual e adequada, tomar as atividades desses agentes similarmente ao modo como o Direito entende a pessoa jurídica. Nesse sentido, como fundamento para adoção de critérios juridicamente, parece conclusiva a posição de Stancioli e Lopes:
Embora agentes de inteligência artificial sejam constituídos de modo diverso a organizações, ambos possuem a semelhança fundamental da busca pela separação entre identidades e ações: sejam de seus membros, ou de seus controladores, programadores ou usuários humanos. É a capacidade social para a ação autônoma – e, por isso, individualizável – que possibilita, segundo Allen e Widdison, considerar tais agentes de IA como fontes de comunicações relevantes, havendo, portanto, sentido em se promover a sua personificação. (Stancioli, Lopes, 2020, p. 90)
A personificação deve ser tomada em sentido pragmático e não semântico, já que, como Allen e Widdison defendem, trata-se apenas de agenciamento como fonte comunicacional relevante e não como semanticamente autônomo. São agentes somente se considerados sob um imperativo técnico, e não sob um imperativo ético. Eis por que é uma impropriedade chamar essas máquinas de “agentes autônomos”, como os carros ditos “autônomos”, os quais, de fato, possuem autonomia técnico-funcional; nesse sentido, a nomenclatura adequada seria autômato (Aristóteles, Descartes) e não autônomo, já que autonomia (autos+nomos: capacidade de se dar as próprias leis) é atributo cooriginário da psyqué (alma), ou a transcendência humana enquanto metabolismo espiritual exclusivo dos humanos.
Na dicção de Lima Vaz, “racionalidade e liberdade são os dois atributos fundamentais do espírito que especificam os dois princípios constitutivos da sua atividade, a inteligência e a vontade” (Lima Vaz, 2000, p. 33). Sob a suposição de que a conditio sine qua non para o reconhecimento jurídico de ações e consequências atribuíveis a elas seja a personalidade, importa anotar que, sob o ponto de vista da Ética, essa categoria está vinculada à espiritualidade própria da pessoa moral. Nesse sentido é que a mutação civilizacional que Lima Vaz aponta é antes e acima de tudo uma empreitada desespirutualizante do humano, vez que nesse século passamos a acreditar ser atribuíveis a seres maquínicos os mesmos qualificativos (logo, direitos) que só o são a seres humanos em virtude da sua intrínseca espiritualidade. Esta é a mais profunda cisão já experimentada na trajetória civilizacional da humanidade, qual seja, a negativa de que o espírito seja a base do reconhecimento dos humanos enquanto tais, o que lhes garantiu por séculos um espaço de especial grandeza perante todos os outros animais: sendo ele o único animal dotado de logos, este o tornou absolutamente singular (Lima Vaz, 2000, p. 201).
Esta é a mais grave espécie de maquinização humana. E quando aqui nos referimos a essa maquinização, não se quer com isso negar, de forma grosseira e anacrônica, sentido e propósito às refinadas acoplagens de artefatos que possam condicionar melhor o corpo humano para o bem-estar, a saúde e a longevidade dos humanos, inclusive as nanoacoplagens que são realidade na mitigação de doenças, como, e.g., a Doença de Parkinson. A referência à maquinização não se dirige à estrutura corpórea humana, mas a sua estrutura simbólica, ao suscitar a discussão que deve ser seriamente trazida a debate pela Filosofia, qual seja, uma crença difícil de ser afastada, a essa altura do progresso das ciências e da irreversibilidade dos feitos tecnológicos: a crença de que humanos são seres similares a máquinas, com o diferencial de que as máquinas de hoje são projetadas e testadas em laboratórios, ao passo que as máquinas humanas foram aleatoriamente “montadas” por sistemas de feedback naturais segundo bilhares de bilhões de tentativas e erros. Esta tem sido uma das teses mais festejadas pela Neurociência e pela Neurocomputação atuais, que pretendem, mapeando o sistema neural humano, superá-lo por cérebros artificiais muito mais potentes que a rede de cálculos da qual nós, homo sapiens, somos dotados, e que nada mais é que um sistema de algoritmos naturais, nada tendo a ver com a arcaica narrativa mítica de uma natureza humana guiada, por fins e valores, a um Bem transcendente.
Neste pequeno ensaio, buscamos em Lima Vaz o ponto central da discussão sobre o progresso tecnológico que ele considera uma verdadeira mutação, marcada pela contradição entre a gênese e o desenvolvimento do processo que libertou os humanos das amarras da natureza, sua capacidade de postular fins e valores, e o atual estágio da evolução humana possibilitada por essa capacidade, o qual tende a negar a singularidade humana enquanto espiritualidade (inteligência livre). O progresso científico e tecnológico chegou a uma objetificação tal da realidade que toma o humano como ser catalogável, desespiritualizando-o, ao suprimir dele seu destino rumo a fins e valores superiores e que deveriam ser intocáveis por qualquer forma de reificação. A civilização tecnológica, ao mesmo tempo que nos trouxe uma plêiade de bens materiais, os quais representariam libertação das amarras da natureza rumo a uma vivência culturalmente mais elevada, rompeu com nosso telos essencial ao suprimir em nós o próprio sentido de espírito. É dizer: a maquinização primorosa implicou em nossa desespiritualização, atingindo nosso “metabolismo espiritual”, que, como explica Lima Vaz, é a abertura própria da pessoa, abertura esta que se processa “mantendo o intercâmbio noético (inteligência) e pneumático (liberdade) com a totalidade do Ser” (Lima Vaz, 2000, p. 237). Essa abertura à transcendência que nos define é que nos permite evoluir historicamente rumo a novos direitos que tutelem, preservem, reconheçam como intocáveis nossos atributos espirituais, todos gravitando em torno da dignidade em ser sempre fim em si mesmo, jamais meio para qualquer outra finalidade (Kant).
O encontro da Ética e do Direito em busca de respostas para os dilemas civilizacionais, neste texto mencionados, equilibra-se na categoria éticojurídica sustentáculo da nossa civilização, a dignidade humana, explicitamente tomada desde a modernidade como valor-eixo em torno do qual gravitam todos os demais valores humanos. Ela é o “último elo da cadeia conceptual que constitui a estrutura inteligível da vida ética concretamente vivida na comunidade ética” (Lima Vaz, 2000, p. 204). E a comunidade ética existe pela importante tarefa desempenhada pelo Direito de funcionar como mediador da realidade que qualifica tudo o que existe em termos de justo e injusto, distribuindo equanimemente bens. Assim é que Lima Vaz entende o papel do Direito na processualidade do ethos: “ao ser assumida na esfera do direito, a realidade objetiva (pessoas, atos, coisas) é negada em sua particularidade empírica e recebe, pela mediação da lei, a qualificação universal de ‘regra justa’ constituindo-se em res justa” (Lima Vaz, 2000, p. 120).
A singularidade da vida ética dos indivíduos, como pontua Lima Vaz, é definida pelo “progresso da liberdade como adesão sempre mais plena da vontade ao Bem, e pelo aprofundamento sempre mais exigente da consciência moral” (Lima Vaz, 2000, p. 204). Esses dois traços são constitutivos do metabolismo espiritual humano e, tal como entende o filósofo, esse metabolismo funciona segundo o intercâmbio noético (inteligência do Ser) e pneumático (vontade livre dirigida ao Bem), liberto de determinações cronológicas ou factuais, tornando a pessoa um ser constantemente aberto segundo a convergência desses dois traços. Essa composição é, por sua vez, a “face da sua dignidade com a qual ele pode voltar-se para o outro, nele reconhecendo a mesma dignidade e com ele consentindo na tarefa de uma vida ética em comum. Entendida como inter-relação dos sujeitos pela aceitação recíproca da dignidade de cada um, a vida ética é uma vida na justiça” (Cf. Lima Vaz, 2000, p. 204). Daí o papel desempenhado pelo Direito na manutenção da comunidade ética, considerando a pessoa moral como sujeito de direitos para uma vida ética comum justa.
Não é possível pensar em regulação ética ou jurídica dos processos que aqui mencionamos, dentre tantos outros que envolvem as novas formas de vida que estamos experimentando, sem postular o metabolismo espiritual humano nestes termos, visto que é ele, pouco importando quais tarefas técnicas e relações maquínicas empreendidas pelos humanos, que nos torna pessoas como um todo aberto, pela inteligência e pela liberdade, à universalidade do Ser e do Bem, sendo, por esta razão (Lima Vaz inspira-se em Jacques Maritain) um ser “aberto e generoso” (Lima Vaz, 2000, p. 237). Essa dimensão da espiritualidade enquanto abertura do humano aos seres e ao Bem, o que o caracteriza como um ser aberto e generoso, vem se apagando em nós, e em seu lugar elegemos um hedonismo sem limites no consumo de bens tecnológicos, sem qualquer fim superior que nos eleve espiritualmente. Por não haver propósito para além do uso desses artefatos, passamos a glorificá-los, entificando-os a ponto de nos subjugar diante das potencialidades desses seres instrumentais, haja vista sua eficaz capacidade de nos trazer fruições materiais e simbólicas jamais experimentadas pelas sociedades humanas. Todos esses bens são apreciados por uma nova feição de sociedade, uma sociedade bulímica, como caracteriza Lima Vaz, a qual, na mesma velocidade e proporção que consome a parafernália técnica sofisticada que alcançou com o avanço das tecnociências, descarta de forma banal e inconsequente o que foi consumido, comprometendo sua morada primordial, vez que o impacto ambiental desse consumismo hedonista e bulímico não é calculável, como querem fazer crer experts tecnocientistas, hoje muito ocupados com suas predições e projeções técnicas, cada vez mais inebriantes e fugazes, buscando nelas, em vão, algum sentido intrínseco que amenize a angústia da finitude da nossa presença neste mundo.","['BITTAR, C. A. “Os Direitos da Personalidade”. São Paulo: Saraiva, 2015.', 'BODEN, M. A. “Inteligência Artificial: Uma Brevíssima Introdução”. Tradução de F. Santos. São Paulo: Editora Unesp, 2020.', 'BROCHADO, M. “Ética e Direito: pelas Trilhas de Padre Vaz”. Curitiba: CRV, 2021.', 'BROCHADO, M. “Inteligência Artificial no Horizonte da Filosofia da Tecnologia: Técnica, Ética e Direito na Era Cybernética”. Tese apresentada à Faculdade de Direito da UFMG como requisito para a promoção à classe de Professor Titular de Filosofia da Tecnologia e do Direito. Belo Horizonte, UFMG, 2022.', 'BROCHADO, M. “Prolegômenos a uma Filosofia Algorítmica Futura que Possa Apresentar-se como Fundamento para um Cyberdireito”. Revista de Direito Público-RDP, Brasília, Vol. 18, Nr. 100, pp. 131-170, out./dez. 2021.', 'DELEUZE, G., GATTARI, F. “O Anti-édipo: Capitalismo e Esquizofrenia”. São Paulo: Editora 34, 2011.', 'DREYFUS, H. L. “Che Cosa non Possono Fare i Computer: i Limiti dell’Intelligenza Artificiale”. Roma: Armando Editore, 1988.', 'FEENBERG, A. “Questioning Technology”. London: Routledge, 1999.', 'LIMA VAZ, H. C. “Escritos de Filosofia II: Ética e Cultura”. São Paulo: Edições Loyola, 1993.', 'LIMA VAZ, H. C. “Escritos de Filosofia IV: Introdução à Ética Filosófica 1”. São Paulo: Edições Loyola, 1999.', 'LIMA VAZ, H. C. “Escritos de Filosofia V: Introdução à Ética Filosófica 2”. São Paulo: Edições Loyola, 2000.', 'MCCARTHY, J., HAYES, P. “Some Philosophical Problems from the Standpoint of Artificial Intelligence”. Stanford: Stanford University, 1969. Disponível em: http://www-formal.stanford.edu/jmc/mcchay69.pdf Acessado 04 de fevereiro de 2022.\n» http://www-formal.stanford.edu/jmc/mcchay69.pdf', 'MORAIS, M. R. “Ética e Direito em Lima Vaz”. 2ª ed. Rio de Janeiro: Lumen Juris, 2018.', 'PEIXOTO, F. H. “Inteligência Artificial e Direito: Convergência Ética e Estratégica”. Curitiba: Alteridade Editora, 2020.', 'POLIDO, F. B. P. “Inteligência Artificial entre Estratégias Nacionais e Corrida Regulatória Global: Rotas Analíticas para uma Releitura Internacionalista e Comparada”. Revista da Faculdade de Direito da UFMG, Nr. 76, pp. 229-256, jan./jun. 2020.', 'RICH, E., KNIGHT, K. “Inteligência Artificial”. Tradução de M. C. S. R. Ratto. Revisão técnica de A. Antunes. São Paulo: Makron Books, 1993.', 'SALGADO, J. C. “A Ideia de Justiça no Mundo Contemporâneo: a Interpretação e Aplicação do Direito como Maximum Ético”. Belo Horizonte: Del Rey, 2006.', 'SALGADO, K. “A Filosofia da Dignidade Humana: a Contribuição do Alto Medievo”. Belo Horizonte: Mandamentos, 2009.', 'SILVEIRA, P. A. C. V. “Ética e Inteligência artificial: da Possibilidade Filosófica de Agentes Morais Artificiais”. Porto Alegre: Editora Fi, 2021.', 'SIMONDON, G. « Du Mode d’Existence des Objets Techniques ». Paris: Editions Aubier, 1989.', 'SMITH, B. C. “The Promise of Artificial Intelligence: Reckoning and Judgment”. Cambridge: MIT Press, 2019.', 'STANCIOLI, B. S., LOPES, G. F. P. “A Personificação de Agentes Autônomos de Inteligência Artificial”. Revista de Direito Civil Contemporâneo, Ano 7, Vol. 23, pp. 65-93. abr.-jun./2020.', 'WHITBY, B. “Inteligência Artificial: um Guia para Iniciantes”. Tradução de C. Blanc. São Paulo: Madras, 2004.', 'ZIVIANI, N. “A Quarta Revolução Tecnológica. Computação Cognitiva e a Humanização das Máquinas”. Disponível em https://homepages.dcc.ufmg.br/~nivio/papers/a-quarta-revolucao-industrial-fonte-julho 2017.pdf Acessado em 2 de fevereiro de 2022.\n» https://homepages.dcc.ufmg.br/~nivio/papers/a-quarta-revolucao-industrial-fonte-julho 2017.pdf', 'ZIVIANI, N. “Projeto de Algoritmos e Estruturas de Dados”. Campinas: Editora UNICAMP, 1986.']","['Publicação nesta coleção\n29 Maio 2023', 'Data do Fascículo\nAbr 2023']",[' Mariah Brochado '],['\n          mbrochado@gmail.com\n        '],http://www.scielo.br/scielo.php?script=sci_arttext&pid=S0100-512X2023000100075&lang=pt,2024-11-21 09:59:43.103531,Scielo.org
O uso de inteligência artificial na tomada de decisão judicial,"Neste artigo, é apresentada a síntese de análises críticas realizadas em pesquisas coordenadas pela autora e pelo autor sobre a falta de transparência e o problema dos vieses no uso de sistemas de inteligência artificial (IA) como apoio ou para a efetiva tomada de decisão judicial, a partir do contexto brasileiro. Do ponto de vista metodológico, foram desenvolvidas pesquisas bibliográficas, documentais e empíricas nas investigações. Foram feitos exames analítico-interpretativos acerca dos materiais levantados para alicerçar as considerações. Na abordagem, foi elaborada uma breve descrição acerca do estado da arte quanto ao uso de IA pelo Judiciário nacional, seguida pelas análises sobre a opacidade dos algoritmos e os vieses cognitivos, conforme os tópicos relacionados com a incompatibilidade estrutural entre o processamento de dados pela IA e a aplicação do Direito; a incapacidade da IA realizar juízos de valor; a acentuação dos vieses cognitivos pela IA; e a falta de transparência em relação aos algoritmos e aos dados utilizados pela IA. Ao final, são apresentadas propostas para enfrentamento dos problemas com o uso de IA para a tomada de decisão judicial.","Neste artigo, são expostos resultados alcançados a partir das investigações em desenvolvimento no Grupo de Pesquisa Inteligência Artificial aplicada ao Direito - liderado pela autora, na Universidade Federal de Juiz de Fora - e do Projeto de Pesquisa Esperança Garcia, coordenado pelo autor na Universidade Federal Rural do Semiárido.
As tecnologias da informação (TI) permeiam a realidade, gerando impactos constantes. No direito, a utilização de IA é considerada inevitável1
, pois entendida como decorrência das transformações da “sociedade em rede”2
e da chamada “quarta revolução industrial”3
.
Diversos fatores socioeconômicos, institucionais e de avanços nas TI contribuíram para a emergência do fenômeno em análise. O processo de informatização do Judiciário no Brasil foi fundamental, pois propiciou a formação de grandes bancos de dados (big data) - condição para o desenvolvimento das IA, baseadas na aprendizagem de máquina (AM).
O uso de IA na produção das decisões judiciais, como ferramenta auxiliar ou como produtora direta da decisão, ocorre no Poder Judiciário em vários países atualmente4
. No Brasil, em 2021, segundo o painel Projetos com Inteligência Artificial no Poder Judiciário, do Conselho Nacional de Justiça (CNJ), foi observado que havia 41 projetos em 32 tribunais5
.
Entretanto, ainda em 2021, percebeu-se inexatidão nos números sobre a utilização de IA no Judiciário brasileiro e imprecisão na distinção entre programas de IA e de automação. Segundo relatório elaborado pelo Centro de Inovação, Administração e Pesquisa da Fundação Getúlio Vargas (FGV), foram inicialmente identificados 72 projetos de IA nos tribunais brasileiros. Contudo, a própria FGV retificou esse número para 64 projetos em 47 Tribunais, exatamente em virtude da reavaliação de algumas ferramentas como automação e não como IA6
. Na 2ª edição do relatório da FGV, foi registrada a mesma quantidade de projetos e de Tribunais, acrescentando-se que 59 programas de IA e/ou automação já foram implantados7
.
No cenário brasileiro, as informações sobre o uso concreto dos programas de IA e/ou de automação na tomada de decisão judicial são escassas, confusas e, por vezes, contraditórias. Geralmente, são encontradas nos sítios oficiais dos Tribunais, enquanto as respostas oficiais em face de solicitações formais por pesquisadores do tema no âmbito acadêmico mostram-se lacônicas ou ambíguas.
Nesse sentido, dois problemas se destacam: a (falta de) transparência nos sistemas de IA e os vieses cognitivos replicados na decisão judicial com uso de IA. Tais problemas suscitam especialmente quatro abordagens: (a) a incompatibilidade estrutural entre a forma de processamento de dados pela IA e a forma de aplicação do Direito; (b) a incapacidade da IA de realizar juízos de valor e sua consequente reprodução dos juízos de valor de seus desenvolvedores; (c) acentuação pelos programas de IA dos vieses cognitivos envolvidos na decisão; (d) a opacidade dos algoritmos e dados da IA.
Não obstante, o uso de IA na produção das decisões judiciais exige a observância dos parâmetros constitucionais que regem a atividade jurisdicional, notadamente os direitos humanos, os direitos fundamentais e o Estado Democrático de Direito. A posição, inclusive, está proposta no Projeto de Lei nº 2.338, atualmente em tramitação no Senado Federal, que visa disciplinar o uso de IA no país8
.
Para a investigação dos problemas acima citados, realizaram-se pesquisas bibliográfica, documental e empírica, com levantamentos de textos científicos, de websites dos tribunais pátrios, textos normativos e documentos com informações oficiais sobre os fenômenos. Foram utilizados como referenciais teóricos o pensamento de Robert Alexy, Francisco Varela e Cathy O’Neil.9
A análise crítica das duas centrais questões mencionadas - falta de transparência nos sistemas de IA e vieses cognitivos na decisão judicial com uso de IA - é desenvolvida neste artigo em três etapas centrais: (i) o exame dos programas utilizados pelos tribunais brasileiros e sua classificação como sistemas de automação ou de IA; (ii) a avaliação crítica do uso de IA na tomada de decisão judicial, em face da opacidade dos algoritmos e dos vieses que as respostas da IA podem apresentar; (iii) a apresentação de propostas como contribuição para solução daqueles problemas.
A informatização do Poder Judiciário iniciou-se nos anos 50 nos EUA e em alguns países da Europa, e no final dos anos 60, no Brasil.10
Já o uso de IA no Judiciário brasileiro para auxiliar na decisão judicial tem antecedentes históricos nos anos 70 do século passado. Em 1971, existe registro do uso direto de computador para resgatar textos decisórios sobre questões de acidentes de trabalho e de problemas de saúde ocupacional (chamado de “sistema PRAT” - Processos de Acidentes do Trabalho), que foi descrito como “um relacionamento da máquina com o processo decisório”, ainda que restrito à tarefa auxiliar ou de suporte à decisão, comparada ao serviço de “um secretário ao qual o juiz ditasse a sua decisão”11
.
Ainda naquela época, foram produzidas análises e obras acadêmicas sobre a informática jurídica e/ou juscibernética, nas quais houve problematização do uso das ferramentas na decisão12
. Porém, o que se mostra atual é a quantidade de softwares e o nível de sofisticação dos equipamentos e dos programas, de acordo com os avanços tecnológicos das últimas décadas, deste século. Contemporaneamente, há diversas IA implantadas e em desenvolvimento para realizar algumas tarefas relacionadas com o auxílio às decisões ou com a própria tomada de decisões judiciais, bem como para a gestão do processo judicial.13
Os diversos programas de informática foram desenvolvidos e implementados com várias funcionalidades específicas, que se referem a etapas diferentes do processo judicial - desde a simples leitura da petição (porta de entrada para o sistema judicial), passando pela classificação, extração de dados, agrupamento de casos, outros atos processuais e a decisão final do(s) caso(s), até deliberações sobre atos de execução da decisão judicial. Destarte, os programas de automação e de IA podem gerar possibilidades de implicações diversificadas nas tomadas de decisões judiciais, em relação a momentos distintos do processo judicial.
Por conseguinte, muitos dos softwares utilizados no processo judicial brasileiro se inserem na estrutura da tomada de decisão, na medida em que realizam operações que selecionam as informações, fornecendo-lhes sentido de acordo com cada uma das funcionalidades em que trabalham. Os programas de automação e/ou de IA elegem e confeccionam os atos processuais que são suas finalidades, seus propósitos.
Em face do cenário descrito, o CNJ buscou centralizar todas as iniciativas implantadas e em desenvolvimento nas várias unidades da organização institucional. É relatado que o programa “Justiça 4.0”, lançado em 2021, congrega essa proposta de centralização, na medida em que reúne múltiplas plataformas e outros programas: Juízo 100% digital; Balcão Virtual; Plataforma Digital do Poder Judiciário (PDPJ); “o auxílio aos tribunais nos registros processuais primários; a consolidação, implantação, tutoria, treinamento, higienização e publicização da Base de Dados Processuais do Poder Judiciário (DataJud)”; Codex; difusão da Plataforma Sinapses14
; tudo destinado àquela finalidade de centralização, com a ideia de unificação ou, pelo menos, de propiciar a comunicação e compartilhamento.
Nesse quadro, observa-se que a tendência é de que se consolide a realidade de digitalização e virtualização de todas as rotinas, sub-rotinas, atos e tomadas de decisões acerca do processo judicial, que já tenham sido objeto de automação ou IA, conforme toda aquela profusão de programas criados, desenvolvidos, em desenvolvimento e implantados ou em implantação. Afinal, as unidades do Judiciário, por meio daquelas plataformas e programas do CNJ, podem acessar e implantar todos os programas de automação e IA que já estejam em operação15
. Provavelmente, as atividades do programa “Justiça 4.0” também poderão criar as condições para a comunicação entre as instâncias do judiciário, de modo que possa ocorrer uma extensa padronização das decisões.
Em virtude dos possíveis impactos em valores relacionados aos direitos fundamentais e ao regime democrático, as respostas dadas pelas máquinas a várias das tarefas a elas atribuídas no processo judicial deveriam se submeter à revisão humana. Entretanto, a pesquisa desenvolvida pela FGV exposta na 2ª edição de seu relatório, aferiu que apenas em “pouco mais da metade das iniciativas (54%)” já implantadas, as respostas da máquina são submetidas a “algum tipo de validação humana”, sem maiores detalhes de como são os procedimentos16
.
Pondera-se, ainda, que a condição de os seres humanos figurarem como “supervisores” ou “validadores” das decisões, atos processuais e seus respectivos textos produzidos pelas máquinas pode significar um deslocamento ou até substituição, em que, talvez, a atividade humana se torne secundária na tomada de decisão judicial. É que a função humana desempenhada pode se resumir em apenas “clicar” para “validar” a decisão da máquina e “autorizar” a inserção das respostas no processo judicial. Ou seja, a rapidez da máquina em oferecer as respostas, a ideia de que as soluções da máquina possuem elevada acurácia e a capacidade de fazê-lo para uma quantidade grande de processos judiciais ao mesmo tempo indicam a possibilidade de que a validação seja só um “click”, pois os seres humanos operam com os vieses da confiança, confirmação, facilidade, conveniência, comodidade, dentre outros17
. A organização institucional e as pressões do sistema judicial por metas, celeridade e eficiência concorrem para que o trabalho já realizado pela máquina não seja revisto ou refeito, mas apenas encaminhado para finalizar o processo judicial.
Quanto à revisão humana de decisões, no PL nº 2.338/2023, determina-se que é direito da pessoa que tiver seus interesses impactados de maneira significativa por decisão tomada por IA (art. 10), devendo o Poder Público que contratar, desenvolver ou utilizar sistemas de IA adotar medidas que garantam tal direito (art. 21, inc. IV)18
.
Apesar das informações até então oferecidas, no levantamento de dados relativos à realidade nacional (descrita pelo CNJ e nos relatórios da FGV19
), verificou-se a ocorrência, também no contexto brasileiro, de falta de transparência acerca do uso dos sistemas de IA na tomada de decisão judicial e da falta de abertura para a revisão de eventuais problemas decorrentes dos vieses cognitivos na decisão judicial com uso de IA.
A falta de transparência no Judiciário nacional é marcada pela dificuldade de acesso às informações relativas ao uso de IA. Os websites oficiais e os boletins dos tribunais informam apenas de forma esparsa se alguma IA está em uso nas decisões judiciais ou se está em instalação20
. Na busca por mais informações, foi enviada mensagem eletrônica ao setor de atendimento do STF e do Tribunal de Justiça de Minas Gerais (TJMG) para obter resposta quanto à implantação da IA ou à sua utilização em decisões definitivas21
.
A falta de transparência em relação à utilização de IA pelo Judiciário brasileiro é evidenciada pelo citado Painel de Projetos de Inteligência Artificial do CNJ22
. A dificuldade de acesso a informações a respeito fica notória, por exemplo, já pelo fato de apenas 22% dos tribunais disponibilizarem publicamente os algoritmos dos programas, o que possibilita a auditabilidade de apenas menos de um quarto da IA atualmente em uso pelo Judiciário pátrio. A situação é ainda mais grave quando tais programas são desenvolvidos por empresas privadas, que detêm a propriedade intelectual e o sigilo comercial em virtude do direito de patente - realidade de quase um terço dos programas adotados pelos Tribunais investigados pelo CNJ.
Por sua vez, quanto aos vieses algorítmicos, as chances de potencialização, em caso de sua ocorrência, são elevadas, pois apenas 4% dos dados inseridos nos programas de IA em uso pelo Poder Judiciário são publicamente disponíveis e podem ser revisados23
. Acontece que as maiores chances de desvios cognitivos estão na seleção dos dados a serem processados pela IA, pois tais dados são escolhidos a partir da valoração atribuída a características que os singularizaram, eliminando-se outras possibilidades, portanto.
Deve-se destacar que transparência, auditabilidade, e rastreabilidade são propostas no PL nº 2.338 como princípios do desenvolvimento, implementação e uso da IA no país (art. 3º, inc. VI, IX), enquanto a publicidade encontra-se estipulada como dever do Poder Público ao contratar, desenvolver ou utilizar sistemas de IA na administração da justiça (art. 17, inc. VII; art. 21, inc. VI). Aliás, é relevante mencionar o caráter altamente protetivo aos indivíduos e à democracia do PL nº 2.338, que coloca, já em seu art. 1º, a proteção dos direitos fundamentais como o primeiro objetivo do desenvolvimento e uso de IA no Brasil e determina como seus fundamentos iniciais a centralidade da pessoa humana, o respeito aos direitos humanos e aos valores democráticos (art. 2º, inc. I e II)24
.
Sem embargo, na 3ª edição do relatório da pesquisa FGV antes referida, foi assinalado que o programa “Justiça 4.0” também cumpriria o papel de oferecer transparência e auditabilidade às ferramentas de IA e automação do Judiciário brasileiro. No entanto, resta evidente o contraste entre, de um lado, as diretrizes daquele programa e da Resolução nº 332/2020 do CNJ, e, de outro, os dados e as informações colhidos nas visitas técnicas realizadas nos Tribunais selecionados (amostragem)25
. Verificou-se pela pesquisa citada que, em geral, há problemas de falta de transparência e de auditabilidade quanto ao uso das ferramentas tecnológicas investigadas na pesquisa citada26
.
Outrossim, em relação à rastreabilidade, expressa pelas referências à “explicação satisfatória” e à “auditoria por autoridade humana” das decisões oferecidas pela máquina, observou-se que as ferramentas pesquisadas pelo grupo da FGV “revelam carência de informações [...] para o público externo ao tribunal quanto a qualquer proposta de decisão apresentada pelo modelo de Inteligência Artificial, especialmente quando essa for de natureza judicial”. Não há possibilidade alguma de o jurisdicionado ter conhecimento dos critérios e parâmetros utilizados na resposta dada pela máquina27
.
Em que pese as situações descritas até então, a pesquisa sobre o estado da arte do uso de IA pelos Tribunais brasileiros encontra-se sintetizada nos quadros seguintes, discriminando-se as atividades realizadas pelos programas de informática do STF, do Superior Tribunal de Justiça (STJ) e de todos os Tribunais de Justiça (TJ) do país. Especial destaque é dado ao programa Victor no STF, por ser essa uma das IA mais avançadas no Poder Judiciário brasileiro e estar em uso na Corte máxima do país, cujas decisões geram o maior impacto social na realidade nacional.
A finalidade do Victor no STF é o auxílio na decisão acerca da repercussão geral (RG) nos processos29
. Para tanto, demandam-se vários procedimentos - como ocerização de documentos e determinação de temas de RG - que exigem algoritmo com nível próprio de IA. Examinam-se 5 peças dos autos - acórdão recorrido, juízo de admissibilidade do recurso extraordinário (RE), petição do RE, sentença e agravo no RE - segundo 27 temas de RG30
.
Como exposto, buscou-se, junto ao canal de acesso à informação do STF (em agosto de 2021), esclarecimento acerca da instalação e execução do programa Victor31
. Do retorno, extrai-se que (i) o projeto iniciou-se no final de 2017; (ii) implementaram-se as fases de leitura, tratamento e extração de dados dos textos dos arquivos dos processos (ocerização); (iii) o módulo de classificação de peças está em implantação; (iv) a realização de testes de inferência dos temas de RG está em andamento, “havendo a expectativa de que ainda em 2021 os resultados sejam apresentados”. As informações não deixam nítido sobre se (e como) está em uso o Victor nos processos concretos, e são insuficientes quanto aos aspectos técnicos da IA.
Entretanto, não se identificou - nem em dezembro de 2021, nem nos meses seguintes em 2022 - qualquer alteração no site do STF no que tange às informações relativas à utilização e aos resultados do Victor. Isto é, a não divulgação desses dados impede o acesso ao conhecimento sobre a principal IA relacionada ao Poder Judiciário brasileiro. Porém, em recentes notícias veiculadas no sítio oficial do STF na internet, a informação foi de que a IA Victor estaria em uso desde 201732
. Independentemente de quando entrou em operação, o fato é que as pessoas não tomam ciência de que seu caso foi julgado pela máquina ou com apoio nela, visto não haver informação a respeito no processo33
.
Em outra oportunidade, foram solicitadas informações técnicas ao setor de TI do STF sobre o Victor. No quadro 2, discriminam-se as perguntas e respectivas respostas34
.
Das respostas, formulam-se algumas observações: (i) a justificativa para negar acesso público ao código-fonte da IA Victor é a segurança do sistema e dos dados; (ii) ao que tudo indica, não se seguiram padrões metodológicos e estatísticos para a aprendizagem e testes; e (iii) há algumas divergências entre as informações prestadas e as descrições do Victor pelas coordenações acadêmicas do projeto - por exemplo, os percentuais de treino e de teste (80% e 20%) destoam dos valores informados nos artigos e livros (70% de treino; 20% de testes; e 10% de validação), e a técnica de árvore de decisão parece não se coadunar com a descrição de uso de redes neurais convolucionais36
ou de deep learning37
, descritas para o Victor na produção acadêmica.
Interpretou-se que os documentos e a bibliografia consultada não trazem elementos descritivos precisos sobre os parâmetros do algoritmo do Victor, pois se referem, em geral, às propostas para o modelo, testes realizados e à defesa de que se trata de ferramenta que incrementa a eficiência nos procedimentos de análises e decisões sobre a RG nos processos de RE. Ao mesmo tempo, as informações parecem indicar que o escopo institucional para o Victor é operar na redução do quantitativo de processos38
.
Os quadros 3 e 4 referem-se aos TJ, fazendo-se uma proposta para a separação respectivamente dos programas de IA daqueles de automação. A distinção reside em que os algoritmos de automação são criados para o processamento de dados com base em regras voltadas para a resolução de um problema ou realização de uma tarefa mecânica ou repetitiva, sem que haja aprendizagem, trabalhando-se sempre com as mesmas entradas, das quais permanentemente resultam as mesmas saídas. Por sua vez, a IA baseada em AM apresenta algoritmos que, mediante o treinamento com o banco de dados (aprendizagem), podem oferecer soluções diversas para entradas semelhantes, a partir dos padrões encontrados no banco de dados. Assim, todas as IA “são automações, mas nem todas as automações são sistemas inteligentes”39
.
Verificou-se que, dos 25 programas levantados nos TJ, a maioria das funções é desempenhada por ferramentas de automação. Identificou-se que alguns programas são utilizados em mais de um TJ (como o programa Leia Peticionamento) e que TJ diferentes atribuem nomes distintos a programas que realizam basicamente a mesma função - como os programas Hércules (TJAL), Elis (TJPE), Classificador de Petição de Execução Fiscal (TJSC).
É interessante perceber que a análise e interpretação de programas como IA ou como automação não é pacífica, havendo discrepâncias e indistinções, seja na doutrina seja pelos agentes do Judiciário que lidam com os projetos de elaboração e execução dos programas de informática42
. Em verdade, a confusão e indiferenciação entre IA e automação está declarada em texto normativo infralegal do CNJ - artigo 2º, parágrafo único, da Resolução n. 271/2020.
No âmbito do STF, do STJ e da justiça comum da região sul do judiciário nacional, Tiago Bruno Bruch mapeou que utilizam ferramentas de IA e/ou de automação para “elaboração e catalogação das decisões judiciais (despachos, sentenças e acórdãos)”43
- pressupõe-se que a tarefa de “elaboração” envolve tanto a tomada de decisão como a confecção da minuta do texto do ato decisório. Segue um quadro ilustrativo:
Em suma, considerando o estado da arte com relação aos programas de IA e/ou automação no Judiciário brasileiro, bem como as informações ainda que esparsas e com certa ambiguidade sobre o uso das ferramentas na tomada de decisão judicial, ao que tudo indica, a prática de delegar a atividade decisória às máquinas no Judiciário nacional45
já pode se encontrar em franca realização, sem que as partes e seus advogados ou advogadas sejam cientificadas a respeito, pois os textos das decisões judiciais recebem apenas a assinatura eletrônica do magistrado ou magistrada responsável, desprovida da informação de que houve apoio da máquina para a escolha de solução efetuada e para o respectivo texto apresentado46
.
A utilização de IA como ferramenta auxiliar ou como produtora direta da decisão judicial levanta distintos questionamentos e apresenta diferentes problemas, dentre os quais destacam-se a falta de clareza em relação aos algoritmos instalados nas máquinas e os consequentes vieses algorítmicos. Discutem-se abaixo questões relevantes envolvidas com a opacidade e os vieses algorítmicos.
Entre as lógicas da IA e do Direito há não apenas diferenças, mas oposição geradora de incompatibilidade estrutural. As IA (baseadas em dados) operam com generalizações, agrupamentos de dados, segundo sua parametrização, enquadrando cada dado singular em grupos ou modelos predeterminados segundo a fórmula do programada no sistema (padronização). Esses conceitos são precisamente opostos aos de individualização e singularidade com que trabalha o Direito no momento da aplicação da norma jurídica na decisão judicial.
Na decisão judicial, a norma jurídica geral e abstrata é tornada individual, do caso concreto, cujas condições particulares conferem singularidade à situação sub judice e ao sujeito. Logo, o uso de IA na decisão judicial pretere exatamente as condições fáticas e jurídicas singulares do caso concreto, que individualizam a situação em juízo. No entanto, as noções de singularidade do caso concreto possuem essencial relevância para o Direito, apresentando-se como princípios jurídicos, como a individualização da pena e a responsabilidade pessoal, no direito penal, e a máxima da proporcionalidade como instrumento para solução de antinomias principiológicas.
No que tange à individualização do caso concreto em julgamento, à consideração de suas particularidades, e das singularidades dos indivíduos nela envolvidos, deve-se destacar que no PL nº 2.33847
chega-se ao ponto de disciplinar, como se fosse real, situação faticamente inexistente, em virtude da impossibilidade de sua ocorrência: em seu art. 9º, § 2º, inc. III, há a determinação de que a pessoa afetada por sistema de IA terá o direito de contestar e de solicitar a revisão de decisões que impactem de maneira significativa seus interesses, se essas decisões se ampararem em inferências que “não considerem de forma adequada a individualidade e as características pessoais dos indivíduos”. Ora, como exposto, a consideração de tal individualidade e de características pessoais é atividade simplesmente impossível a programas de IA - pelo menos, tal como se estrutura hoje seu processamento de dados.
Magalhães aduz que o conhecimento jurídico opera como obstáculo à implementação de IA ao Direito, visto que impõe limitações às simplificações que são exigidas pelos modelos e linguagens da IA para representação do conhecimento48
. São limites:
De ordem subjetiva, em razão das ideologias, valores e interesses que estão presentes nas formulações do dever ser: (i) relativos ao conhecimento implícito ou tácito, que pode ser descrito pela cultura e pelo senso comum dos juristas, ou pela perícia adquirida nas experiências, presentes nas suas mentes e não nos códigos, jurisprudência e/ou livros; (ii) interpretativos, que envolvem aspectos pessoais, sociais e culturais acerca da realidade, geradores de pré-compreensões e representações conceituais inalcançáveis pela IA, bem como questões acerca de métodos de interpretação; (iii) relacionados com a incerteza e textura aberta da linguagem jurídica, abrangendo impossibilidades de tratabilidade computacional e de formalização da linguagem jurídica;
Lógicos, referem-se à incapacidade de os modelos lógico-matemáticos abarcarem, na automatização do raciocínio jurídico, a possibilidade de simular ou reproduzir a complexidade de inferências analógicas que se perfazem no raciocínio jurídico;
Jusfilosóficos, relativos às questões éticas e de responsabilidade da IA quanto à tomada de decisão.
A par das limitações, é preciso saber a base de conhecimento (BC) jurídico utilizada para a representação na linguagem algorítmica, a fim de avaliar se ocorreu uma simplificação válida e aceitável, ou se houve uma redução que não se afigura adequada. As informações colhidas acerca das IA em desenvolvimento e/ou operação no Judiciário brasileiro não permitem essa aferição.
A respeito da representação do conhecimento nas IA, não é possível saber com precisão quais foram os dados tomados como substitutivos de valores e crenças sobre um determinado instituto jurídico. Por exemplo, no caso do Victor, aparentemente as classificações daquelas cinco peças jurídicas do RE e dos temas nelas encartados podem ter sido os dados substitutivos escolhidos para operar como representação do conhecimento49
, com o objetivo de serem informados para consulta à BC sobre a RG representada no algoritmo da IA - porém, essa BC não é descrita.
Os problemas do uso de IA para a decisão judicial começam na estrutura da própria ontologia50
de representação do conhecimento e da incompatibilidade entre as linguagens da IA e do Direito. Atualmente, as dificuldades aludidas mostram-se insuperáveis, pois não é possível expressar as atividades mentais por meio de representações com regras e símbolos51
.
A tomada de decisão judicial implica não apenas o conhecimento de dados, mas julgamentos, com elaboração de juízos de valor sobre atos, fatos, interesses que compõem a realidade. A valoração de algo como bom (juízo de valor) ou como devido/correto (juízo de dever) deve ser atividade exclusivamente humana, pois a determinação da vida cabe ao próprio indivíduo e à sociedade na qual se insere, sob pena de alienação de sua capacidade de autodeterminação, de liberdade. A delegação à IA dessa competência decisória pode significar alienação da liberdade, que, como direito fundamental, é inalienável52
.
Não obstante, a IA não consegue (hoje) realizar juízos de valor - pode reproduzi-los, caso inseridos subliminarmente no seu código, mas não os elabora autonomamente. O algoritmo é programado para identificar os dados e suas características para então classificá-los conforme seu código matemático, “rotulando” tais dados, “encaixotando-os” nas alternativas de modelos prefixados como resultados possíveis. Essa atividade não se confunde com juízo de valor, mas tem forma análoga a um juízo de fato, o qual é fundado exatamente na cognição da realidade53
. Diversamente, juízos de valor não tratam do conhecimento da realidade, mas de seu direcionamento segundo os valores do Bem (Moral) e da Correção (Direito)54
.
Os algoritmos, que são base para toda a aprendizagem da IA, ou as regras de automação de algum programa para lidar com os atos processuais, são limitados à dimensão linguística do Direito, sem possibilidade alguma de apreensão e processamento sobre os acontecimentos reais acerca da relação sociojurídica desenvolvida antes, durante e depois do processo judicial. Isto é, estruturalmente não oferecem elementos que possam processar e lidar com aspectos interacionais ou comunicativos das relações sociojurídicas, nas dimensões concretas da vida. Dessa forma, aquele problema e dificuldade estrutural descrito antes, geralmente indicado como uma vantagem para o julgamento por meio da IA, pode também oferecer desvantagem para o uso da ferramenta na decisão judicial, pois as informações acerca dos desequilíbrios, assimetrias, explorações, opressões, exclusões e demais aspectos das desigualdades na relação jurídico-processual não serão processadas pela máquina, logo, não poderão ser tratadas e reguladas pelo Direito no caso concreto decidido por meio da IA, no sentido de desfazê-las material e formalmente.
Com efeito, a decisão por humanos envolve um nível de processamento e escolhas integradas com o ambiente, que “não podem ser isolados sem que eles percam muitas das suas funcionalidades”, bem como não se reduz à “lógica binária usada por computadores digitais”. A computabilidade da máquina para simular a decisão humana “é, portanto, uma construção alfanumérica”, na qual não é possível alcançar as formas analógicas de processamento por sistemas biológicos - os quais encerram “bilhões ou mesmo trilhões de parâmetros, que definem o estado atual do cérebro”, não tratáveis nem sequer apreensíveis pelo sistema formal e simbólico dos algoritmos55
.
Destarte, o algoritmo não tem a habilidade de avaliar um dado como bom ou mau, justo ou injusto. Seu código simplesmente reproduz a avaliação feita pelo desenvolvedor ao associar determinado dado com certo modelo de resultado entendido (pelo desenvolvedor) como bom, positivo, correto.
A análise dos vieses cognitivos que se transmudam em vieses algorítmicos exige uma abordagem pluridisciplinar, envolvendo conhecimentos de neurociências, IA, linguística, epistemologia e psicologia cognitiva, pelo menos56
.
Na decisão, ilusões cognitivas ou de pensamentos podem ser determinantes, destacando-se as heurísticas e os vieses cognitivos57
. As heurísticas podem ser crenças, emoções ou outras funções que operam na tomada de decisão, de modo intuitivo. São espécies de atalhos para as decisões, em que, por exemplo, a zona de conforto ou o status quo é a escolha mais fácil, vez que promove a substituição das análises mais reflexivas, aprofundadas e com base nas estatísticas (por isso, trabalhosas e onerosas), pelas crenças, estereótipos, e/ou repertório já constituído - gerando, assim, os vieses58
. Vieses são formas nas quais as heurísticas aparecem nos julgamentos59
.
No caso do Judiciário, o big data formado pelos arquivos digitais de decisões anteriores (histórico), representativas de toda cultura judicial, é permeado pelos vieses cognitivos existentes e tendencialmente naturalizados pela cultura de cada sociedade. Uma vez consignados nos textos repetidamente, vão se transmutar em dados para a aprendizagem da máquina. Serão assimilados enquanto padrões e, de sua reiterada reprodução decorrem tanto a ampliação do viés cognitivo, quanto a redução das possibilidades interpretativas e inviabilização de sua modificação60
.
Assim, o modo de produção das decisões judiciais, na plataforma do processo no sistema judicial, induz à consolidação de vieses cognitivos para a decisão judicial, pois a estrutura opera com bloqueios para processos cognitivos de reflexão a respeito dos próprios vieses - um círculo vicioso fechado61
. Todos os preconceitos, discriminações, injustiças, e “erros” de interpretações, que se estabelecem em função das estruturas racistas, machistas, LGBTfóbicas, de poder, de (falsas) hierarquias, da insensibilidade e indiferença sociais, das desigualdades socioeconômicas etc. - vieses cognitivos humanos, enfim -, são replicados e mantidos, porque reconhecidos enquanto padrões pela IA para a tomada de decisão.
Um exemplo concreto se deu no Judiciário estadunidense, com o uso da IA COMPAS para análise de risco de reincidência e atribuição de pontuação para apoiar as decisões judiciais sobre livramento condicional e outros benefícios da execução penal - foi identificado um viés racista, pois pessoas negras receberam pontuações de risco alto por causa do bairro que moravam (de população com menor poder econômico, majoritariamente negra) ou outros fatores implícitos, enquanto pessoas brancas, que mereceriam maior pontuação de risco de reincidência, obtiveram pontuação mais baixa62
.
Todos aqueles procedimentos são padrões decisórios humanos, que podem ser transpostos para as máquinas. Por conseguinte, os vieses cognitivos envolvidos na tomada de decisão com auxílio de (ou exclusivamente por) IA, chamados vieses algorítmicos, recebem denominação imprecisa ou inexata, pois o desvio no processo de conhecimento não se origina no algoritmo, mas no seu desenvolvedor. A transposição dos vieses cognitivos humanos para a máquina, com sua assimilação ou incorporação pela IA, ocorre em razão das formatações, configurações e comandos (parametrizações) da programação de aprendizagem e execução da IA63
, e pela própria seleção dos dados a serem utilizados na aprendizagem.
Porquanto a IA reproduz juízos de valor dos seus desenvolvedores, qualquer resultado enviesado apresentado não é inerente aos programas nem é por eles gerado, mas decorre dos dados inseridos, do seu cruzamento e combinação, dos pesos a eles atribuídos, das relações de implicação e inferência entre eles estabelecidas, no algoritmo e na arquitetura do sistema.
Em síntese, nesse processo de reprodução automática, de modo sistemático, do que já está estabelecido, a única atividade exclusivamente realizada pela IA é o reforço e a potencialização dos vieses humanos, a ampliação exponencial dos preconceitos sociais, ante a notória superioridade da velocidade de processamento de dados da IA.
Entretanto, quando sistemas de IA com vieses algorítmicos são utilizados pelo Poder Público, àquela potencialização e reforço dos preconceitos humanos soma-se a institucionalização desses preconceitos, a oficialização do tratamento discriminatório, enfim, a legalização do ilegal64
.
Assim, como consequência do uso de IA em decisões judiciais, deve-se ainda destacar que da reprodução do que já está estabelecido, advém a manutenção do status quo, com a perpetuação dos valores e parâmetros do passado para a condução das demandas do presente.
A introdução dos programas de IA e/ou automação “dá origem a novas formas de lidar com os dados e produzir informações no circuito da comunicação” do Judiciário brasileiro. Diferentemente da tomada de decisão por humanos, a máquina não lê textos em busca dos significados, uma vez que os computa independentemente da compreensão do seu sentido, de maneira que produz informação distintamente, na medida em que as seleções são orientadas e realizadas por outros critérios - estabelecidos pela estrutura do algoritmo65
.
Diversamente dos demais sistemas de IA que operam na web, os programas do Judiciário brasileiro não contam com as alternativas do big data da internet, que dispõe de outras interpretações sobre os temas e situações jurídicas dos casos avaliados, tanto práticas (outros Tribunais ou outras esferas de tratamento das matérias) como teóricas (repositórios das academias, por exemplo). Muito provavelmente, as IA e/ou automações no Judiciário do Brasil podem funcionar ou trabalhar numa “bolha”, como “câmara de eco” do próprio Judiciário. A situação de “bolha” pode representar uma dimensão da opacidade, porque a IA vai realizar uma seleção pré-ordenada das informações (com base no passado “aprendido”), em que as informações foram transformadas em dados e a operação seletiva é efetuada mediante computação, cálculos, inferências, acerca dos padrões e correlações dos dados, por meio das linguagens de programação, sem que se tenha o tipo de compreensão sobre os significados e os potenciais de sentidos das informações, própria do raciocínio humano66
.
A transparência algorítmica exige desde o acesso ao código-fonte até o dever de informação de que a IA foi usada para apoio à decisão judicial, ou mesmo a efetuou, com explicação em linguagem natural e inteligível dos parâmetros da IA para o processamento de informações, sua funcionalidade e finalidade, os dados utilizados e o próprio modo de decisão67
.
Outros aspectos da transparência são a necessidade de amplo debate público sobre a utilização da IA para a decisão judicial, seus parâmetros68
e a realização contínua e permanente de auditorias sobre a IA69
. Entretanto, no mercado das IA, prevalecem os modelos opacos - “caixas pretas inescrutáveis” -, de forma que os modelos transparentes são raras exceções70
. No âmbito do Poder Judiciário, não se conhecem (i) os dados fornecidos à IA, (ii) o código da IA utilizada na decisão judicial, e (iii) como são organizados os dados destinados à máquina, então se desconhecem as informações envolvidas no processo judicial, o que afeta diretamente tanto a ampla defesa71
quanto o contraditório, pois as partes não sabem do que se defender, nem o que contraditar72
. A falta de transparência no uso de IA pelo Judiciário configura evidente afronta ao princípio da publicidade, orientador do Estado Democrático de Direito.
As situações antes problematizadas merecem enfrentamentos mais dedicados para que o uso de IA na decisão judicial seja criticamente avaliado, em virtude dos riscos concretos de violações a direitos humanos, direitos fundamentais e a valores e princípios regentes do Estado Democrático de Direito.
Dado que a regulação por meio da Resolução nº 332/2020 do CNJ não se encontra satisfatoriamente cumprida73
, uma providência imediata é a regulamentação da IA, estabelecendo-se princípios que orientem seu desenvolvimento e utilização conforme parâmetros de transparência, segurança, responsabilidade, rastreabilidade, imparcialidade, valores democráticos, direitos humanos, direitos fundamentais. Nesse sentido, como dito, está em tramitação no Congresso Nacional o PL 2.338, que possui forte embasamento em normas internacionais como o Regulamento de Inteligência Artificial da do Parlamento Europeu e a Carta Europeia sobre a Utilização da IA nos Sistemas Judiciais e no Respectivo Ambiente74
.
Embora propostas que contribuam para a resolução das questões destacadas estejam sob investigação, podem-se seguramente mencionar:
Abertura à participação de representatividades das categorias profissionais jurídicas e da sociedade civil organizada, propiciando amplo debate público sobre o uso de IA na decisão judicial;
Realização de auditorias externas nas IA, enfrentando-se os problemas da falta de transparência e dos vieses, devido à possibilidade de acesso às informações e resultados da IA. O modelo usado para auditar as urnas eletrônicas é promissor75
;
Estudo das possibilidades de configurações híbridas de IA para a tomada de decisão, com modelos baseados não só em dados, mas também em conhecimento. Essa formatação propicia lidar com as incompatibilidades estruturais entre a IA e o Direito, uma vez que permite à característica dialógica e democrática do processo judicial incidir no processamento das informações pela IA, inserindo as vozes dos demais atores processuais como informações a serem sopesadas pelo sistema nas decisões76
;
Informação às partes, endoprocessual e oficialmente, sobre o uso de IA no processamento dos dados e na decisão, promovendo-se assim a transparência algorítmica;
Abertura de possibilidade às partes de, com base nas informações fornecidas sobre a IA utilizada, avaliar e dizer se concordam ou não com a atividade. Caso uma parte não consinta, o procedimento a ser adotado pode ser, por analogia, o mesmo aplicado aos RE e recursos especiais repetitivos - art. 1.037, §§ 8º ao 13, do Código de Processo Civil (CPC) -, em que a parte informa as razões de distinção de sua causa em face da classificação operada pela máquina, solicitando que seu processo seja destacado para julgamento por humanos;
Possibilidade de veiculação de pedido de nulidade ou de revisão da decisão judicial por IA, na hipótese de falta de conhecimento e consentimento prévios do sujeito77
do uso de IA na tomada de decisão78
;
Utilização de técnicas de revisão e ajustes (fine tuning) durante os testes para o combate aos vieses, bem como uso de validações da aprendizagem ancoradas em possibilidades de funções algorítmicas representativas de procedimentos de desenviesamento, tais como: substituição de padrões, raciocínio contraintuitivo, through law, e modelo normativo de “reengenharia precaucional”79
;
Uniformização da IA empregada pelos tribunais brasileiros por meio do CNJ, de modo a promover a identificação e a resolução de problemas de forma mais dinâmica do que ocorreria em caso de uso de sistemas diversos no Judiciário nacional.
As proposições oferecidas não esgotam as técnicas, ferramentas e outras possibilidades para enfrentamento dos problemas.
Há inquestionáveis vantagens trazidas pela informatização e pela atual implementação de IA no Judiciário brasileiro, como o ganho em celeridade e eficiência na prestação jurisdicional. No entanto, esses parâmetros não devem ser tomados isoladamente, nem se apresentam como fins em si mesmos. Em verdade, celeridade e eficiência são qualidades que devem integrar a prestação jurisdicional, a qual se apresenta como meio para realização do fim que orienta o Direito: o valor justiça, normatizado em âmbito internacional nos direitos humanos e, em dimensão nacional, nos direitos fundamentais, cujo pleno exercício apenas ocorre sob a vigência de um regime democrático.
Ante os riscos concretos das decisões por IA - como a reprodução dos juízos de valor dos desenvolvedores das IA ou a acentuação dos vieses cognitivos envolvidos no processo de tomada de decisão - e a incompatibilidade estrutural entre a forma de processamento da IA e a forma de aplicação do Direito, afigura-se recomendável, ao menos por ora, que não sejam delegadas funções decisórias à IA no âmbito judicial. Mesmo decisões interlocutórias que envolvam juízos de valor - ou seja, que impliquem não apenas o conhecimento da realidade, mas a realização de escolhas segundo os fins eleitos -, submetem-se às limitações apontadas.
Sob outro aspecto, os problemas da falta de transparência, da dificuldade de acesso aos dados e da imprecisão de informações acerca do uso de IA nas decisões judiciais no Brasil praticamente inviabilizam seu conhecimento pelo jurisdicionado e sua análise crítica (consequentemente, sua controlabilidade) pela pesquisa científica. Por exemplo, não é possível realizar simulações, testagens ou comparações acerca das respostas oferecidas pelas máquinas, tampouco observar os parâmetros decisórios para confrontá-los com outras possibilidades dogmáticas ou jurisprudenciais.
Ademais, ressalta-se a necessidade de se promover o debate público sobre a implementação da tomada de decisão por IA no Judiciário brasileiro, pois a limitação no acesso a informações, bem como sua vagueza e discrepância, inviabilizam o conhecimento da atual utilização de programas para a decisão judicial, tanto em termos de medidas quantitativas, de intensidade e de substituição, quanto aos aspectos qualitativos. De todo modo, independentemente de como se encontra o nível de inserção e de uso da IA na tomada de decisão pelo Judiciário brasileiro, afigura-se indispensável a possibilidade de contestação de decisões tomadas por IA e de sua revisão humana. Esse é, aliás, o posicionamento adotado no PL nº 2.33880
- documento elaborado com a pretensão de se tornar o marco legal da IA no país -, ao prever o direito de contestação àquele cujos interesses forem impactados pela decisão tomada por IA.
Deve-se, sem dúvida, dar continuidade ao estudo e aprimoramento das IA para a tomada de decisões, mas os riscos e deficiências mencionados evidenciam que o atual estado da arte de desenvolvimento dos sistemas de IA indica sua utilização apenas para a realização das tarefas burocráticas e repetitivas de andamento processual. As considerações críticas aqui expostas visam, enfim, à promoção da reflexão sobre o uso de IA nas decisões judiciais, evidenciando a exigência de seu aperfeiçoamento para o desempenho dessa atividade, assim como as propostas apresentadas pretendem ser contribuições no sentido desse aprimoramento.","['ABRANCHES, Carlos Alberto Dunshee de. A aplicação cibernética ao direito e a administração da justiça. In: Conferência Nacional da Ordem dos Advogados do Brasil, 4., São Paulo. Anais [...], 1970, p. 322-339.', 'ANDRADE, André; JOIA, Luiz Antônio. Organizational structure and ICT strategies in the brazilian judiciary system. Government Information Quarterly, v. 29, s. 1, 2012, p. 32-42. Disponível em: Disponível em: https://www.sciencedirect.com/science/article/pii/S0740624X11000694 Acesso em: 20 fev. 2023.\n» https://www.sciencedirect.com/science/article/pii/S0740624X11000694', 'ANGWIN, Julia; LARSON, Jeff. Machine bias: there’s software used across the country to predict future criminals. And it’s biased against blacks. ProPublica, Nova York, 2016. Disponível em: Disponível em: https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing Acesso em: 04 dez. 2021.\n» https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing', 'ALEXY, Robert. Justicia como corrección. Doxa, v. 26, p. 161-171, 2003.', 'ALEXY, Robert. Teoria dos Direitos Fundamentais. São Paulo: Malheiros, 2008.', 'ALEXY, Robert. Legal certainty and correctness. Ratio Juris, v. 28, n. 4, p. 441-451, 2015.', 'BAVITZ, Christopher et al. Assessing the assessments: Lessons from early state experiences in the procurement and implementation of risk assessment tools. Berkman Klein Center for Internet & Society research publication, 2018. Disponível em: Disponível em: https://dash.harvard.edu/ handle/1/37883502 Acesso em: 22 jun. 2021.\n» https://dash.harvard.edu/ handle/1/37883502', 'BOBBIO, Noberto. O Positivismo Jurídico: lições de Filosofia do Direito. São Paulo: Ícone, 1995.', 'BOEING, Daniel H. Arruda. Ensinando um robô a julgar: pragmática, discricionariedade e vieses no uso de aprendizagem de máquina no judiciário. Florianópolis, 2019. 84 f. Monografia (Graduação) - Curso de Direito da Universidade Federal de Santa Catarina.', 'BRAGANÇA, Fernanda; BRAGANÇA, Laurinda Fátima F. P. G. Revolução 4.0 no poder judiciário: levantamento do uso de inteligência artificial nos tribunais brasileiros. Auditorium. 2019. Disponível em: Disponível em: http://revistaauditorium.jfrj.jus.br/index.php/revistasjrj/article/%20 view/256/194 Acesso em: 05 mai. 2020.\n» http://revistaauditorium.jfrj.jus.br/index.php/revistasjrj/article/%20 view/256/194', 'BRASIL. Projeto de lei nº 2338. Dispõe sobre o uso da Inteligência Artificial. Diário do Senado Federal Brasília, 4 mai. 2023. Disponível em: Disponível em: https://www25.senado.leg.br/web/ atividade/materias/-/materia/157233 Acesso em: 04 out. 2023.\n» https://www25.senado.leg.br/web/ atividade/materias/-/materia/157233', 'BRUCH, Tiago Bruno. Judiciário brasileiro e inteligência artificial. Curitiba: CRV, 2021.', 'CASTELLS, Manuel. Sociedade em rede. 21. ed. São Paulo: Paz e Terra, 2020.', 'CAVALCANTI, João Carlos Gonçalves. Controle e resistências no processo de informatização da corte de justiça pernambucana (1983-1992). Recife, 2020. 232 f. Dissertação (Mestrado) - Programa de Pós-graduação em História da Universidade Católica de Pernambuco.', 'CICUREL, Ronald; NICOLELIS, Miguel. O cérebro relativístico: como ele funciona e por que ele não pode ser simulado por uma máquina de Turing. Natal, Montreux, Durhan, São Paulo: Kio Press, 2015.', 'COMISSÃO de Juristas Responsável por Subsidiar Elaboração de Substitutivo sobre Inteligência Artificial no Brasil (CJSUBIA). Relatório final. Brasília, dez. 2022. Disponível em: Disponível em: https://www6g.senado.leg.br/busca/?portal=Atividade+Legislativa&q=relat%C3%B3rio+ final+cjusbia Acesso em: 04 mai. 2023.\n» https://www6g.senado.leg.br/busca/?portal=Atividade+Legislativa&q=relat%C3%B3rio+ final+cjusbia', 'COSTA-ABREU, Márjory da; SILVA, Bruno dos Santos F. A critical analysis of “law 4.0”: the use of automation and artificial intelligence and their impact on the judicial of Brazil. RDFT, 2020. Disponível em: Disponível em: http://www.rdft.com.br/revista/article/view/30 Acesso em: 12 mai. 2021.\n» http://www.rdft.com.br/revista/article/view/30', 'DEZAN, Sandro Lúcio. Desafios à transparência, à publicidade e à motivação da decisão jurídica assistida por sistemas de inteligência artificial no processo administrativo valorativo. In: PINTO, Henrique Alves et al. Inteligência artificial aplicada ao processo de tomada de decisões. Belo Horizonte: D’Plácido, 2020, p. 513-537.', 'ESPOSITO, Elena. Artificial communication: how algorithms produce social intelligence. Cambridge: MIT Press, 2022.', 'FINATEC. Fundação de Empreendimentos Científicos e Tecnológicos. Edital de Seleção Pública n. 053/2018, de 19 jul. 2018. Brasília: FINATEC, 2018. Disponível em: Disponível em: http://www.finatec.org.br/editais_finatec/files/licitacoes/2018/edital_selecao_053_2018.pdf Acesso em: 18 mai. 2020.\n» http://www.finatec.org.br/editais_finatec/files/licitacoes/2018/edital_selecao_053_2018.pdf', 'FRÖLICH, Afonso Vinício Kirschner; ENGELMANN, Wilson. Panorama da utilização da inteligência artificial nos tribunais de justiça brasileiros. Revista Brasileira de Inteligência Artificial e Direito, RBIAD, 2020. Disponível em: Disponível em: https://rbiad.com.br/index.php/rbiad Acesso em: 02 jun. 2020.\n» https://rbiad.com.br/index.php/rbiad', 'GARCIA, Dinio de Santis. Introdução à informática jurídica. São Paulo: USP, 1976.', 'KAHNEMAN, Daniel. Rápido e devagar: duas formas de pensar. Rio de Janeiro: Objetiva, 2012.', 'LAGE, Fernanda de Carvalho. Manual de inteligência artificial no direito brasileiro. Salvador: JusPODIVM, 2021.', 'O, Mario G. Lições de informática jurídica. São Paulo: Editora Resenha Tributária, 1974.', 'LÖW, Marieta Marks. Da automatização à virtualização: a criação do processo eletrônico no Brasil. Scire, Zaragoza, v. 18, p. 143-6, 2012.', 'MAGALHÃES, Renato Vasconcelos. Automatización del raciocinio jurídico: perspectivas y límites en la aplicación de la inteligencia artificial al derecho. Burgos, 2004. 627 f. Tese (Doutorado) - Faculdade de Direito da Universidade de Burgos.', 'MARTÍN, Nuria Belloso. Los desafíos iusfilosóficos de los usos de la inteligencia artificial en los sistemas judiciales: a propósito de la decisión judicial robótica vs. decisión judicial humana. In: MARTÍN, Nuria Belloso; IORIO FILHO, Rafael Mario; PINTO, Adriano Moura da Fonseca. Sociedad plural y nuevos retos del derecho. Pamplona: Editorial Aranzadi, 2021, arquivo Kindle, p. 416-515.', 'NUNES, Dierle; LUD, Natanael; PEDRON, Flávio Quinaud. Desconfiando da imparcialidade dos sujeitos processuais: um estudo sobre os vieses cognitivos, a mitigação de seus efeitos e o debiasing. 2. ed. Salvador: JusPodivm, 2020.', 'O’NEIL, Cathy. Armas de destrucción matemática. Madrid: Capitán Swing, 2020, arquivo Kindle', 'PAINEL DE PROJETOS DE INTELIGÊNCIA ARTIFICIAL. Conselho Nacional de Justiça (CNJ). 2020. Disponível em: Disponível em: https://paineisanalytics.cnj.jus.br/single/?appid=29d710f7-8d8f-47be-8af8-a9152545b771&sheet=b8267e5a-1f1f-41a7-90ff-d7a2f4ed34ea⟨=pt-BR&opt=ctxmenu,currsel Acesso em: 08 nov. 2021.\n» https://paineisanalytics.cnj.jus.br/single/?appid=29d710f7-8d8f-47be-8af8-a9152545b771&sheet=b8267e5a-1f1f-41a7-90ff-d7a2f4ed34ea⟨=pt-BR&opt=ctxmenu,currsel', 'PAULO, Euflázio. Secretaria de Tecnologia de Informação do STF. RES: Ofício - solicitação de informações sobre Projeto Victor. Destinatário: Daniel Pessoa, Brasília, 2 jun. 2021, mensagem eletrônica.', 'PEIXOTO, Fabiano Hartmann; SILVA, Roberta Zumblick Martins da. Inteligência artificial e direito. Curitiba: Alteridade Editora, 2019.', 'PESSOA, Daniel. O uso de inteligências artificiais no sistema judicial brasileiro: cenário de disputas. Unisul de Fato e de Direito. 2020, p. 41-56. Disponível em: Disponível em: https://portaldeperiodicos. unisul.br/index.php/%20U_Fato_Direito/article/view/9818 Acesso em: 18 out. 2020.\n» https://portaldeperiodicos. unisul.br/index.php/%20U_Fato_Direito/article/view/9818', 'PESSOA, Daniel. Projeto Esperança Garcia: relatos e propostas para uma pesquisa empírica sobre a inteligência artificial no modo de produção das decisões judiciais. In: CASTRO, F.A.; MAIA, M.S.F. Observatório de práticas sociojurídicas: programas de pesquisas para o campo jurídico profissional. Curitiba: CRV, 2021, p. 121-146.', 'PESSOA, Daniel. Algumas contribuições da neurociência cognitiva para explicar a decisão judicial. Campina Grande: EDUEPB, 2021a.', 'PESSOA, Daniel. Ofício - solicitação de informações sobre Projeto Victor. Destinatários: Ministro Presidente do STF, Luiz Fux; Pedro Felipe de Oliveira Santos; e Venício Glebson Dantas Silva. Mossoró, 18 mai. 2021b, mensagem eletrônica.', 'RAMOS, Janine Vilas Boas Gonçalves. Inteligência artificial no poder judiciário brasileiro: projetos de IA nos tribunais e o sistema de apoio ao processo decisório judicial. São Paulo: Editora Dialética, 2022.', 'RUFINO, Humberto d’Ávila. A informática jurídica e a prestação jurisdicional trabalhista: uma proposta concreta. Florianópolis, 1985. 170 f. Dissertação (Mestrado) - Pós-graduação em Direito, Universidade Federal de Santa Catarina.', 'SALOMÃO, Luís Felipe. (coord.). Tecnologia Aplicada à Gestão dos Conflitos no Âmbito do Poder Judiciário Brasileiro. Rio de Janeiro: FGV, 2020. Disponível em: Disponível em: https://ciapj.fgv. br/sites/ciapj.fgv.br/files/estudos_e_pesquisas_ia_1afase.pdf Acesso em: 08 mai. 2021.\n» https://ciapj.fgv. br/sites/ciapj.fgv.br/files/estudos_e_pesquisas_ia_1afase.pdf', 'SALOMÃO, Luís Felipe. (coord.). Inteligência artificial: tecnologia aplicada à gestão dos conflitos no âmbito do poder judiciário brasileiro. 2. ed. Rio de Janeiro: FGV, 2022. Disponível em: Disponível em: https://conhecimento.fgv.br/sites/default/files/2022-08/publicacoes/relatorio_ia_2fase.pdf Acesso em: 20 jun. 2023.\n» https://conhecimento.fgv.br/sites/default/files/2022-08/publicacoes/relatorio_ia_2fase.pdf', 'SALOMÃO, Luís Felipe (coord.); TAUK, Caroline Somesom et al. Inteligência artificial: tecnologia aplicada à gestão de conflitos no âmbito do Poder Judiciário brasileiro. 3. ed. Rio de Janeiro: FGV, 2023. Disponível em: Disponível em: https://ciapj.fgv.br/sites/ciapj.fgv.br/files/ relatorio_ia_3a_edicao_0.pdf Acesso em: 02 out. 23.\n» https://ciapj.fgv.br/sites/ciapj.fgv.br/files/ relatorio_ia_3a_edicao_0.pdf', 'SCHWAB, Klaus. A quarta revolução industrial. São Paulo: Edipro, 2016.', 'SILVA, Nilton Correia et al. Document type classification for Brazil’s supreme court using a convolutional neural network. In: International Conference on Forensic Computer and Cyber Law, 10., São Paulo, 2018, p. 7-11. Disponível em: Disponível em: http://icofcs.org/2018/ICoFCS-2018-001.pdf Acesso em: 08 nov. 2021.\n» http://icofcs.org/2018/ICoFCS-2018-001.pdf', 'SOUSA, Rosalina F. Martins de; CÂMARA, Maria Amélia Arruda; RODRIGUES, Walter de Macedo. Inteligência artificial no âmbito do poder judiciário: a participação democrática e a transparência algorítmica. In: PINTO, Henrique Alves et al. Inteligência artificial aplicada ao processo de tomada de decisões. Belo Horizonte: D’Plácido, 2020, p. 191-206.', 'STF, CENTRAL DO CIDADÃO. Notificação - sua solicitação (36882 - acesso à informação) foi concluída Destinatária: Cláudia Toledo. Brasília, 20/08/2021, mensagem eletrônica.', 'STF, CENTRAL DO CIDADÃO. Notificação - sua solicitação (88321 - acesso à informação - STI) foi concluída Destinatário: Daniel Pessoa. Brasília, 16/02/2023, mensagem eletrônica.', 'SUSSKIND, Richard. Online courts and the future of justice. Oxford: Oxford University Press, 2019.', 'SUSSKIND, Richard; SUSSKIND, Daniel. O futuro das profissões: como a tecnologia transformará o trabalho dos especialistas humanos. Lisboa: Gradiva, 2019.', 'TENÓRIO, Igor. Direito e cibernética. 3. ed. Rio de Janeiro: Editora Rio, 1975.', 'TJMG. Tribunal de Justiça de Minas Gerais. TJMG utiliza inteligência artificial em julgamento virtual. Notícia no site oficial, Belo Horizonte, 07 nov. 2018. Disponível em: Disponível em: https://www.tjmg.jus.br/portal-tjmg/noticias/tjmg-utiliza-inteligencia-artificial-em-julgamento-virtual.htm Acesso em: 08 nov. 2021.\n» https://www.tjmg.jus.br/portal-tjmg/noticias/tjmg-utiliza-inteligencia-artificial-em-julgamento-virtual.htm', 'TJMG. Tribunal de Justiça de Minas Gerais. Consulta - Fale com o TJMG. Destinatário: Cláudia Toledo. Belo Horizonte, 24 jun. 2020, mensagem eletrônica.', 'TOLEDO, Cláudia. Direito Adquirido e Estado Democrático de Direito. São Paulo: Landy, 2003.', 'TOLEDO, Cláudia. Inteligência Artificial e sua aplicabilidade em decisões judiciais. In: PEIXOTO, F.H. (org.). Inteligência Artificial: Estudos de Inteligência Artificial. Curitiba: Alteridade, 2021, p. 57-90.', 'TOLEDO, Cláudia; ALVES, Michelle. 2021. Inteligência Artificial Aplicada ao Direito. In: SEMINÁRIO DO OBSERVATÓRIO DE PRÁTICAS SOCIOJURÍDICAS, 1., 2021a, UFERSA, Mossoró. Disponível em: Disponível em: https://ppgd.ufersa.edu.br/wp-content/uploads/sites/ 168/2021/05/Lista-de-Trabalhos-Aprovados-nos-GTs-do-ISeminario-de-Pesquisa-do-OPS.pdf Acesso em: 08 nov. 2021.\n» https://ppgd.ufersa.edu.br/wp-content/uploads/sites/ 168/2021/05/Lista-de-Trabalhos-Aprovados-nos-GTs-do-ISeminario-de-Pesquisa-do-OPS.pdf', 'TOLEDO, Cláudia. Solicitação 36882 - acesso à informação. Destinatário: Central do Cidadão do STF. Juiz de Fora, 28 ago. 2021b, mensagem eletrônica.', 'VALENTINI, Rômulo Soares. Julgamento por computadores? As novas possibilidades no século XXI e suas implicações para o futuro do direito e do trabalho dos juristas. Belo Horizonte, 2017. 150 f. Tese (Doutorado) - Programa de Pós-graduação em Direito, Universidade Federal de Minas Gerais.', 'VARELA, Francisco J. Conhecer: as ciências cognitivas: tendências e perspectivas. Lisboa: Instituto Piaget, 1995.']","['Publicação nesta coleção\n19 Jan 2024', 'Data do Fascículo\n2023']","[' CLÁUDIA TOLEDO ', ' DANIEL PESSOA ']","[' Universidade Federal de Juiz de Fora (Juiz de Fora-MG, Brasil) toledo.claudia@direito.ufjf.br', ' Universidade Federal Rural do Semiárido (Mossoró-RN, Brasil) daniel.pessoa@ufersa.edu.br']",http://www.scielo.br/scielo.php?script=sci_arttext&pid=S2359-56392023000100203&lang=pt,2024-11-21 09:59:45.839407,Scielo.org
"Dimensões do uso de tecnologia e Inteligência Artificial (IA) em Recrutamento e Seleção (R&S): benefícios, tendências e resistências","Este estudo investiga as dimensões do uso de dispositivos tecnológicos, entre eles a Inteligência Artificial (IA), em processos de Recrutamento e Seleção (R&S) sob a perspectiva de recrutadores de empresas do setor farmacêutico instaladas no estado de São Paulo. Para isso, foi realizada uma pesquisa qualitativa, por meio de um roteiro semiestruturado, com 12 entrevistados com experiência em R&S antes e depois do advento da tecnologia. Foram observados os benefícios, as tendências e resistências com relação ao uso de tecnologia e IA nos processos de R&S. Como benefício, tem-se o papel da tecnologia e IA na desburocratização da área de Recursos Humanos (RH), de modo a tornar seu foco mais estratégico e consultivo, na medida em que reduz tempo e custo na triagem de currículos e seleção de candidatos. Como tendência, verificou-se que a pandemia trouxe uma quebra de paradigma no uso de tecnologias no processo de R&S, a qual deverá ser utilizada, seja de forma integral ou parcial, em uma maior amplitude de vagas. Dentre as resistências ao seu uso, tem-se o ceticismo acerca da assertividade na seleção do candidato por meio da tecnologia e IA, devido à redução do contato humano. Foram abordadas, ainda, as questões ambíguas acerca das implicações do uso de tecnologia e IA na diversidade dos negócios. Sugestões para futuras pesquisas e limitações da pesquisa também foram apresentadas.","Da Primeira à Terceira Revolução Industrial, ocorridas nos últimos 300 anos, ocorreram mudanças radicais nas sociedades (Corvalán, 2017
). A Quarta Revolução Industrial, em curso no mundo (Schwab, 2020
), diz respeito a uma revolução digital ligada ao avanço de tecnologias inovadoras que mudaram o mundo de forma rápida e radical, de modo que a transformação digital e a Inteligência Artificial (IA) não estão mais vinculadas somente a computadores, robôs e softwares destinados a melhorar a habilidade física do ser humano (Mendonça, Rodrigues, Aragão, & Del Vecchio, 2018
).
No contexto organizacional, também é possível presenciar transformações tecnológicas, na medida em que a velocidade da economia vem ultrapassando fronteiras e demandando processos consistentes que resultam em uma melhor eficiência, em virtude da economia de tempo e maior lucro para as corporações (Mendonça et al., 2018
). O departamento de Recursos Humanos (RH) tem sido, cada vez mais, requisitado a trabalhar em linha com a estratégia organizacional, sendo impactado, diretamente, por estas mudanças, enquanto apoia o desenvolvimento do negócio e da organização em meio a este novo contexto digital (Bensberg, Buscher, & Czarnecki, 2019; Jatobá, 2020). Ainda segundo Jatobá, (2020), a tecnologia que vem envolvendo a área de RH em suas diversas atividades é a IA, cujos processos digitais levam à automatização de variadas tarefas; dentre elas, o Recrutamento & Seleção (R&S). Segundo Farias, Santos e Licciardi (2018
), as metodologias inovadoras no R&S estão determinadas a melhorar o dia a dia nas organizações, contribuindo assim para o seu crescimento. Automatizar os processos de análise dos perfis dos candidatos, com o intuito de identificar os que se adéquam às especificações da vaga, pode trazer uma maior eficiência (Faliagka, Ramantas, Tsakalidis, & Tzimas, 2012).
Após a introdução de tecnologias, a área de RH se tornou mais estratégica, deixou de ser burocrática e operacional e deu significado à IA, tecnologia que busca colaborar com o crescimento das organizações facilitando as formas de trabalho (Mendonça et al., 2018
). Segundo os dados do relatório Panorama RH Brasil 2018 (HR.Rocks, 2018
), que, aliás, engloba empresas do segmento da saúde - contexto no qual esta pesquisa está inserida -, somente 15% das empresas pesquisadas consideram elevada a utilização de tecnologias e 50% consideram estar na média. Um total de 91% dos que responderam à pesquisa consideram o uso da tecnologia uma questão importante para que o RH passe a ser mais estratégico, 51% utilizam algum software no processo de R&S e 59% têm uma página no site para atração de talentos.
Os dados apontam, portanto, para a relevância do tema, mas os estudos acadêmicos ainda são incipientes e escassos, o que justifica um maior aprofundamento sobre o tópico. Com base neste contexto, este trabalho busca responder à seguinte pergunta de pesquisa: Quais as dimensões do uso de dispositivos tecnológicos, entre eles a IA, em processos de R&S de pessoas, sob a ótica do recrutador? Para respondê-la foi realizada uma pesquisa qualitativa, recorrendo a 12 entrevistas semiestruturadas com profissionais de RH do setor farmacêutico de empresas instaladas no estado de São Paulo que ocupam cargos diversos nas organizações em que atuam.
O artigo contribui para a literatura sobre o uso de tecnologia e IA no R&S, na medida em que ressalta a importância do uso dessas ferramentas, especialmente nos contextos em que o fit cultural com a empresa é considerado um critério importante para a escolha do candidato. Outro ponto identificado foi o papel da matriz da empresa na implementação das tecnologias e IA durante os processos de R&S. Além disso, identificou-se que as tecnologias e IA deverão estar mais presentes no cotidiano das empresas, ainda que os entrevistados tenham se mostrado preocupados com o nível de contato humano que deve ser mantido durante os processos de R&S. Por fim, foram verificadas as implicações em termos de diversidade com o uso de tecnologia e IA.
Este artigo está estruturado da seguinte maneira: além desta introdução, apresenta o referencial teórico para abordagem do tópico sobre o uso de tecnologia e IA nos processos de R&S; em seguida, descreve o procedimento metodológico e, depois, resultados e análises; para, posteriormente, expor a conclusão.
Optou-se por abordar o tópico tendo como base as literaturas internacional e nacional separadamente, na medida em que é possível notar diferenças com relação à maturidade da discussão nesses diferentes âmbitos, especialmente com relação ao uso da IA durante o processo de R&S.
A literatura internacional a respeito da tecnologia nos processos de R&S mostra que houve um crescimento exponencial do número de candidatos em busca de emprego utilizando a web, o que acarretou um número grande de ofertas de currículos e um reduzido número de profissionais envolvidos na seleção dos candidatos (Faliagka et al., 2012). Pérez e Falótico (2019
)afirmam que uma boa parte das grandes e médias empresas utiliza a tecnologia nos processos de R&S. Estas tecnologias envolvem recrutamento de candidatos por meio de e-mails, entrevistas, videoconferências, realização de testes pela internet ou por softwares. Malik e Mujtaba (2018
) apresentam a tecnologia do recrutamento eletrônico (E-Recruitment), que consiste em utilizar sites de empresas, jornais on-line, sites de empregos, estações de rádios on-line e entrevistas por Skype ou Viber.
Além dessas tecnologias, as empresas também fazem uso da IA, que, segundo Geetha e Bhanu (2018) compõe-se de um sistema disponibilizado por computador, desenvolvido para processar dados com vistas a prover resultados de forma análoga ao trabalho humano nas empresas, usando a aptidão de aprender, tomar decisões e solucionar problemas. Ela é a ciência de reproduzir a inteligência do homem utilizando computadores. Segundo Barman e Das (2018) esses recursos podem ser acessados via soluções propostas por HR Techs, as quais já são mais de 125 no mundo e usam tecnologias em evolução. Elas são capazes de incorporar cloud computing, métricas, robótica, automação e aplicação em larga escala de IA. Vale ressaltar, no entanto, que essas soluções representam ferramentas, caberá, poranto, à competência humana definir sua eficiência.
Pérez e Falótico (2019
) citam que, de acordo com o Big Data Social, 96% dos recrutadores entendem que os processos de IA aumentam a assertividade e, portanto, reduzem o turnover dos colaboradores e aumentam o alcance a grupos de talentos. Faliagka et al. (2012) afirmam que a IA reduz o custo de contratação, em virtude da redução do tempo em que a vaga fica disponível, bem como a necessidade de contratação de mão de obra para efetivar o processo de seleção (Faliagka et al., 2012).
Não somente a seleção de currículos por meio de IA é um recurso recente, como também houve um avanço no processo de R&S com as redes sociais, entrevistas automatizadas e gravadas em vídeo - as chamadas entrevistas assíncronas (Forman, Glasser, & Jones, 2020) -, jogos direcionados para detectar competências, além de entrevistas por videoconferência, de forma síncrona (Gee, 2017
). Dados mostram uma melhor eficiência do processo de R&S com o recurso à IA na análise de perfil de candidatos em redes sociais (Faliagka et al., 2012). De forma geral, a literatura internacional mostra que a IA permite um processamento de dados mais volumoso e, com isso, a localização do candidato certo para o lugar certo (Collins 2001; Upadhyay & Khandelwal, 2018
). Essa concepção é relevante na medida em que se compreende que, devido às suas competências (Bartlett & Ghoshal, 1997
; Prahalad, & Hamel, 2000
), as pessoas são fonte de vantagem competitiva (Boxall, 1996
; Boxall & Steeneveld, 1999
).
Outro ponto positivo explorado por Upadhyay e Khandelwal (2018
) é o fato de a IA responder à aplicação de um candidato em 24 horas após a sua inscrição. A IA é capaz de prover um feedback relativo às qualificações e às habilidades do candidato, o que o auxilia a se aperfeiçoar e a ter uma experiência positiva. Nesse sentido, os recrutadores dedicam-se a questões mais estratégicas, passando a ser consultores de talentos. Os autores apontam, no entanto, que os sistemas de IA precisam ser programados de forma adequada, para que se evitem vieses inconscientes.
Cabe destacar a importância do tratamento dos dados, porque, conforme colocaram Blommaert, Coenders, e Tubergen (2013
), se os dados não forem inseridos e analisados de forma correta, o resultado também pode ser enviesado. Os autores citam um exemplo ocorrido na Holanda, durante um processo envolvendo candidatos do sexo masculino e feminino, três níveis ocupacionais, cinco setores e dez regiões geográficas. Os resultados mostraram a existência de fortes indícios de que candidatos com nomes árabes foram menos acessados, a despeito do sexo, da escolaridade, da idade, da região ou do setor. Segundo Ahmed (2018), estes preconceitos podem ser encontrados tanto nas descrições de cargos, como na análise de currículos, mas algoritmos podem ser desenvolvidos para ajudar os recrutadores a reconhecer e a retirar os vieses, possibilitando a seleção de uma gama de candidatos.
Como ponto negativo relacionado ao uso de tecnologias e IA nos processos de R&S, Blommaert et al. (2013
) enfatizam que ele pode restringir o atendimento a pessoas que não possuem intimidade com as tecnologias, bem como aos indivíduos que não possuem acesso à internet.
A literatura internacional também chama a atenção para a ocorrência de cybervetting quando se utiliza a internet durante o processo de R&S. O cybervetting é uma forma de favorecer a obtenção de diferentes informações dos candidatos, que podem envolver o aspecto familiar, do dia a dia, hobbies, opiniões e muito mais (Berger, 2015; Backman & Hedenus, 2019
). Segundo Berkelaar e Harrison (2016
), cybervetting é a forma de obtenção de dados on-line cujo objetivo é analisar a adequação de um indivíduo para um papel específico. Os recrutadores avaliam os candidatos tanto com base nas informações das redes sociais, como também pela falta de informações, o que pode ser prejudicial ao candidato, porém, não eliminatório.
Segundo The Reppler Effect (2011
), com base em uma pesquisa realizada com 300 recrutadores, 91% afirmam usar social networking para obter informação sobre potenciais candidatos, ressaltando-se que quase 50% fazem isso assim que recebem o currículo. Outro dado é que 69% dos recrutadores pesquisados já rejeitaram candidatos em razão do que eles postaram nas redes sociais. Outra pesquisa, realizada pela CareerBuilder (2018)
aponta que 70% dos empregadores americanos usam algum tipo de mídia social para pesquisar candidatos durante o processo de seleção, aproximadamente 50% verificam seus empregados atuais em mídias sociais, e quase 35% já repreenderam ou demitiram colaboradores por terem postado conteúdos on-line considerados inadequados. Praticamente metade dos recrutadores afirma que se não encontrar o candidato on-line, há uma menor chance de o chamar para uma entrevista. Segundo Melton, Miller, Jensen, e Shah (2018
), ver que o candidato não é ativo nas redes sociais pode mostrar que, talvez, ele não seja bem conectado com pessoas, o que, apesar de gerar uma imagem de que não possua muita habilidade pessoal, não o desqualifica. Ainda, segundo a pesquisa realizada pela CareerBuilder (2018
), quase 30% mencionam gostar de reunir mais informações por meio das redes sociais antes de ligar para o candidato.
Na literatura internacional, discute-se, ainda, a questão ética relacionada ao cybervetting. Um estudo comparativo realizado no Reino Unido e na Austrália mostra que 60% dos colaboradores defendem que os empregadores não devem investigar informações em redes sociais, mesmo que as configurações de privacidade estejam abertas. Já estudantes universitários canadenses responsabilizam o dono do perfil pelo conteúdo postado; ou seja, se as configurações de privacidade não forem ativadas, é admissível que outros indivíduos acessem suas informações (Backman & Hedenus, 2019
).
A literatura nacional aborda o tópico da tecnologia nos processos de R&S, especialmente da perspectiva das vantagens de seu uso.
Segundo Avelar, Y. M. Silva, e H. L. Saraiva (2021
), em um ambiente competitivo, profissionais de RH que atuam com R&S encontram na tecnologia um poderoso suporte para seu trabalho. Uma das vantagens exploradas por (Cappelli, 2001
) diz respeito ao custo estimado para a contratação de um novo colaborador utilizando a internet, o qual é vinte vezes menor comparativamente aos custos de um processo em que não se utiliza a web. Além disso, nota-se uma grande economia de tempo. Portanto postar vagas on-line, obter currículos digitalizados, buscar perfis em sites na internet são maneiras de redução de custo e de tempo. Lorenz, Oliveira, e J. R. D. Silva (2019
) também concordam que o processo seletivo que envolve tecnologia apresenta como ponto forte o fato de trazer uma maior agilidade, efetividade e assertividade. No entanto, os recursos tecnológicos não devem ser utilizados de forma isolada e deve haver o envolvimento do recrutador. Além disso, ocorre que algumas companhias estão delegando aos gerentes de linha autonomia na contratação de candidatos, sem a interferência da área de RH da empresa. O recrutamento on-line acaba sendo um facilitador, descentralizando, por sua vez, a atuação do responsável pela contratação (Cappelli, 2001).
Ferreira (2020) explora a vantagem sob a perspectiva da redução do trabalho manual efetuado pelos recrutadores, visto que a otimização dos processos nas fases de triagem possibilita alcançar um número maior de candidatos e despender menos esforços e menos tempo nas etapas seguintes do processo. Diante do exposto, é possível considerar que há uma facilitação dos processos, tornando o RH mais ágil (Mendonça, Rodrigues, Aragão, & Del Vecchio, 2017) e, com isso, mais estratégico (Lima & Rabelo, 2018
).
Costa (2018) afirma que o ponto alto do processo seletivo digital é proporcionar tanto uma maior amplitude na busca por candidatos, sem restrição de fronteiras, como também uma maior possibilidade de acesso à diversidade. Por meio das mídias sociais, é possível atingir muitas pessoas com uma única publicação de uma vaga disponível e, ao mesmo tempo, analisar os candidatos interessados pelas vagas - isso tudo antes de estabelecer um contato pessoal (Pondé, 2019). Costa (2018) explica que as vagas operacionais possibilitam a inclusão de processos completamente on-line, com aplicação de testes de personalidade, comportamentais e de conhecimento técnico. Já para cargos mais seniores e complexos, as fases on-line serão eliminatórias, mas com processos presenciais. Os cargos de alta gerência e C-Level não dispõem de procedimentos on-line.
Gaspar e Schwartz (2017) afirmam que a internet passou a ser uma ferramenta de suporte que permitiu a evolução drástica do processo de R&S, uma vez que incluiu a utilização de simulações e jogos on-line, sistemas de simulação de software e programação para avaliar conhecimentos práticos de candidatos, ferramentas de análise de voz, dicção e gramática por telefone, além da identificação do rastro social on-line por meio de redes sociais e entrevistas on-line. Segundo Avelar et al. (2021
), avanços tecnológicos como ferramentas de IA, machine learning, visão computacional, blockchain, realidade virtual, entre outras, estão revolucionando as empresas e mercados por meio da digitalização de processos. A literatura não aborda de forma ampla o uso de IA nos processos de R&S, mas Ferreira (2020) afirma que este é um recurso que proporciona uma maior transparência nos processos de recrutamento, evitando vieses no momento da triagem e seleção, e melhora o entendimento do candidato no que tange ao processo e seu objetivo. O processo tende a ser mais imparcial e mais justo, oferecendo, assim, a mesma oportunidade para todos os concorrentes da posição.
Ainda sobre o uso de IA nos processos de R&S, por meio de um estudo sobre as HR Techs brasileiras, Avelar et al. (2021
) identificaram que essa tecnologia permite, além da redução de tempo e custo, a centralização de informações (gestão de dados) e o cruzamento de dados. Essas facilidades proporcionam a melhoria de processos e facilidade na divulgação e atração de candidatos aderentes à vaga. Vale lembrar que, segundo Cepellos (2019
), as HR Techs são startups que usam a tecnologia a fim de melhorar práticas, desde R&S até avaliações de desempenho. Avelar et al. (2021)
localizaram quatro HR Techs (em 2019) com soluções para R&S. Segundo Cepellos (2019)
, as HR Techs promovem um serviço capaz de agilizar operações burocráticas e rotineiras, contribuem para uma melhor experiência do candidato e usufruem dos dados para indicar profissionais com o melhor desempenho, facilitando a busca por novos talentos com perfis similares. Avelar et al. (2021)
identificaram que as dificuldades na utilização dos serviços de HR Techs estavam atreladas à adequação da solução às expectativas criadas, especialmente aquelas relacionadas a um recrutamento mais assertivo tanto para diminuir despesas com turnover, quanto em relação à falta de customização de testes.
J. Silva e Barreto (2019
) abordam a presença de tecnologias com IA durante o processo de R&S por meio das redes sociais, tanto aquelas criadas para o ambiente corporativo, como o LinkedIn, quanto aquelas que não são voltadas especificamente para esta finalidade, como o Facebook (utilizado para avaliar a reputação de uma empresa e envolver pessoas com uma marca), Twitter (usado para anunciar vagas via hashtags visando alcançar grupos específicos) e Whatsapp (usado para divulgar vagas e estabelecer uma rede de contatos).
Com relação à literatura nacional sobre a prática do cybervetting, destaca-se o estudo de Biberg (2019), o qual aponta que as mídias sociais se mostram significativamente importantes na interação e avaliação dos candidatos em empresas brasileiras pesquisadas em seu estudo. De acordo com a autora, no contexto de R&S, por meio das redes sociais, os recrutadores têm a possibilidade de verificar os comportamentos dos candidatos fora do ambiente de trabalho, o que pode ser prejudicial ao processo, já que indivíduos podem agir de formas distintas no trabalho e na vida pessoal.
Este estudo buscou responder a seguinte pergunta de pesquisa: Quais as dimensões do uso de dispositivos tecnológicos, entre eles a IA, em processos de R&S de pessoas, sob a ótica do recrutador? Para respondê-la, efetuou-se uma pesquisa qualitativa, com a realização de 12 entrevistas semiestruturadas com profissionais de RH do setor farmacêutico de empresas instaladas no estado de São Paulo que ocupam cargos diversos nas organizações em que atuam, porém, com mais de 5 anos atuando em R&S.
De acordo com Creswell (2007), a pesquisa qualitativa é utilizada quando um problema ou questão precisa ser explorado. Fazer a exploração passa por estudar um grupo ou população, identificar variáveis que podem ser medidas. Godoy (1995
) comenta que, quando o estudo tem perfil descritivo e o que se objetiva é o entendimento do fenômeno de forma ampla, é possível que uma abordagem qualitativa seja mais adequada. Dessa forma, com base na descrição acima, a metodologia de pesquisa qualitativa descritiva por meio de entrevistas semiestruturadas foi a mais adequada para responder à pergunta de pesquisa.
Segundo Gil (1987), entrevista pode ser definida como a técnica em que o entrevistador se apresenta ao entrevistado e lhe faz perguntas com o intuito de obter informações que interessam ao processo de entrevista. Ou seja, um lado traz os dados e o outro obtém as informações. Ainda, segundo o autor, a entrevista é uma técnica de obtenção de dados muito usada no contexto das ciências sociais. Assim, como forma de coleta de dados, a entrevista é muito adequada para trazer informações em relação ao que as pessoas sabem, acreditam, esperam, sentem, querem, objetivam, realizam ou realizaram. A adequação deste método está relacionada ao fato de que o objetivo é identificar, no problema de pesquisa deste estudo, quais são as dimensões acerca do uso da tecnologia e IA durante os processos de R&S.
A escolha do setor farmacêutico brasileiro se deu por sua grande representatividade no mercado global, qual seja: de aproximadamente 2% a 8o em faturamento no ranking das 20 principais economias (Sindusfarma, 2020). Segundo os dados do Anuário Estatístico do Mercado Farmacêutico da Secretaria Executiva da Câmara de Regulação do Mercado de Medicamentos, da Agência Nacional de Vigilância Sanitária (Anvisa), em 2019 o mercado farmacêutico alcançou o valor de R$ 74,6 bilhões em vendas (Verdélio, 2021
). O estado de São Paulo apresenta a maior concentração de indústrias farmacêuticas, a qual corresponde a 56,25% do total de empresas do setor e 76,85% do faturamento do Brasil (Verdélio, 2021
). Esta representatividade indica uma importância significativa em sua competitividade e, por sua vez, a necessidade de atração e retenção de talentos, já que a vantagem competitiva está cada vez mais focada nos profissionais e em suas competências (Bartlett & Ghoshal, 1997
).
Foram considerados, para as entrevistas, profissionais de ambos os sexos, maiores de 18 anos, que tinham envolvimento no processo de R&S por meio de dispositivos tecnológicos (IA, softwares, internet, videoconferências, redes sociais), com mais de 5 anos de experiência em R&S, independentemente do cargo que ocupavam, mas que também tinham conhecimento do processo de R&S tradicional, sem o envolvimento de dispositivos tecnológicos. A fim de garantir que os entrevistados tivessem conhecimento acerca do tópico que seria explorado ao longo das entrevistas, foram questionados previamente sobre sua capacidade para uma possível contribuição na pesquisa. A ideia de envolver recrutadores que tinham experiência com recrutamento tradicional e por meio de dispositivos tecnológicos tem como objetivo trazer informações comparativas entre as duas formas de processo de seleção. Foi possível chegar até estes entrevistados por intermédio da rede de contatos de um dos autores do trabalho e, a partir daí, aplicar a técnica de snowball. Considerou-se como critério de encerramento das entrevistas o grau de saturação e repetição dos conteúdos apresentados pelos participantes. A saturação teórica pode ser entendida como a fase da análise de dados qualitativos na qual o pesquisador, em razão da amostragem e análise de dados, entende que não ocorrem novas situações, todas as ideias da teoria estão robustas e nenhuma informação adicional é necessária (Given, 2008; Ribeiro, Souza, & Lobão, 2018).
As entrevistas ocorreram entre os dias 20/04/2021 e 18/06/2021, período situado no segundo ano da pandemia da COVID-19, o que ocasionou o desenvolvimento das entrevistas por videoconferência com a ferramenta Zoom. As entrevistas tiveram duração média de 1 hora, foram gravadas e transcritas (Bardin, 1977).
O roteiro de entrevista utilizado contemplou 25 questões abertas que tinham como intuito investigar os objetivos da empresa e da área de RH, como se dá o processo de R&S na empresa, quais as características das vagas disponíveis, as mudanças nos processos seletivos nos últimos anos, como a IA é utilizada nos processos de R&S, quais as vantagens e desvantagens das tecnologias nos processos de R&S para a empresa e para o candidato, quais seus impactos, qual a motivação para o uso de IA nas empresas, a influência da pandemia da COVID-19 na implementação de tecnologia nos processos de R&S, entre outros aspectos relacionados ao tópico. A fim de preservar o anonimato dos respondentes, foram utilizados pseudônimos, conforme é possível visualizar no Quadro 1, o qual apresenta a demografia dos entrevistados.


As entrevistas foram realizadas pelo primeiro autor do artigo, o qual também foi o responsável pelo contato inicial e seleção dos respondentes. Com os dados coletados, iniciou-se o processo de análise de conteúdo (Bardin, 1977) por meio da análise de significados, dando origem, portanto, a uma análise temática. Utilizou-se a ferramenta AtlasTi, versão web, para codificação das entrevistas. O foco da análise teve como base os 47 principais códigos, os quais são mais diretamente ligados às questões e aos objetivos propostos inicialmente. Após a codificação, foi realizada a análise para encontrar as categorias intermediárias, as quais surgiram após agrupamento dos principais códigos listados. Em seguida à análise e ao agrupamento de cada código, houve o desenvolvimento e análise do conceito norteador. A partir daí, surgiram 8 categorias intermediárias. Após análise, agrupamento e desenvolvimento de um novo conceito norteador, tais categorias deram origem a 4 categoriais finais: (a) benefícios da tecnologia durante R&S para empresa e candidato; (b) tendências e resistências sobre o uso de tecnologia durante R&S; (c) benefícios da IA durante R&S para empresa e candidato e (d) tendências e resistências sobre o uso de IA durante R&S. É importante ressaltar que todas as categorias emergiram da análise de dados, a qual será apresentada na próxima seção.
Nesta seção, será feita a discussão dos resultados analisados com base no referencial teórico. A sequência da discussão seguirá os temas que emergiram com a análise temática.
A tecnologia, como entrevista por vídeo, proporciona facilidade para o candidato e para o profissional responsável pelo processo de R&S. Como vantagem para o candidato, identificou-se que ele não precisa se deslocar até o local da entrevista, e como vantagem para o recrutador, o ganho de tempo por conseguir marcar entrevistas sequenciais. Este ganho de tempo é algo que Belmont, Pereira, Houzer e Caldeira (2015) evidenciam destacando a tecnologia como fator determinante no processo de R&S para agregar este benefício. A entrevista por vídeo traz, ainda, o benefício de redução de custos à empresa e ao candidato, conforme apontado, também, pela literatura (Cappelli, 2001
). Na perspectiva do candidato, destaca-se o benefício de poupar recursos financeiros, já que não precisa se deslocar até o local da entrevista, economizando em custos de transporte e de refeição.
O processo seletivo? Eu acho que é muito mais fácil na otimização de agenda mesmo, principalmente com o candidato. Porque antes o candidato tinha que [...] Se é uma entrevista de 1 hora, no mínimo, ele precisava de 30 minutos antes e 30 minutos depois, e se a gente tá falando de nível profissional, essa pessoa eventualmente trabalha, muitos deles trabalham, então, para o candidato é muito mais simples fazer o processo on-line, não tem tempo de deslocamento. E pra gente não tem aquelas dinâmicas de ter sala disponível (Noemi).
Segundo os entrevistados, a tecnologia no processo de R&S é vista como uma forma de desburocratizar e ajudar o RH a ser mais ágil (Belmont et al., 2015) na contratação de talentos, visto que diminui a carga operacional. Isso permite que o RH seja cada vez mais estratégico. Tais achados coadunam-se com o que a literatura evidencia (Farias, Santos, & Licciardi, 2018
; Mendonça et al., 2017).
Eu trago no contexto de diminuição de carga operacional. Eu acho que se a gente tiver um sistema inteligente, fácil de usar, de manusear, sem muita burocracia, acho que você salva tempo do recrutador, você profissionaliza o processo e você tem um impacto muito melhor no mercado - tanto de marca quanto de experiência do candidato; minimiza possibilidade de erros e você cuida da experiência do candidato também ter uma interface boa. Então tudo isso ajuda muito (Noemi).
Com relação à experiência do candidato e a possíveis vantagens para os participantes, os entrevistados apontam que, para aquele que foi selecionado, a experiência do R&S com uso de tecnologia pode ter sido benéfica, mas, para os candidatos que não foram selecionados, pode ter havido frustração. É importante lembrar que as literaturas nacional e internacional pouco discutem a perspectiva do candidato, ainda que esta seja uma parte importante do processo.
Candidatos selecionados talvez tenham uma experiência mais positiva porque vão falar “Nossa, o processo levou um mês e antigamente levava três”. Então, essa pessoa fica com uma experiência mais positiva. Em contrapartida, eu tenho a sensação de que as outras pessoas ficam mais frustradas, do lado do candidato (Joana).
Durante as entrevistas, foi possível observar que a tecnologia é frequentemente utilizada para o preenchimento de todos os cargos. Porém à medida que o cargo sobe na hierarquia organizacional, o uso da tecnologia torna-se restrito e mais contato humano é estabelecido durante o processo de R&S.
Eu sei que se utiliza vídeo para posições até nível de analista e, depois disso, já se começa a fazer entrevistas face-to-face nesse momento até Talent Acquisition (Joana).
No entanto, este estudo identificou que, na pandemia da COVID-19, dentro do contexto da tecnologia, a entrevista por vídeo passou a estar presente em praticamente todos os cargos, com indícios de que este processo passará a ser amplamente utilizado. Os entrevistados apontam que antes havia preconceito por grande parte dos profissionais com relação às entrevistas via videoconferência, devido à falta tanto de contato olho no olho quanto da linguagem corporal do candidato. Entretanto a relevância que as entrevistas virtuais ganharam na pandemia quebrou o paradigma de muitos recrutadores, levando inclusive à menção de que quase 100% do processo pós-pandemia será virtual, restando o presencial apenas à última etapa, bem como ao onbording. Outros acreditam em um modelo híbrido, conforme é possível depreender da fala de Bárbara:
A probabilidade de que ele veio para ficar é grande. O processo seletivo remoto não perde em qualidade, em riqueza de detalhes ou informações dos candidatos. Pelo contrário, eu consigo estar em SP e fazer as entrevistas de outra localidade pensando em força de vendas ou candidato que está viajando, enfim. Nós conseguimos adequar a necessidade tanto da companhia quanto do candidato. Te dizer que veio 100% para ficar, acredito que é muito precoce, mas que podemos adotar um modelo híbrido é fato (Bárbara).
Não obstante o interesse pela implementação da tecnologia para facilitar o processo de R&S, há uma grande preocupação com a humanização desse processo por parte de todos os entrevistados, o que pode ser entendido como uma resistência ao seu uso de forma mais ampla. No entanto, possuir tecnologia nos processos seletivos não significa abandonar o contato humano, o qual pode se dar por meio de uma ligação telefônica ou de vídeo para explicar como serão as etapas do processo, mesmo que estas sejam automatizadas.
Mas eu acho que, num processo seletivo, o fator humano tem que existir. Óbvio, você pode colocar uma assistente virtual para fazer a entrevista, mas eu acho que, no Brasil, essa questão do olho a olho, essa questão do acolhimento, da humanização do processo, ele ainda é muito importante (Noemi).
Nota-se, ainda, que a questão do uso de tecnologia pode ser permeada pela questão cultural, a qual não foi abordada nas literaturas nacional e internacional, o que torna importante, portanto, considerá-la como um fator que pode impactar na adoção ou não de tecnologia no R&S.
Ao longo das entrevistas, foram abordados os benefícios específicos das tecnologias com IA durante o processo de R&S. A triagem de candidatos é o momento em que, de forma unânime, os entrevistados entendem ser importante a implementação da IA, pois o número de candidatos nesta fase é muito grande. Com o recurso à IA, é possível utilizar critérios que facilitam a seleção de candidatos para uma próxima fase.
Quando a gente posta essa posição, a gente coloca pre-screening questions. Então, quando eu vou alinhar com o hiring manager, eu vou falar com ele: “Olha, o que é o mandatório?”. Um exemplo: “Não posso te apresentar uma pessoa se ela não falar chinês, porque se não falar chinês não adianta, pode ser o Papa, mas não vai ser aceita nessa sua vaga. Então você vai lá e a gente coloca: ‘Você fala chinês?’ E tem o “sim” e o “não”, se a pessoa fala “não”, ela já não tem, né? Então a gente faz essas pre-screening questions e tem o próprio currículo da pessoa. E o cérebro do nosso sistema vai classificar essas pessoas por A, B, C, D [...] chama HiredScore (Joana).
No momento da triagem, além de agilidade, a IA proporciona transparência aos candidatos como uma das vantagens do processo, pois todos eles são analisados, o que, para a empresa, traz também um senso de justiça. Nessa mesma linha, Ferreira (2020) aponta que a IA evita vieses e erros nesta etapa do processo.
Além disso, eu consigo garantir algo que eu acho muito importante para um processo seletivo, que é o senso de justiça: as pessoas que aplicaram foram avaliadas, passaram por um filtro da ferramenta e que me deu o mais aderente por essa primeira etapa que é o currículo. […] Garantir que as pessoas que têm interesse na empresa sejam avaliadas igualmente (Haroldo).
Outro achado refere-se ao uso, especificamente, do LinkedIn. Ficou evidente que todos os entrevistados incluem essa rede social como recurso fundamental no R&S passivo ou ativo. Passivo, quando postam as vagas, e ativo, na busca de talentos, quando estes não são encontrados via encaminhamento de currículo nas postagens de vagas. A busca de talentos de forma ativa se dá por meio de filtros e palavras-chave, o que se mostra eficaz, na visão dos entrevistados.
Nós utilizamos o LinkedIn para a divulgação das vagas e para a busca ativa, hunting mesmo de candidatos (Bárbara).
Os entrevistados também comentaram sobre a importância do LinkedIn Recruiter, o qual permite o uso de filtros mais precisos de forma rápida e eficiente. No entanto, nem todas as empresas disponibilizam a ferramenta a ponto de, em alguns casos, revezar a licença entre os países, devido a custo versus necessidade do momento. Já outros usam seu perfil pessoal para a busca, recurso considerado não tão eficiente. Interessante notar que, segundo Pondé (2019), os candidatos mais jovens, acima dos 18 anos e abaixo dos 40 anos, à procura de emprego, utilizam com maior frequência o Facebook (97,78%); em seguida, o Instagram (93,33%); em terceiro lugar, o LinkedIn (84,44%), na contramão do que foi citado em nossa pesquisa: todos os recrutadores utilizam o LinkedIn como fonte de busca de talentos. Poucos citaram as outras redes sociais.
Os entrevistados destacaram, ainda, a importância do uso de IA em situações em que se faz importante identificar o fit cultural do candidato com a empresa, uma vez que ela permite incluir a cultura da empresa como um critério de acordo com a calibragem feita com os colaboradores atuais.
O sistema da Gupy tem a parte de cultura, o fit cultural que ele faz - isso é para 100% dos candidatos externos. A gente tem o perfil da Companhia [...] No final do ano passado e início desse ano, a gente fez uma amostra com mais de 500 colaboradores indicados em performance, enfim, como se fosse o desenho da companhia para chegarmos no desenho desse fit cultural e fazer essa análise junto com o mercado também. Então, quando o candidato preenche o cadastro dele, ele já responde esse fit cultural e aí só cruzamos para ver a aderência (Haroldo).
Outro ponto discutido pelos entrevistados está relacionado à flexibilidade e conveniência das videoconferências assíncronas com IA, já que os candidatos podem gravar suas entrevistas quando julgarem mais apropriado, independentemente da agenda dos recrutadores. Pode-se dizer, portanto, que o recurso à IA proporciona a candidato e empresa maior autonomia. Além disso, essa ferramenta possibilita a comparação por pergunta realizada, em vez de comparação entre candidatos.
Ai, a gente, [o candidato] vai fazer na hora que ele se sentir melhor! [...] A gente usa o HireVue, é uma ferramenta global. Eu indico as perguntas que eu quero fazer e aí a pessoa recebe um link e ela está sendo gravada. Ela recebe a primeira pergunta e responde, depois a segunda e ela responde. E depois eu recebo essas gravações e posso avaliar. E eu posso avaliar como cada um respondeu cada pergunta (Tatiana).
Com a realização das entrevistas, foi possível identificar que a IA, quando é utilizada para facilitar a triagem dos currículos e a realização de testes psicológicos e comportamentais, mostra-se mais presente em processos que envolvem cargos operacionais (Costa, 2018). O fato de a IA ser mais utilizada para essas posições está diretamente ligado ao volume de vagas e número de currículos recebidos (Faliagka et al., 2012), o que proporciona maior ganho de tempo e, em paralelo, não exige um volume grande de profissionais para operacionalizar a triagem, em linha com Mendonça et al. (2017), já que automatizar traz velocidade e facilita processos, tornando o RH mais ágil (Lima & Rabelo, 2018
) e estratégico.
Porém, com base nos dados, foi possível observar que, quando se trata da rede social LinkedIn, seu uso permeia todos os cargos, dos mais operacionais aos mais estratégicos, na busca ativa e mapeamento de talentos (Biberg, 2019). De acordo com os entrevistados, a busca ativa no LinkedIn gera um contato com o candidato, que p ode ser via telefone, e-mail ou mensagem de WhatsApp, o que promove uma humanização do processo. Esta busca ativa tem como objetivo encontrar o perfil adequado, mas não envolve a pesquisa do comportamento do candidato em nenhuma das redes sociais (Backman & Hedenus, 2019
).
Então, no filtro do Recruiter, a gente vai colocando o cargo, a gente escreve o cargo, nível de inglês, se tiver, palavras-chave, as empresas-alvo ou o setor alvo, a gente vai incluindo mesmo para fazer um mapeamento quando precisa. [...] Então é bem legal esse recurso do LinkedIn, ele traz um relatório bem completo a partir dos pré-requisitos que você coloca [...] Então, por exemplo, eu sou a recrutadora, mas normalmente eu tenho um sourcer que me ajuda na triagem do currículo, nesse mapeamento ativo, na abordagem com o candidato por telefone (Noemi).
A diversidade também foi um tópico presente em todas as entrevistas e que vem ganhando relevância nas empresas, sendo um indicador-chave de performance ligado à contratação. Inclusive, os entrevistados chamam atenção para o cuidado com a implementação do filtro no sistema de IA, de modo a evitar que pessoas pertencentes a grupos minoritários fiquem fora do processo seletivo. O ponto da diversidade é tão relevante que empresas adquirem ferramentas, como o Textio (Ahmed, 2018; Albert, 2019
), que possibilitam desenvolver linguagem neutra na descrição dos anúncios, sendo esta uma forma de dirimir os preconceitos citados por Institute for Employment Studies (2019)
, que passam pela programação realizada por um ser humano, o que pode impor seus vieses.
O cybervetting, outro ponto trazido pelos entrevistados, embora seja apontado pela literatura como prática comum no processo de R&S (Biberg, 2019), não é aprovado pelos profissionais entrevistados, a ponto de classificarem seu uso como antiético. Eles acreditam que inspecionar a vida do candidato por meio das redes sociais não agrega valor ao processo de R&S.
Os entrevistados não esboçam preocupação com o advento da IA como forma de se apropriar da sua mão de obra, pois entendem que estes recursos podem ajudar (Rab-Kettler & Lehnervp, 2019
) a tornar o recrutador mais eficiente ao ter um papel mais consultivo do que operacional, contexto em que, aliás, o hiring manager passa a gerir o processo de R&S (Cappelli, 2001
). Este ponto se apresenta em linha com Upadhyay e Khandelwal (2018
), que comentam que, com a IA sendo responsável pelas tarefas repetitivas, os recrutadores passam a colocar o foco em questões mais estratégicas.
O LinkedIn tá vindo para me ajudar como recrutadora e não para tirar o trabalho do recrutador [...] Eu acho que a inteligência artificial tá para somar, melhorar o trabalho, a eficiência, eficácia desse recrutador e a vida do recrutador mesmo - pensando em como ele gasta esse tempo (Joana).
Um ponto mencionado por todos os entrevistados é a necessidade de rápido preenchimento das posições, o time to fill, um importante indicador-chave de desempenho, que influencia a triagem dos candidatos para posições simples ou complexas, liberando o profissional de R&S do foco operacional para investir seu tempo em um foco mais estratégico.
Apesar da tendência em se utilizar, cada vez mais, a tecnologia nos processos de R&S, os entrevistados relataram resistências à adoção deste recurso. Vale ressaltar, no entanto, que as tecnologias, se mostraram mais atreladas à implementação do sistema nas empresas multinacionais, já que é difícil implantar uma ferramenta nova exclusivamente em uma única filial. É preciso que haja o entendimento na matriz quanto à necessidade de outras filiais no mundo para que esta implementação ocorra. Geralmente a implementação de novos sistemas é top down, vindo da matriz para as filiais.
A (empresa) é muito engessada, então, provavelmente, eu teria muitas dificuldades, porque eu teria que mostrar primeiro para a área de TI da empresa que essa ferramenta é confiável, que não viola [...] Principalmente porque há um tempo atrás um hacker entrou na nossa rede. Então, as coisas ficaram muito mais difíceis... de contratar sistemas locais (Renata).
Além disso, os entrevistados relataram que o processo de R&S pode prejudicar determinados candidatos que não são localizados pelos algoritmos por não dominarem os recursos tecnológicos. Nesse caso, profissionais acabam ficando de fora do mercado de trabalho por um determinado período e sequer podem explicar os motivos, já que não foram selecionados pela ferramenta (Biberg, 2019; Costa, 2018). Logo, os algoritmos podem acabar enviesando a seleção dos candidatos, visto que reforça a escolha de candidatos homogêneos, isto é, com as mesmas características. Outro ponto é que a IA acaba exigindo que os candidatos tenham conhecimento da tecnologia e utilizem palavras-chave que serão capturadas pelos algoritmos, demandando destes, portanto, uma “esperteza tecnológica”.
Mas acho que você reforça certos vieses de rotulagem: você vai ter sempre o mesmo tipo de perfil sendo aprovado e quando você treina essa IA e mostra o que você começa a contratar, você replica aquele modelo. Então você vai ter gente que começa a ficar fora desse algoritmo sem você ter o controle disso, porque essa inteligência está aprendendo com algo que está sendo reforçado, né? […] Se você tem uma IA que está vendo certas características que esse candidato não tem, ele não vai ser considerado nunca, né? Se você não tem alguém que minimamente sabe que palavras-chave são usadas nesses algoritmos, que não tem talvez uma esperteza tecnológica, essa pessoa pode perder muitas chances de emprego (Alexandra).
Nota-se, portanto, uma implicação em termos de diversidade quando se utiliza a IA, uma vez que esta pode acabar excluindo determinados perfis de candidatos. Os entrevistados também apresentaram resistências associadas à falta de confiança de que a IA seja capaz de selecionar a pessoa certa.
Não sei se a gente vai trazer as pessoas certas, às vezes pode perder algum talento, não sei. E, quando você tem o olho humano para um pool de currículos, é muito melhor do que confiar nessas tecnologias [...]. Você acaba que tem algumas pessoas que vendem bem o currículo e outras nem tanto, né? E, às vezes, essas que nem tanto, não têm um currículo mega elaborado com palavras-chave. Talvez a gente pode perder a oportunidade de conhecer esse tipo de pessoa, sabe? (Gabriela).
Este trabalho teve como objetivo avaliar as dimensões do uso de dispositivos de tecnologias, entre eles, a IA, sobre processos de R&S, da perspectiva de recrutadores de empresas do setor farmacêutico instaladas no Estado de São Paulo. Esta pesquisa teve como resultado alguns pontos semelhantes aos achados de outros pesquisadores, como a vantagem do uso das tecnologias e de IA durante o processo de triagem de currículos (Ferreira, 2020, Pondé, 2019), ganho de tempo (Belmont et al., 2015) e redução de custo (Cappelli, 2001
). Notou-se também a possibilidade de o RH se tornar mais estratégico com o uso de tecnologias e IA, pois menos tempo será dedicado aos processos de R&S (Lima & Rabelo, 2018
).
É possível considerar que este estudo traz algumas contribuições práticas e teóricas para o campo de Gestão de Pessoas quando se trata do uso de tecnologias e IA nos processos de R&S, devido aos achados que ainda não tinham sido abordados por outros pesquisadores. Uma das contribuições teóricas encontra-se na identificação da importância da matriz da empresa para a implementação das tecnologias e de IA durante os processos de R&S. Com base nos dados foi possível verificar que, quando a empresa é multinacional, a adoção desses ferramentais é impactada. Portanto a falta de autonomia, nesses casos, prejudica a possibilidade de uso desses instrumentos pelas organizações, apesar dos indicativos de vantagens e benefícios. Este ponto permite uma melhor apreensão dos fatores que influenciam a adoção desses recursos nas empresas.
Outra contribuição teórica identificada diz respeito ao uso intensificado de tecnologias e IA nos processos de R&S durante a pandemia da COVID-19, o que demonstra uma tendência na área. Diferentemente do achado de Costa (2018), este estudo identificou que a entrevista por vídeo foi utilizada nos processos de R&S em praticamente todos os cargos, com indícios de que passará a ser amplamente utilizada, exceto em uma última etapa do processo, para cargos mais elevados. Entretanto, apesar desta tendência, todos os entrevistados mostraram-se preocupados com a humanização nos processos de R&S. Notou-se a influência da cultura do país na adoção de tecnologia e IA no processo de R&S, uma vez que se percebeu a importância do contato humano para os brasileiros. Nesse sentido, uma das resistências está atrelada à crença de que esses recursos podem distanciar os recrutadores dos candidatos e comprometer a assertividade durante a seleção. Entende-se, então, que a cultura do país pode impactar no grau de adoção de tecnologia e IA nos processos de R&S, aspecto que ainda não havia sido considerado pela literatura nacional e internacional.
Outra contribuição teórica, a qual consideramos a mais significativa deste estudo, está relacionada ao tema da diversidade, pouco discutido na literatura internacional e nacional. De acordo com os entrevistados, a tecnologia e a IA apresentam questões ambíguas com relação à diversidade. Ao longo das entrevistas, foi possível verificar que a tecnologia e, em especial, a IA podem prejudicar a seleção de candidatos que fazem parte de grupos minoritários e apresentam pouca representatividade nas empresas. Isso pode ocorrer, pois,s há o risco de os algoritmos enviesarem a seleção dos candidatos, já que reforçam a escolha de indivíduos com as mesmas características. Eles afirmam que os algoritmos podem selecionar pessoas similares àquelas que já foram identificadas na organização como apropriadas, já que possuem fit cultural e competências que levam a um bom desempenho organizacional. A empresa torna-se, então, cada vez mais homogênea. Esse é um fator preocupante se considerarmos o contexto das organizações brasileiras, as quais, de forma geral, valorizam a diversidade nos discursos, mas não nas práticas empresariais (L. A. S. Saraiva & Irigaray, 2011
).
Por um lado, alguns entrevistados afirmam que se deve ter uma atenção quanto à implementação dos filtros utilizados no sistema de IA para que ele não seja excludente e reproduza os preconceitos sociais. Nota-se, então, que, a depender da forma como se dá o uso desses recursos, a diversidade pode ficar ainda mais comprometida. Por outro lado, os entrevistados comentaram que também é possível utilizar tecnologias a favor da minimização de vieses, por exemplo, com a utilização de sistemas de linguagem neutra, que buscam atrair candidatos de todos os gêneros. Nesse caso, deve-se ter atenção à forma como esses recursos são utilizados, considerando a dimensão da diversidade nos negócios.
Outro ponto levantado pelos entrevistados trata-se da necessidade, cada vez maior, do uso de recursos tecnológicos por parte dos candidatos para que possam participar do processo seletivo. Este uso, no entanto, deve ser permeado pelo que os entrevistados chamam de “esperteza tecnológica”, ou seja, os candidatos devem ter uma atitude estratégica na escolha das palavras-chave a serem utilizadas em currículos e entrevistas para que sejam localizados pelos algoritmos e possam prosseguir no processo de seleção. Logo, não basta ter acesso às tecnologias, mas compreender como usá-las estrategicamente, conhecimento que não é amplamente divulgado. Esse aspecto também pode ser considerado tanto uma contribuição teórica, na medida em que ainda não havia sido abordado em outros estudos, quanto uma contribuição prática direcionada aos candidatos, pois, exerce a função de alerta às pessoas que desejam se inserir no mercado de trabalho.
Além do uso inadequado da tecnologia pelos candidatos, outro fator que pode prejudicar um resultado bem-sucedido no processo seletivo é o desprovimento de acesso a recursos tecnológicos por parte dessas pessoas, impedindo-as de participarem dos processos de seleção. Esse fator é ainda mais relevante se considerarmos a realidade brasileira, em que a exclusão digital é um aspecto que pode agravar o acesso de pessoas em situação de vulnerabilidade social ao mundo do trabalho. Para se ter uma ideia, de acordo com uma pesquisa realizada pela PwC e Instituto Locomotiva (2022
), há, no Brasil, 49,4 milhões de brasileiros plenamente conectados, os quais, predominantemente, pertencem às classes A e B, são brancos e escolarizados; 44,8 milhões parcialmente conectados, os quais, predominantemente, pertencem às classes C, D e E, são negros e menos escolarizados; 41,8 milhões de brasileiros subconectados, os quais, predominantemente, pertencem às classes D e E, são negros e menos escolarizados; e 33,9 milhões de brasileiros que são predominantemente das classes C, D e E, idosos e não alfabetizados. Nota-se, portanto, uma “exclusão invisível”, na medida em que o candidato, ainda que busque o acesso à vaga por outros meios, sequer é considerado, pois, a priori, já está fora do processo de seleção. Desta perspectiva, é possível dizer que o uso de tecnologia e IA podem contribuir para um aumento da desigualdade social, ainda que as empresas busquem usar os filtros que contemplem a seleção de candidatos diversos. Haverá sempre uma parcela que será desconsiderada no processo de seleção. Outro agravante é o fato de que, segundo os entrevistados, tecnologias e IA estão mais presentes no processo de R&S de vagas operacionais, as quais são, comumente, ocupadas por pessoas de classes sociais mais baixas.
Este estudo traz, ainda, outra contribuição teórica, qual seja: apesar de a literatura demonstrar que recrutadores fazem uso do cybervetting nos processos de R&S (Biberg, 2019), nesta pesquisa, os entrevistados declaram não fazer uso desta prática, classificando-a, inclusive, como antiética. É possível supor que o fato de a investigação se concentrar no setor farmacêutico tenha impactado neste resultado, na medida em que o segmento é altamente regulamentado, com procedimentos de compliance bastante rigorosos.
Uma contribuição prática está relacionada ao destaque dado à rede social LinkedIn durante o processo ativo ou passivo de R&S. Por meio desta ferramenta, é possível localizar candidatos de forma ativa, com maior economia de tempo. Seu uso permeia todos os cargos, dos operacionais aos mais estratégicos. Este achado pode contribuir de forma mais prática aos candidatos que estão em busca de uma oportunidade, na medida em que indica a necessidade e importância do perfil nesta rede social para maiores chances de localização pelos recrutadores. Não obstante os entrevistados considerarem o amplo uso desta ferramenta quando buscam talentos, Pondé (2019) aponta que os candidatos mais jovens, acima dos 18 anos e abaixo dos 40 anos, à procura de emprego, utilizam com maior frequência o Facebook (97,78%), em seguida, o Instagram (93,33%), e em terceiro lugar, o LinkedIn (84,44%), na contramão do que foi citado em nossa pesquisa, isto é, que todos os recrutadores utilizam o LinkedIn como fonte de busca de talentos. É possível supor que este resultado possui influência do setor em que a pesquisa foi realizada, na medida em que há uma especificidade quando se trata de candidatos que atuam no setor farmacêutico e o LinkedIn pode contribuir na identificação desses profissionais.
Apesar das contribuições, o estudo também apresenta limitações. Entende-se que uma delas está relacionada à escassez de empresas que utilizam a IA, além do LinkedIn, em seus processos de R&S, o que prejudicou um entendimento mais profundo sobre o tópico. Isto se deu também pelo fato de grande parte do universo de empresas pesquisadas serem multinacionais, as quais têm maior dificuldade de aprovação local de compra e implementação de processos de R&S envolvendo tecnologia e IA. Outra limitação refere-se à investigação em empresas exclusivamente do setor farmacêutico, limitando uma melhor compreensão de como as tecnologias e IA estão sendo utilizadas por outras empresas de outros ramos em nosso país.
Como sugestão futura, pesquisas similares podem ser realizadas com empresas de outros setores, que não o farmacêutico, até mesmo para que se efetue um comparativo em relação ao uso de tecnologia e IA nos processos de R&S. É possível, ainda, investigar o uso de tecnologias e IA em outros subsistemas de recursos humanos, como nos processos de aprendizagem e nos processos de avaliação de desempenho. Outro ponto que pode ser levado em consideração é a perspectiva do candidato, tanto daquele que foi selecionado, quanto daquele que não foi selecionado durante os processos de R&S em que são utilizadas tecnologias e IA.","['Ahmed, O. (2018). Artifical Intelligence in HR. International Journal of Reserach and Analytical Reviews, 5(4), 971-978.', 'Albert, E. T. (2019). AI in talent acquisition: a review of AI-applications used in recruitment and selection. Strategic HR Review, 18(5), 215-221. Recuperado de https://doi.org/10.1108/shr-04-2019-00\n» https://doi.org/10.1108/shr-04-2019-00', 'Avelar, C. F. P., Silva, Y. M., & Saraiva, H. L. (2021). Tecnologia Aplicada ao Recrutamento e Seleção: Mudanças Divulgadas e Resultados Percebidos no Uso de Soluções Oferecidas por Hr Techs Brasileiras. Gestão & Sociedade, 15, 4620-4643. Recuperado dehttps://doi.org/10.21171/ges.v15i43.3490\n» https://doi.org/10.21171/ges.v15i43.3490', 'Backman, C., & Hedenus, A. (2019). Online privacy in job recruitment processes? Boundary work among cybervetting recruiters. New Technology, Work and Employment, 34(2), 157-173. Recuperado dehttps://doi.org/10.1111/ntwe.12140\n» https://doi.org/10.1111/ntwe.12140', 'Bardin, L. (1977). Análise de Conteúdo São Paulo, SP: Edições 70.', 'Barman, A., & Das, M. K. (2018). Businesses through Human Resource Technology-Innovations and Dominance. London Journal of Research in Management and Business, 18(2), 33-44.', 'Bartlett, C. A., & Ghoshal, S. (1997). The Myth of the Generic Manager: New Personal Competencies for New Management Roles. California Management Review, 40(1), 92-116. Recuperado dehttps://doi.org/10.2307/41165924\n» https://doi.org/10.2307/41165924', 'Belmont, V., Pereira, G. B., Houzer, I. H., & Caldeira, J. M. X. (2015). Os subprocessos de captação e seleção de pessoas sob o impacto das tecnologias de informação. In Anais do 12º Simpósio de Excelência em Gestão e Tecnologia, Resende, RJ.', 'Bensberg, F., Buscher, G., & Czarnecki, C. (2019). Digital Transformation and IT Topics in the Consulting Industry: A Labor Market Perspective. In V. Nissen (Ed.), Advances in Consulting Research: Recent Findings and Practical Cases (Chap. 16, pp. 341-357). Charm, UK: Springer.', 'Berger, J. L. (2015). Cybervetting: a Common Antecedents Model (Dissertação de Mestrado). Bowling Green State University, Bowling Green, OH.', 'Berkelaar, B. L., & Harrison, M. A. (2016, junho). Cybervetting. The International Encyclopedia of Organizational Communication Recuperado dehttps://doi.org/10.1002/9781118955567.wbieoc054\n» https://doi.org/10.1002/9781118955567.wbieoc054', 'Biberg, J. M. M. (2019). Mídias sociais em processos de recrutamento & seleção: um estudo pela perspectiva de recrutadores e selecionadores brasileiros (Dissertação de Mestrado). Fundação Getulio Vargas, São Paulo, SP.', 'Blommaert, L., Coenders, M., & van Tubergen, F. (2013). Discrimination of Arabic-named applicants in the Netherlands: An internet-based field experiment examining different phases in online recruitment procedures. Social Forces, 92(3), 957-982. Recuperado dehttps://doi.org/10.1093/sf/sot124\n» https://doi.org/10.1093/sf/sot124', 'Boxall, P. C. (1996). The Strategic Hrm Debate and the Resource-Based View of the Firm. Human Resource Management Journal, 6(3), 59-75. Recuperado dehttps://doi.org/10.1111/j.1748-8583.1996.tb00412.x\n» https://doi.org/10.1111/j.1748-8583.1996.tb00412.x', 'Boxall, P. C., & Steeneveld, M. (1999). Human resource strategy and competitive advantage: A longitudinal study of engineering consultancies. Journal of Management Studies, 36(4), 443-463. Recuperado dehttps://doi.org/10.1111/1467-6486.00144\n» https://doi.org/10.1111/1467-6486.00144', 'Cappelli, P. (2001, março). Making the Most of On-Line Recruiting. Harvard Business Review, 79(3), 139-146. Recuperado de https://hbr.org/2001/03/making-the-most-of-on-line-recruiting\n» https://hbr.org/2001/03/making-the-most-of-on-line-recruiting', 'Careerbuilder. (2018, agosto 09). More than half os employers have found content on social media that caused then NOT to hire a candidate, according to recent CareerBuilder survey Recuperado de https://press.careerbuilder.com/2018-08-09-More-Than-Half-of-Employers-Have-Found-Content-on-Social-Media-That-Caused-Them-NOT-to-Hire-a-Candidate-According-to-Recent-CareerBuilder-Survey\n» https://press.careerbuilder.com/2018-08-09-More-Than-Half-of-Employers-Have-Found-Content-on-Social-Media-That-Caused-Them-NOT-to-Hire-a-Candidate-According-to-Recent-CareerBuilder-Survey', 'Cepellos, V. (2019). HR Techs e suas implicações. GV-executivo, 18(5), 45-45. Recuperado dehttps://doi.org/10.12660/gvexec.v18n5.2019.80378\n» https://doi.org/10.12660/gvexec.v18n5.2019.80378', 'Collins, J. (2001). Empresas feitas para vencer: por que apenas algumas empresas brilham (9a ed.). Rio de Janeiro, RJ: Elsevier.', 'Corvalán, J. G. (2017). Administración Pública digital e inteligente: transformaciones en la era de la inteligencia artificial. Revista de Direito Econômico e Socioambiental, 8(2), 26. Recuperado dehttps://doi.org/10.7213/rev.dir.econ.soc.v8i2.19321\n» https://doi.org/10.7213/rev.dir.econ.soc.v8i2.19321', 'Costa, V. P. (2018). Utilização da internet nos processos de recrutamento e seleção: uma avaliação de prós e contras à luz do ambiente de negócios de uma empresa do setor de papel e celulose (Dissertação de Mestrado). Fundação Getulio Vargas, Rio de Janeiro, RJ.', 'Creswell, J. W. (2007). Qualitative Inquiry and Research Design: Choosing Among Five Approaches(2a ed.) Thousand Oaks, CA: Sage Publications.', 'Faliagka, E., Ramantas, K., Tsakalidis, A., & Tzimas, G. (2012). Application of learning algorithms to online recruitment systems. In Proceedingsof the 7º International Conference on Internet and Web Applications and Services Application, Stuttgart, Germany.', 'Farias, J. D. S., Santos, L. D. A., & Licciardi, N. (2018). A Importância da Inovação como Diferencial Competitivo nos Processos de Recrutamento e Seleção. South American Development Society Journal, 4(12), 151-177. Recuperado de https://doi.org/10.24325/issn.2446-5763.v4i12p151-177\n» https://doi.org/10.24325/issn.2446-5763.v4i12p151-177', 'Ferreira, B. P. (2020). Inteligência Artificial no Recrutamento e Seleção: Amiga ou Inimiga? Perceções e Atitudes de Profissionais de Recrutamento e Seleção Portugueses (Dissertação de Mestrado). Instituto Universitário de Lisboa, Liboa, Portugal.', 'Forman, B. A. S., Glasser, N. M., & Jones, S. G. (2020). Companies Using Video Interviews Beware: New Obligations for Positions Based in Illinois. The Computer & Internet Lawyer, 37(2), 13-14.', 'Gee, K. (2017, junho 26). In Unilever’s radical hiring experiment, resumes are out, algorithms are in. The Wall Street Journal Recuperado de https://www.wsj.com/articles/in-unilevers-radical-hiring-experiment-resumes-are-out-algorithms-are-in-1498478400\n» https://www.wsj.com/articles/in-unilevers-radical-hiring-experiment-resumes-are-out-algorithms-are-in-1498478400', 'Geetha, R., & Bhanu, D. S. R. (2018). Recruitment through artificial intelligence: A conceptual study. International Journal of Mechanical Engineering and Technology, 9(7), 63-70.', 'Gil, A. C. (1987). Métodos e técnicas de pesquisa social(2a ed.). São Paulo, SP: Atlas.', 'Given, L. (2008). The SAGE Encyclopedia of Qualitative Research Methods Thousand Oaks, CA: SAGE Publications Ltd.', 'Godoy, A. S. (1995). Introdução à pesquisa qualitativa e suas possibilidades artigos. Revista de Administração de Empresas, 35(2), 57-63. Recuperado de https://doi.org/10.1590/S0034-75901995000200008\n» https://doi.org/10.1590/S0034-75901995000200008', 'HR.Rocks. (2018). Panorama de RH no Brasil 2018 Recuperado de https://conteudo.qulture.rocks/panorama-do-rh-no-brasil-2018\n» https://conteudo.qulture.rocks/panorama-do-rh-no-brasil-2018', 'Institute for Employment Studies. (2019, janeiro). Which way now for HR and organisational changes? IES Perspectives on HR 2018. Recuperado de https://www.employment-studies.co.uk/system/files/resources/files/516-IES-Perspectives-on-HR-2018_0.pdf\n» https://www.employment-studies.co.uk/system/files/resources/files/516-IES-Perspectives-on-HR-2018_0.pdf', 'Jatobá, M. N. (2020). Inteligência artificial no recrutamento & seleção: inovação e seus impactos para a gestão de recursos humanos (Dissertação de Mestrado). Instituto Politécnico de Bragança, Bragança, Portugal.', 'Lima, A. S. H., & Rabelo, A. A. (2018). A Importância do E-Recrutamento e Seleção Online no Processo Organizacional. Revista Psicologia, Diversidade e Saúde, 7(1), 147. Recuperado dehttps://doi.org/10.17267/2317-3394rpds.v7i1.1697\n» https://doi.org/10.17267/2317-3394rpds.v7i1.1697', 'Lorenz, D. R., Oliveira, J. M. S., & Silva, J. R. D. (2019). Instrumentos Tecnológicos: Vantagens e Desvantagens da Utilização no Processo de Recrutamento e Seleção de Pessoas Recuperado de http://tcconline.fag.edu.br:8080/app/webroot/files/trabalhos/20191021-231403.pdf\n» http://tcconline.fag.edu.br:8080/app/webroot/files/trabalhos/20191021-231403.pdf', 'Malik, M. S., & Mujtaba, M. A. (2018). Impact of E-Recruitment on Effectiveness of HR Department in Private Sector of Pakistan. International Journal of Human Resource Studies, 8(2), 80-94. Recuperado de https://doi.org/10.5296/ijhrs.v8i2.12869\n» https://doi.org/10.5296/ijhrs.v8i2.12869', 'Melton, J., Miller, R., Jensen, B. R., & Shah, V. (2018). Decisions, decisions: Cybervetting through the eyes of students. Journal of Education for Business, 93(5), 252-259. Recuperado de https://doi.org/10.1080/08832323.2018.1442785\n» https://doi.org/10.1080/08832323.2018.1442785', 'Mendonça, A. P. A., Rodrigues, B. A. A., Aragão, C. A. S., & Del Vecchio, R. C. (2017). A Tecnologia Atrelada ao Resultado-Recursos Humanos. Razão Contábil e Finanças, 7(2), 1-13.', 'Mendonça, A. P. A., Rodrigues, B. A. A., Aragão, C. A. S., & Del Vecchio, R. C. (2018). Inteligência artificial - recursos humanos frente as novas tecnologias, posturas e atribuições. Contribuciones a La Economía Recuperado de https://www.eumed.net/rev/ce/2018/4/inteligencia-artificial.html\n» https://www.eumed.net/rev/ce/2018/4/inteligencia-artificial.html', 'Pérez, J. B., & Falótico, A. J. A. (2019). Various perspectives of labor and human resources challenges and changes due to automation and artificial intelligence. Academicus International Scientific Journal, 20, 106-118. Recuperado dehttps://doi.org/10.7336/academicus.2019.20.08\n» https://doi.org/10.7336/academicus.2019.20.08', 'Pondé, F. A. (2019). O impacto das mídias sociais no processo de recrutamento e seleção (Trabalho de Conclusão de Curso). Universidade Federal do Rio de Janeiro, Rio de Janeiro, RJ.', 'Prahalad, C. K., & Hamel, G. (2000). The core competence of the corporation. Strategic Learning in a Knowledge Economy Recuperado dehttps://doi.org/10.1016/b978-0-7506-7223-8.50003-4\n» https://doi.org/10.1016/b978-0-7506-7223-8.50003-4', 'PwC & Instituto Locomotiva. (2022). O abismo digital no Brasil Recuperado de https://www.pwc.com.br/pt/estudos/preocupacoes-ceos/mais-temas/2022/o-abismo-digital-no-brasil.html\n» https://www.pwc.com.br/pt/estudos/preocupacoes-ceos/mais-temas/2022/o-abismo-digital-no-brasil.html', 'Rab-Kettler, K., & Lehnervp, B. (2019). Recruitment in the Times of Machine Learning. Management Systems in Production Engineering, 27(2), 105-109. Recuperado dehttps://doi.org/10.1515/mspe-2019-0018\n» https://doi.org/10.1515/mspe-2019-0018', 'Ribeiro, J., Souza, F. N., & Lobão, C. (2018). Editorial: Saturação da Análise na Investigação Qualitativa: Quando Parar de Recolher Dados? Revista Pesquisa Qualitativa, 6(10), 1-5.', 'Schwab, K. (2020). La Cuarta Revolución Industrial. Futuro Hoy, 1(1), 6-10. Recuperado dehttps://doi.org/10.5281/zenodo.4299164\n» https://doi.org/10.5281/zenodo.4299164', 'Saraiva, L. A. S., & Irigaray, H. A. D. R. (2009). Políticas de diversidade nas organizações: uma questão de discurso? Revista de Administração de Empresas, 49(3), 337-348. Recuperado dehttps://doi.org/10.1590/S0034-75902009000300008\n» https://doi.org/10.1590/S0034-75902009000300008', 'Silva, J., & Barreto, L. (2019). O Uso da Tecnologia no Recrutamento e Seleção de Pessoas: Um Estudo no Setor Hoteleiro. PODIUM Sport, Leisure And Tourism Review, 8(2), 192-210. Recuperado dehttps://doi.org/10.5585/podium.v8i2.10665\n» https://doi.org/10.5585/podium.v8i2.10665', 'Sindusfarma. (2020). Perfil da Indústria Farmacêutica e Aspectos Relevantes do Setor Recuperado de https://sindusfarma.org.br/publicacoes/\n» https://sindusfarma.org.br/publicacoes/', 'The Reppler Effect. (2011, setembro 27) Managing your online image across social networks Recuperado de https://reppler. wordpress.com/2011/09/27/managing-your-online-image-across-social-networks/\n» https://reppler. wordpress.com/2011/09/27/managing-your-online-image-across-social-networks/', 'Upadhyay, A. K., & Khandelwal, K. (2018). Applying artificial intelligence: implications for recruitment. Strategic HR Review, 17(5), 255-258. Recuperado dehttps://doi.org/10.1108/shr-07-2018-0051\n» https://doi.org/10.1108/shr-07-2018-0051', 'Verdélio, A. (2021, julho 16). Mercado de medicamentos é concentrado em 64 empresas, diz Anvisa. Agência Brasil Recuperado de https://agenciabrasil.ebc.com.br/saude/noticia/2021-07/mercado-de-medicamentos-e-concentrado-em-64- empresas-diz-anvisa\n» https://agenciabrasil.ebc.com.br/saude/noticia/2021-07/mercado-de-medicamentos-e-concentrado-em-64- empresas-diz-anvisa']","['Publicação nesta coleção\n08 Maio 2023', 'Data do Fascículo\nMar-Apr 2023']","[' DANIEL BLUMEN ', ' VANESSA MARTINES CEPELLOS ']","['Fundação Getulio Vargas(FGV EAESP) / Escola de Administração de Empresas de São Paulo, São Paulo - SP, Brasil', 'Fundação Getulio Vargas(FGV EAESP) / Escola de Administração de Empresas de São Paulo, São Paulo - SP, Brasil']",http://www.scielo.br/scielo.php?script=sci_arttext&pid=S1679-39512023000200616&lang=pt,2024-11-21 09:59:49.139652,Scielo.org
A Inteligência Artificial na divisão leste-oeste,"Pode ser que, para muitos, o assunto “Inteligência Artificial” já não seja novidade e, para outros, algo muito distante do dia a dia. No entanto, sabemos que as tecnologias estão cada vez mais presentes na rotina diária de milhões de pessoas e estão cada vez mais rápidas, aplicáveis, eficientes e inteligentes.","Pode ser que, para muitos, o assunto “Inteligência Artificial” já não seja novidade e, para outros, algo muito distante do dia a dia. No entanto, sabemos que as tecnologias estão cada vez mais presentes na rotina diária de milhões de pessoas e estão cada vez mais rápidas, aplicáveis, eficientes e inteligentes.
Fato é que o tema “Inteligência Artificial” (IA) não foi esgotado e nem mesmo está ultrapassado, sendo duas características até mesmo impossíveis de ocorrerem dada a rápida velocidade em estudos e desenvolvimento nesta área do conhecimento.
Kai-Fu Lee, um cientista da computação, empresário e escritor nascido em Taiwan, escreve Inteligência Artificial: Como os robôs estão mudando o mundo, a forma como amamos, nos relacionamos, trabalhamos e vivemos, visando apontar as diferenças entre a aplicação da inteligência artificial em países desenvolvidos e em desenvolvimento. Assim, não se engane ao pensar que o livro é voltado para experts do ramo. Ele discursa para cidadãos do mundo e espera que o livro “lance luz sobre como chegamos até aqui (em relação a IA) e inspire novas conversas sobre para onde vamos a partir de onde estamos” (p.11).
Apesar de Lee ser bem claro na exposição de seu objetivo, caberá ao leitor construir essa linha de raciocínio, pois ela não aparece de forma clara no início do livro. Desse modo, com o intuito de explorarmos essa sequência passado-presente-futuro, essa resenha está dividida da seguinte forma: irá começar com o despertar da China para retratar o momento em que ela entra para o panorama da IA. Nesse ponto, teremos um vislumbre da insistente comparação e concorrência com os Estados Unidos. Depois, seguirá para alguns breves fatos históricos, com acréscimo de alguns marcos do avanço da tecnologia que envolvem o escopo do livro e relatam as eras e fases que Lee aborda em sua obra.
Após esses dois tópicos, o despertar e a análise comparativa, o leitor encontrará o foco do livro: a disputa entre a China e os Estados Unidos pontuada pela constante comparação entre os dois países. É nesse ponto que o autor traz uma bagagem diferencial; seu background de vivência nessas duas culturas permite uma imersão original com uma visão única e singular de um especialista e empresário de uma tecnologia sem fronteiras, neste ponto, o livro faz “valer a pena”.
Por último, a resenha, assim como o livro, tem seu fim numa reviravolta de pensamentos e emoções. O próprio autor coloca em xeque alguns pontos morais e éticos sobre o desenvolvimento da tecnologia de IA e aborda problemáticas socioeconômicas trazidas por ela. É possível que essas contestações advêm do momento pessoal vivido pelo autor, que humaniza e traz sentimentos mais afetivos, não encontrados em momentos anteriores do livro.
Para a leitura do texto, uma última consideração mostra-se importante, qual seja, a substituição do termo “Inteligência Artificial” pela sigla “IA”. E a explicação de que alguns termos mais populares em inglês foram traduzidos para o português como, por exemplo, deep learning (aprendizado profundo), machine learning (aprendizado de máquina), entre outros, seguindo a tradução do livro em português.
O livro tem seu início com o relato do momento em que a China acorda para o avanço na tecnologia de IA, ou seja, quando o país se dá conta de que, caso não impulsione estudos e produção na tecnologia de IA, ficará em defasagem com outros países.
Já dando indícios de qual será o pano de fundo da história - disputa China vs. Estados Unidos -, o despertar da China ocorre quando o programa americano AlphaGo vence, em 2017, o então campeão chinês do jogo Go Ke Jei (p.15).
Rapidamente falando, Go é conhecido como o jogo de tabuleiro mais antigo ainda jogado. Acredita-se que ele leva seus jogadores a um refinamento e sabedoria intelectual e representa uma arte. Dessa forma, com esse contexto, fica fácil entender a importância da partida relatada e, mais ainda, o impacto criado ao perder a partida.
Lee nomeia esse momento como o “Momento Sputnik da China” em uma alusão análoga à época em que a então União Soviética lançou o primeiro satélite feito pelo homem ao espaço. A China estaria despertando somente após esse episódio e começaria a impulsionar o desenvolvimento em IA, assim como os Estados Unidos fizeram com tecnologias aeroespaciais que resultou, como exemplo, a criação da Nasa.
Seguindo a analogia, o autor segue afirmando que o resultado do despertar da China é o aviso de que, até 2030, seu país será o “centro de inovação global em inteligência artificial, liderando em teoria, tecnologia e aplicação” (p.16).
Porém, a provocação do jogo não é o único fator que determinou a entrada da China para a corrida. De acordo com Lee, a China uniu exatamente tudo o que foi preciso para ganhar a disputa e tornar-se uma superpotência em IA, o que ele denominou de “quatro blocos de construção principais: dados abundantes, empreendedores tenazes, cientistas de IA bem treinados e um ambiente político favorável” (p.104).
A vitória do AlphaGo frente ao campeão humano é nitidamente um marco nos avanços em IA. Não por menos, essa vitória representa a clássica disputa entre o homem e a máquina. É natural que o Momento Sputnik da China tenha sua importância intensificada no Oriente, permitindo uma comparação antes-e-depois. Felizmente, o livro não fica restrito a esse episódio, e assim, o autor traz um incrível panorama sobre a história da IA, com alguns momentos marcantes os quais a população atual teve a oportunidade de testemunhar; uma espécie de linha do tempo, com etapas de evolução e histórias de empresas que inovam utilizando essa tecnologia.
Adicionalmente, a aula de história não para. O autor também divide esses avanços tecnológicos em eras e explora questões socioeconômicas que poderão vir a acontecer, as quais serão oportunamente trazidas e exploradas ao final da resenha.
O desenvolvimento das tecnologias que permitiram o avanço da IA na sociedade é fruto e semente de muitas outras conquistas. Envolve, por exemplo, as bases do aprendizado de máquinas, como semente, e as promessas do aprendizado profundo, como frutos já em colheita. Complexo? Sim. Mas nunca foi simples. O autor insiste em aprofundar-se no assunto e leva a discussão sempre mesclando tópicos de tecnologia e do seu impacto na sociedade.
Querendo responder à pergunta se máquinas poderiam pensar como nós, o matemático britânico Alan Turing publicou, em 1950, um estudo explorando o teste hipotético no qual um computador seria capaz de se passar por um humano fazendo perguntas e respostas, como se numa conversa. Este teste foi apelidado de “Teste de Turing” e continua sendo utilizado até os dias atuais (OECD, 2019, p.20) como um indicativo de proximidade da inteligência humana.
Lee retorna ao século passado comentando sobre os avanços nas pesquisas. Foi em 1956, durante o Dartmouth Summer Research Project, que muitos acreditam ter sido o nascimento da Inteligência Artificial, um conceito criado em conjunto por John McCarthy, Alan Newell, Arthur Samuel, Herbert Simon e Marvin Minsky (Anyoha, 2017
).
As pesquisas e descobertas em inteligência artificial foram constantes por 60 anos. Depois dessa data, a IA passou por um período chamado de “inverno de IA” (OECD, 2019, p.20) (p.19), isso em 1970, que foi caracterizado pelos poucos avanços na área e drástica diminuição de financiamentos.
Esse período de desapontamento da IA nasce depois de duas grandes decepções em relação às promessas de avanços na Ciência da Computação. A primeira decepção ocorre na segunda metade dos anos 1960 quando a comunidade de computação se frustra com o baixo desempenho dos tradutores automáticos de então e; a segunda decepção ocorre pouco tempo mais tarde, no final da mesma década, com o desencanto mostrado por Marvim Minsky e Seymour Papert sobre o modelo conexionista de Frank Rosenblatt, num paper de 1969. Esse período ainda marca essa área de pesquisa e é de certa forma irônico perceber hoje que a abordagem conexionista (redes neurais) é a grande esperança de IA nos modelos de aprendizado profundo.
Como todo inverno, esse também passou e os anos seguintes foram seguidos de grandes descobertas: em 1997, o campeão mundial de xadrez foi vencido pelo Deep Blue, o computador da IBM que utilizou tecnologia de IA para jogar partidas de xadrez e, no mesmo ano, o Windows implementou o software de reconhecimento de fala desenvolvido pela Dragon Systems1 (Anyoha, 2017
).
Esses são alguns exemplos emblemáticos e conhecidos, mas que, até então, não contavam com a participação da China, uma vez que o país somente entra para a corrida para se tornar uma superpotência em IA após seu “Momento Sputnik”.
Negando que o papel da China ficaria restrito à de “imitadora atrás da vanguarda” (Estados Unidos) (p.25), Kai-Fu Lee explica que a China vive hoje o momento ideal para se tornar a maior superpotência em IA. Tal conquista, de acordo com o autor, é possível dada as duas grandes transições globais que ocorreram: da era da descoberta à era da implementação, e da era da especialidade à era dos dados (p.25).
Ainda segundo Lee, a vantagem para a China de estarmos na era da implementação é o fato de minimizar algumas das suas fraquezas como, por exemplo, a tardia entrada para os estudos, pesquisas e desenvolvimento em IA. Estar na era da implementação implica partir de pontos em comum com a tecnologia existente e disponível. Ele sugere uma espécie de nivelamento de informações.
Sobre a segunda transição, a da era da especialidade à era dos dados, o autor é mais breve em sua explanação. Simplificadamente, fala que, por não estamos na era de descobertas, os profissionais especialistas já não são tão fundamentais. Atualmente, o necessário é volume de dados e, quem os possui, está vencendo a disputa e está a caminho de se tornar uma superpotência em IA.
Seguindo essa linha de raciocínio, continua o autor afirmando que a China possui exatamente o que é preciso para dominar essa era: big data, poder de computação e o trabalho de engenheiros para criarem bons algoritmos de IA (p.27).
Ao longo do livro, Kai-Fu Lee relata inúmeras estratégias, empresas envolvidas, empreendedores motivados e cita vários exemplos alertando para a vinda da China brigando na disputa. Ao menos um recado se destaca, o de que devemos ficar alertas.
Com estudos, inclusive o doutorado, na prestigiosa Carnegie Mellon nos Estados Unidos e a atuação profissional na China como presidente do Google China, Kai-Fu Lee une conhecimentos técnicos e experiências na área de IA, proporcionando ao leitor uma visão única e interessante dos dois principais países que disputam a excelência na área.
Explorando as diferenças culturais americanas e chinesas, Lee escreve o aspecto mais curioso do livro, fornecendo ao leitor um conhecimento de dentro de ambos os mercados, situação raramente acessível, o que inclui particularidades de uma cultura oriental ainda pouco conhecida, ao mesmo tempo em que desafia o leitor, transpondo-o a situações muitas vezes impensadas, cheias de particularidades.
Dividido entre nove capítulos, o sumário destaca que apenas um capítulo é dedicado a essa rivalidade comparativa com os Estados Unidos. Por outro lado, é possível notar essa temática permeando pelo livro todo, seja com relação às pesquisas e desenvolvimentos em IA, seja em relação aos valores culturais da sociedade, ou então em relação ao que motiva o sucesso de empresas e startups, ou mesmo a interferência do governo. Por qualquer ângulo, é possível encontrar a dualidade Estados Unidos-China.
Uma das características culturais que desperta a curiosidade é a cópia como prática aceita na China (p.29). São vários os casos de cópias e podemos citar algumas, como: a empresa chinesa Meituan, copiando Groupon, empresa norte-americana, na categoria de sites de compras coletivas e as empresas chinesas, Xiaonei e Fanfou, imitando o Facebook e o Twitter, respectivamente (p.37 ss). De acordo com Lee, esse tipo de “empreendedorismo imitador” (p.38) é estigmatizado na cultura ocidental, uma vez que considera a imitação um obstáculo ao processo de inovação; contudo, é visto, na China, como uma maneira para impulsionar o crescimento do país.
Por conseguinte, de acordo com o autor, o que tem feito o país prosperar é, na verdade, o uso da estratégia da cópia como primeiro passo - eliminando a fase em que é preciso desenvolver a engenharia básica e novas habilidades - para, só então, investir na concorrência como segunda etapa, adaptando e otimizando seus serviços aos usuários chineses (p.50).
O autor elucida bem o exemplo de adaptação para o usuário chinês. Lee compartilha a experiência vivida enquanto presidente do Google China quando o principal concorrente era o mecanismo de busca chinês Baidu, que tinha um diferencial de destaque no país, visto que utilizava os hábitos de busca dos usuários chineses.
Sabendo que a interação dos usuários com as páginas de pesquisa possui uma interferência direta com o sucesso da ferramenta, pesquisadores utilizaram mapas de calor gerados por usuários chineses e norte-americanos para mapear como cada usuário usava o site, procurando padrões em onde olhavam e onde clicavam.
O resultado mostrou dois padrões opostos, e enquanto os usuários norte-americanos procuravam uma informação específica, como se estivessem consultando uma lista telefônica, e permaneciam na mesma página por dez segundos; os chineses conferiam todos os resultados, como se fizessem compras em um shopping center, numa espécie de escolha, e levavam trinta e sete segundos em cada página.
Transformando o exemplo numa realidade constante, a prática da imitação seria o caminho de sucesso para muitas empresas, mas desde que, após imitar, se dedicassem em estudar e adaptar ao usuário chinês. No entanto, muitas não o fizeram e, culparam seu fracasso nas fiscalizações e protecionismo do governo chinês (p.55).
Lee afirma que o uso da imitação é estratégico, pois elimina dois componentes difíceis do empreendedorismo: custo e tempo. Inovar, além de custoso por conta dos investimentos, exige planejamentos feitos nas áreas da educação, fomentando pesquisas, estágios e orientações, dois investimentos que a China não podia arcar à época. Para exemplificar, o livro traz alguns dados como, enquanto o Google era fundado em 1998, 30% da população dos Estados Unidos estava conectada à internet, enquanto essa porcentagem na China era de 0,2% (p.49).
A prática da cópia também possui um aspecto histórico e, ao contrário do que pode parecer, não foi adotada recentemente, ela advém de valores culturais fortemente enraizados. Lee explica que, ao contrário de Sócrates, que propunha o questionamento para chegar à verdade, os antigos filósofos chineses instruíam as pessoas a “seguirem os rituais dos sábios do passado antigo”.
A imitação é um componente forte do livro e dedica-se um capítulo exclusivo a ele. No entanto, Lee também aborda um aspecto social bastante importante ao nos lembrar de que essa geração de empreendedores dedicados à tecnologia são, em sua maioria, filhos da antiga e extinta política de filho único e são parte de uma geração em que seus avós, e até mesmo seus pais, viveram durante a Grande Fome Chinesa.
Não somente a conformidade e deferência com figuras de autoridade (pais, por exemplo) é cultural e presente na sociedade. Unindo o passado com essas características, estamos falando de jovens que, ao invés de seguirem uma carreira no setor público, modo tradicional para se prosperar na China, eles estão arriscando no setor privado e levando consigo a expectativa de serem a primeira geração da família a sair de uma condição de pobreza (p.43).
Sem adentrar na questão polêmica de “qual cultura é melhor”, Lee atribui o sucesso atual do país a sua cultura, citando como exemplo a prática da imitação que, por criar muita concorrência, possibilitou um ambiente de fomentação de empreendedores ferozes, com muita determinação para vencer.
No decorrer do livro, Lee traz diversos exemplos da aplicabilidade da tecnologia envolvendo IA. Para citar alguns, são as geladeiras que interagem com sua lista do supermercado, supermercados com carrinhos de compra que sabem seu nome e diagnósticos médicos e sentenças judiciais feitas por ferramentas de IA. A lista continua conforme os limites da tecnologia ou até onde a imaginação alcança.
Partindo da ideia de que a sociedade de fato quer esse tipo de “facilidade” inserida no seu dia a dia, o autor, que até então mostrou um lado pendente para o otimismo, dedica a última parte do livro nos impactos e consequências negativas advindas da IA.
Partindo de uma visão ampliada, a IA gravita em direção aos monopólios por meio de um ciclo contínuo de repetição: “produtos melhores levam a mais usuários, esses usuários levam a mais dados e esses dados levam a produtos ainda melhores e, assim, a mais usuários e dados” (p.201). Por conseguinte, isso levaria o mundo a ser regido por uma nova ordem mundial bipolar, dominado pelas superpotências em IA.
Entretanto, Lee traz um alerta, para todas as nações em um não muito distante do futuro, no que concerne à extinção e substituição de empregos. Percebe-se pela leitura que arriscar num valor, data e impacto mais preciso é de pouca valia, uma vez que nem mesmo importantes consultorias entram num consenso em suas estimativas.1
Independentemente de como as estimativas são calculadas, as consequências relacionadas aos empregos e profissões são inevitáveis e, nesse aspecto, o livro contribui muito ao explorar quais são os tipos de perda de trabalho, quais tipos de profissões podem ter um impacto mais rápido e como são os processos de substituição dessas profissões.
O livro, que possui uma abordagem um tanto quanto fria e competitiva em seu decorrer, surpreende o leitor com uma reviravolta. É um momento mais íntimo, em que Lee expõe seus pensamentos e emoções aos compartilhar sua batalha pessoal com o diagnóstico de Linfoma Estágio 4. Ele relata como essa fase o aproximou dos valores humanos e como ficou imerso na importância do amor, atribuindo à “sabedoria do câncer”, expressão utilizada por ele.
As reflexões de Lee fizeram uma excelente contribuição para sua obra. Ao sei final, ele arrisca numa espécie de brainstorming e propõe algumas sugestões para suavizar e melhorar a vida da sociedade com as tecnologias advindas da IA, que ele nomeia como “Projetos para a coexistência entre os humanos e a IA” (p.233).
Pode-se dizer que Kai-Fu Lee atinge o objetivo proposto em seu início, ou seja, o de entender de onde viemos, onde estamos e para onde estamos indo. Além disso, a imersão cultural chinesa juntamente com as reflexões finais e soluções propostas, enriquecem a obra, e tornam-na uma leitura importante para a atualidade, onde a consciência das ações do presente possuem impactos estonteantes no futuro.","['ANYOHA, R. The History of Artificial Intelligence. SITN, 2017. Disponível em: <http://sitn.hms.harvard.edu/flash/2017/history-artificial-intelligence/>. Acesso em: 2 jul. 2020.\n» http://sitn.hms.harvard.edu/flash/2017/history-artificial-intelligence', 'BOSTROM, N.; YUDKOWSKY, E. The Ethics of Artificial Intelligence. Machine Intelligence Research Institute. New York: Cambridge University Press, 2018. Disponível em: <https://intelligence.org/files/EthicsofAI.pdf>. Acesso em: 30 jun. 2020.\n» https://intelligence.org/files/EthicsofAI.pdf', 'LEE, K.-F. Inteligência Artificial: Como os robôs estão mudando o mundo, a forma como amamos, nos relacionamos, trabalhamos e vivemos. Rio de Janeiro: Editora Globo, 2019.', 'LUFKIN, B. Why the biggest challenge facing AI is na ethical one. BBC Future, 2017. Disponível em: <https://www.bbc.com/future/article/20170706-theres-a-problem-with-the-way-we-define-inequality>. Acesso em: 29 jun. 2020.\n» https://www.bbc.com/future/article/20170706-theres-a-problem-with-the-way-we-define-inequality', 'MARR, B. What’s The Impact Of Artificial Intelligence And Technology On Society. Forbes, 2020. Disponível em: <https://www.forbes.com/sites/bernardmarr/2020/03/09/whats-the-impact-of-artificial-intelligence-and-technology-on-society/#6214d7da3098>. Acesso em: 2 jul. 2020.\n» https://www.forbes.com/sites/bernardmarr/2020/03/09/whats-the-impact-of-artificial-intelligence-and-technology-on-society/#6214d7da3098', 'OECD LIBRARY. Artificial Intelligence in Society. Paris: OECD Publishing, 2019. E-book. Disponível em: <https://doi.org/10.1787/eedfee77-en>. Acesso em: 3 jul. 2020.\n» https://doi.org/10.1787/eedfee77-en', 'TATE, K. History of A.I.: Artificial Intelligence (Infographic). Live Science, 2014. Disponível em: <https://www.livescience.com/47544-history-of-a-i-artificial-intelligence-infographic.html>. Acesso em: 30 jun. 2020.\n» https://www.livescience.com/47544-history-of-a-i-artificial-intelligence-infographic.html']","['Publicação nesta coleção\n20 Mar 2023', 'Data do Fascículo\nJan-Apr 2023']","[' Isadora Maria Roseiro Ruiz ', ' Cristina Godoy Bernardo de Oliveira ']","['Faculdade de Direito de Franca, Franca, São Paulo, Brasil. ruiz.isadora@gmail.com ', 'Universidade de São Paulo, Faculdade de Direito, Ribeirão Preto, São Paulo, Brasil. cristinagodoy@usp.br ']",http://www.scielo.br/scielo.php?script=sci_arttext&pid=S0103-40142023000100387&lang=pt,2024-11-21 09:59:51.213775,Scielo.org
